<!DOCTYPE html><html lang="zh-TW"><head><!-- Google Analytics--><script async src="https://www.googletagmanager.com/gtag/js?id=UA-103835191-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-103835191-1');
</script><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>SLMT's Blog | Java 筆記 (1) - 探究 JVM 對自製系統造成的效能問題</title><link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css" integrity="sha384-nn4HPE8lTHyVtfCBi5yW9d20FjT8BJwUXyWZT9InLYax14RDjBj46LmSztkmNP9w" crossorigin="anonymous"><link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/blog/css/style.css"><link rel="stylesheet" type="text/css" href="/blog/css/syntax-highlight.css"><script src="https://use.fontawesome.com/0bc11e7eba.js"></script><!-- Open Graph Protocol--><meta property="og:title" content="Java 筆記 (1) - 探究 JVM 對自製系統造成的效能問題"><meta property="og:image" content="http://www.slmt.tw/blog/images/logo.png"><meta property="og:type" content="website"><meta property="og:url" content="/blog/2021/06/07/java-note-drop-due-to-jit/"><meta property="og:site_name" content="SLMT's Blog"><meta property="og:locale" content="zh-TW"><meta property="og:description" content="最近在使用實驗室開發的 ElaSQL 分散式資料庫系統 進行實驗時，發現系統效能在某個時間點會有突然下墜的情況。 因此這篇文章分享一下調查下墜原因的過程，以及可能的應對措施。"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/blog/rss.xml" title="SLMT's Blog" type="application/atom+xml">
</head><body><div id="container"><div id="header"><h1 class="title">SLMT's Blog</h1><div class="pure-g navs"><div class="nav pure-u-1 pure-u-sm-1-4"><a href="/blog/.">All Posts</a></div><div class="nav pure-u-1 pure-u-sm-1-4"><a href="/blog/archives">Archive</a></div><div class="nav pure-u-1 pure-u-sm-1-4"><a href="https://www.slmt.tw/">About</a></div><div class="nav pure-u-1 pure-u-sm-1-4"><a href="/blog/rss.xml">RSS</a></div></div></div><div id="main"><h1 class="post-large-title">Java 筆記 (1) - 探究 JVM 對自製系統造成的效能問題</h1><div class="post-meta"><div class="post-date"><i class="fa fa-calendar" aria-hidden="true"></i>2021/06/07</div><div class="post-cats"><i class="fa fa-folder-open" aria-hidden="true"></i><a class="post-cat" href="/blog/categories/programming/">Programming</a>/<a class="post-cat" href="/blog/categories/programming/java/">Java</a></div><div class="post-tags"><i class="fa fa-tags" aria-hidden="true"></i><a class="post-tag" href="/blog/tags/java/">#java</a><a class="post-tag" href="/blog/tags/performance/">#performance</a><a class="post-tag" href="/blog/tags/jvm/">#jvm</a><a class="post-tag" href="/blog/tags/jit/">#jit</a></div></div><div class="post-content"><p>最近在使用實驗室開發的 <a target="_blank" rel="noopener" href="https://github.com/elasql/elasql">ElaSQL 分散式資料庫系統</a> 進行實驗時，發現系統效能在某個時間點會有突然下墜的情況。 因此這篇文章分享一下調查下墜原因的過程，以及可能的應對措施。</p>
<a id="more"></a>

<h2 id="發現問題"><a href="#發現問題" class="headerlink" title="發現問題"></a>發現問題</h2><p>最近正在整理之前 <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.14778/3303753.3303764">發表的論文</a> 的程式碼，以提供其他研究團隊進行後續的研究。</p>
<p>該論文主要是研究如何在分散式的先決式資料庫系統 (Deterministic Database System) 上一邊搬移資料的同時避免去影響到系統效能。</p>
<p>實驗的時候有很多情境要測試。其中一個測試是啟動一個包含三台 server 的分散式資料庫系統，讓第一台 server 的負載超過它能處理的能力，第二台 server 則處理適量的負載，第三台機器則作為預備 server，一開始不包含任何資料，也不處理任何使用者請求。此時系統在發現第一台 server 負載過高時，就會下達一個指示將第一台 server 的部分資料搬移到第三台 server，並且讓第三台 server 加入處理使用者請求。實驗過程我們會記錄效能的變化，以觀察效能是否有受到資料搬遷的影響。</p>
<p>因此最近我在我們最新版的系統上面重現了這組實驗：</p>
<p><img src="scaleout-ex-mgcrab.png" alt="Scale-out Experiment - MgCrab"></p>
<p style='text-align: center'>圖一、我們提出的方法 (MgCrab) 的實驗結果</p>

<p>圖的 X 軸代表時間軸，Y 軸代表每一台 server 每五秒處理的 transaction (Relational DBMS 處理請求的單位) 數量，資料搬遷發生在第 115 秒到 325 秒之間。</p>
<p>基本上結果看起來非常好，其中 Server 2 (第三台 server) 的效能飛起代表它具備足夠的資料開始處理使用者請求，而且效能也沒受到甚麼影響… </p>
<p>除了一個地方之外。</p>
<p>在第 115 ~ 125 秒之間，系統效能神秘地下墜了一下。這點是我們之前沒有觀察到的狀況，因此勾起了我的好奇。</p>
<h2 id="各種碰壁"><a href="#各種碰壁" class="headerlink" title="各種碰壁"></a>各種碰壁</h2><p>首先我考慮了一下系統在那個時間點是否出現了甚麼變化。第一個在我腦中顯現的就是系統在當時開始了資料搬遷的動作，然而這個下墜並沒有持續到資料搬遷結束，而只是在開始的前十秒下墜而已。顯然並不是資料搬遷本身造成的。</p>
<p>接著我思考了有甚麼東西會在資料搬遷的初始期才會存在。後來我想到可能是初始化資料搬遷的動作造成的影響。</p>
<p>為了要讓資料搬遷順利進行，在資料搬遷剛開始的瞬間，系統會進行一個準備作業。包括確定搬遷計畫的內容，要搬動的資料範圍等等。然而這些程式碼實際上並沒有太多工作要做，因此我對這項可能性感到懷疑。不過我暫時想不到其他可能性，所以還是先對該段程式碼進行計時 (這邊使用 <code>java.lang.System.nanoTime()</code> 進行)。</p>
<p>計時之後的結果令我感到訝異，該段準備工作竟然會耗費大概 5 ~ 30 ms 不等的時間。這段時間雖然看起來不多，但要知道對資料庫系統這種高效能系統來說其實是非常長的。我們系統其實處理一筆包含 10 個 SQL 的 transaction (假設資料都在同一台電腦上) ，從收到指令、解析、Query 優化、Index 搜尋、讀取資料表、序列化結果並回報使用者等等，也只要大概 5 ms 左右的時間而已。特別是該段程式碼又在系統一個重要的處理元件中，如果花太久時間鐵定會造成整體效能的下降。</p>
<p>為了找出確切是哪一段程式碼出拖慢效能，我進一步將該段程式碼分割成多份，並對每一段程式碼計時。然而結果卻令人失望。因為結果顯示每一段程式碼都分別花費差不多的時間。換句話說，沒有一個真正慢的地方，而是大家都很慢。</p>
<h2 id="難道是垃圾回收-GC-？"><a href="#難道是垃圾回收-GC-？" class="headerlink" title="難道是垃圾回收 (GC)？"></a>難道是垃圾回收 (GC)？</h2><p>中間我稍事休息一下，重新思考甚麼樣的動作可能會造成大家都變慢。後來得到一個結論，應該是 Java Virtual Machine (JVM) 搞得鬼。</p>
<p>JVM 是執行 Java 的必要程式，有時候它背後會做一些事情造成前景的程式變慢，這個時候就會造成大家都變慢的假象。我們的研究為了避免花太多時間在處理記憶體的問題，因此選擇了 Java 這種有 Garbage Collection (GC) 機制的語言作為開發語言。但是代價是效能會稍慢於 C/C++ 與 Rust 這種精確掌控記憶體的語言，而且背後有時候會因為 GC 而卡住。</p>
<p>為了確定是否是 GC 造成的問題，我在 JVM 啟動時加入了 <code>-verbose:gc -Xloggc:gc.log -XX:+PrintGCTimeStamps -XX:+PrintGCDetails</code> 的參數。這組參數可以讓 JVM 在每次 GC 的時候輸出一條 log 到 <code>gc.log</code> 檔案。因此如果有甚麼異狀就可以馬上知道。</p>
<p>我滿懷期待的心情，想說終於要抓到這個壞蛋了。打開了 <code>gc.log</code> 檔：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Java HotSpot(TM) 64-Bit Server VM (25.211-b12) for linux-amd64 JRE (1.8.0_211-b12), built on Apr  1 2019 20:39:34 by &quot;java_re&quot; with gcc 7.3.0</span><br><span class="line">Memory: 4k page, physical 32675496k(16773680k free), swap 4079612k(3923452k free)</span><br><span class="line">CommandLine flags: -XX:InitialHeapSize&#x3D;17179869184 -XX:MaxHeapSize&#x3D;17179869184 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC</span><br><span class="line">...</span><br><span class="line">(中略)</span><br><span class="line">...</span><br><span class="line">92.842: [GC (Allocation Failure) [PSYoungGen: 4040512K-&gt;1728K(4813824K)] 4535064K-&gt;496968K(15998976K), 0.0091350 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">94.758: [GC (Allocation Failure) [PSYoungGen: 4040384K-&gt;1728K(4843520K)] 4535624K-&gt;497728K(16028672K), 0.0092166 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">96.690: [GC (Allocation Failure) [PSYoungGen: 4080832K-&gt;1568K(4827648K)] 4576832K-&gt;498288K(16012800K), 0.0160904 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.02 secs]</span><br><span class="line">98.667: [GC (Allocation Failure) [PSYoungGen: 4080672K-&gt;2560K(4888064K)] 4577392K-&gt;499976K(16073216K), 0.0099236 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">100.644: [GC (Allocation Failure) [PSYoungGen: 4162560K-&gt;1920K(4864000K)] 4659976K-&gt;501032K(16049152K), 0.0099665 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">102.635: [GC (Allocation Failure) [PSYoungGen: 4161920K-&gt;1728K(4942848K)] 4661032K-&gt;501552K(16128000K), 0.0094264 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">104.654: [GC (Allocation Failure) [PSYoungGen: 4267200K-&gt;1728K(4914688K)] 4767024K-&gt;502240K(16099840K), 0.0093296 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">106.668: [GC (Allocation Failure) [PSYoungGen: 4267200K-&gt;2144K(5001728K)] 4767712K-&gt;503368K(16186880K), 0.0094392 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">108.814: [GC (Allocation Failure) [PSYoungGen: 4383840K-&gt;1696K(4972032K)] 4885064K-&gt;503648K(16157184K), 0.0144723 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">110.894: [GC (Allocation Failure) [PSYoungGen: 4383392K-&gt;1664K(5061632K)] 4885344K-&gt;504400K(16246784K), 0.0094931 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">113.020: [GC (Allocation Failure) [PSYoungGen: 4503168K-&gt;1824K(5031936K)] 5005904K-&gt;505376K(16217088K), 0.0096430 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">115.163: [GC (Allocation Failure) [PSYoungGen: 4503328K-&gt;2400K(5120000K)] 5006880K-&gt;506728K(16305152K), 0.0096150 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">117.324: [GC (Allocation Failure) [PSYoungGen: 4621664K-&gt;2240K(5091328K)] 5125992K-&gt;507384K(16276480K), 0.0097563 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">119.544: [GC (Allocation Failure) [PSYoungGen: 4621504K-&gt;1920K(5175808K)] 5126648K-&gt;507864K(16360960K), 0.0096707 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">121.757: [GC (Allocation Failure) [PSYoungGen: 4733824K-&gt;1728K(5148160K)] 5239768K-&gt;508472K(16333312K), 0.0166801 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.02 secs]</span><br><span class="line">124.013: [GC (Allocation Failure) [PSYoungGen: 4733632K-&gt;4160K(5227008K)] 5240376K-&gt;511728K(16412160K), 0.0110958 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">126.397: [GC (Allocation Failure) [PSYoungGen: 4841024K-&gt;1792K(5201920K)] 5348592K-&gt;512216K(16387072K), 0.0126207 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">128.720: [GC (Allocation Failure) [PSYoungGen: 4838656K-&gt;1664K(5273600K)] 5349080K-&gt;512952K(16458752K), 0.0099746 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">131.062: [GC (Allocation Failure) [PSYoungGen: 4934272K-&gt;2144K(5251072K)] 5445560K-&gt;514256K(16436224K), 0.0136200 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">...</span><br><span class="line">(下略)</span><br></pre></td></tr></table></figure>
<p>…嗯，好像沒啥異狀</p>
<p>一般 JVM 的 GC 分成兩種。一種是效能幾乎沒有影響的 Young GC，也就是上面 log 中每一行顯示的資訊。另一種是會花費大量時間，並且卡住所有 thread 的 Full GC。因此我們這邊主要要找的是 <code>Full GC</code> 的字樣。不過 log 中沒有任何這樣的字樣出現，代表並沒有 Full GC 發生。</p>
<h2 id="找到真正的問題來源"><a href="#找到真正的問題來源" class="headerlink" title="找到真正的問題來源"></a>找到真正的問題來源</h2><p>如果不是 GC 的話，就只能深入找找看到底程式的 Hot Spot 在哪裡。稍早用計時的方式就是一種尋找方式，但是只能針對某個特定的程式碼去找。如果問題並不在明顯的地方的話，就需要大範圍地去找。</p>
<p>這邊我使用 GitHub 上找到的一個很好用的程式：<a target="_blank" rel="noopener" href="https://github.com/jvm-profiling-tools/async-profiler">async-profiler</a>。這個程式能夠利用著名的效能分析工具 <code>perf</code> 來對 Java 的程式進行 profile，並且將蒐集的 profile 資訊統整起來，依照想要的形式匯出。我最喜歡的功能就是把 profile 匯出成 SVG 的互動式圖片來檢視。這個工具曾經幫我找到了很多難解的問題。</p>
<p>這邊我使用 async-profiler 來分別針對剛開始進行資料搬遷的時段與進行了一陣子的時段進行 profile。理論上程式在後面的時段應該是正常的，所以可以作為一個參考點。</p>
<p>蒐集結果如下：</p>
<p><img src="profile-normal.png" alt="Profile - Normal"></p>
<p style='text-align: center'>圖二、效能正常時的 Profile</p>

<p><img src="profile-slow.png" alt="Profile - Slow"></p>
<p style='text-align: center'>圖三、效能異常時的 Profile</p>

<p>上面兩張圖顯示的是每一個 thread 呼叫每一個 method 的頻率，並且以 call stack 的方式顯示。非常地淺顯易懂。(有另一個模式是可以將各個 thread 的結果合併起來觀察，這邊就看各自的需求設定。)</p>
<p>可以看到效能異常的時候有一個區塊明顯地大很多，代表那些 method 的動作耗費了大量的時間。於是我們將這個區域放大 (這也是為什麼我喜歡用這個 profiler)：</p>
<p><img src="profile-slow-enlarge.png" alt="Profile - Slow (Enlarged)"></p>
<p style='text-align: center'>圖四、效能異常時的 Profile (放大黃色區塊)</p>

<p>可以看到裡面有些關鍵字：<code>CompileBroker</code>、<code>C2Compiler</code>、<code>Compiler::Optimize()</code>。</p>
<p>我起初看到這些字以為是 class loader 在讀取程式碼，但針對這些關鍵字搜尋了之後才發現不是。原來這代表的是 just-in-time (JIT) compilation。<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/35601841/how-does-the-jvm-decided-to-jit-compile-a-method-categorize-a-method-as-hot">這篇 Stackoverflow</a> 的解答有稍微解釋 JVM 的 JIT 的運作機制。簡單來說，就是 JVM 觀察了程式碼的使用狀況之後，就會視情況對 Java 的程式進行優化，包括重構程式碼與編譯成機器碼等等。而我們在圖四所觀察到的現象，就是 JVM 在進行 JIT 優化。</p>
<p>但是為什麼是在資料搬遷的開始做呢？</p>
<p>我進一步根據 <a target="_blank" rel="noopener" href="https://www.oracle.com/technical-resources/articles/java/architect-evans-pt1.html">這篇文章</a> 的指示在 JVM 上加上 <code>-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation</code>的參數，讓 JVM 在每次進行 JIT 優化的時候都會將動作輸出到一個 log 檔。</p>
<p>我擷取其中一段：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;task_queued compile_id&#x3D;&#39;4063&#39; compile_kind&#x3D;&#39;osr&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;16765&#39; backedge_count&#x3D;&#39;16765&#39; iicount&#x3D;&#39;16765&#39; osr_bci&#x3D;&#39;13&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;188.930&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;16765&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4064&#39; compile_kind&#x3D;&#39;osr&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;16765&#39; backedge_count&#x3D;&#39;16765&#39; iicount&#x3D;&#39;16765&#39; osr_bci&#x3D;&#39;13&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;188.930&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;16765&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4063&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb350e34dc0&#39; size&#x3D;&#39;8520&#39; address&#x3D;&#39;0x00007fb350e34b10&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5456&#39; scopes_data_offset&#x3D;&#39;5896&#39; scopes_pcs_offset&#x3D;&#39;7696&#39; dependencies_offset&#x3D;&#39;8432&#39; nul_chk_table_offset&#x3D;&#39;8448&#39; oops_offset&#x3D;&#39;5768&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;17033&#39; backedge_count&#x3D;&#39;17033&#39; iicount&#x3D;&#39;17033&#39; stamp&#x3D;&#39;188.931&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4064&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb350edfb00&#39; size&#x3D;&#39;8520&#39; address&#x3D;&#39;0x00007fb350edf850&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5456&#39; scopes_data_offset&#x3D;&#39;5896&#39; scopes_pcs_offset&#x3D;&#39;7696&#39; dependencies_offset&#x3D;&#39;8432&#39; nul_chk_table_offset&#x3D;&#39;8448&#39; oops_offset&#x3D;&#39;5768&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;17033&#39; backedge_count&#x3D;&#39;17033&#39; iicount&#x3D;&#39;17033&#39; stamp&#x3D;&#39;188.932&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4065&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;cache&#x2F;calvin&#x2F;CalvinCacheMgr flush ()V&#39; bytes&#x3D;&#39;110&#39; count&#x3D;&#39;12584&#39; backedge_count&#x3D;&#39;173953&#39; iicount&#x3D;&#39;12584&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;189.122&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;12584&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4066&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;schedule&#x2F;calvin&#x2F;mgcrab&#x2F;CrabbingAnalyzer updateMigrationStatus ()V&#39; bytes&#x3D;&#39;43&#39; count&#x3D;&#39;14336&#39; backedge_count&#x3D;&#39;18551&#39; iicount&#x3D;&#39;14336&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;189.233&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;14336&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4066&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb350ee2820&#39; size&#x3D;&#39;2416&#39; address&#x3D;&#39;0x00007fb350ee2650&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;464&#39; stub_offset&#x3D;&#39;1712&#39; scopes_data_offset&#x3D;&#39;1976&#39; scopes_pcs_offset&#x3D;&#39;2152&#39; dependencies_offset&#x3D;&#39;2376&#39; nul_chk_table_offset&#x3D;&#39;2384&#39; oops_offset&#x3D;&#39;1928&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;schedule&#x2F;calvin&#x2F;mgcrab&#x2F;CrabbingAnalyzer updateMigrationStatus ()V&#39; bytes&#x3D;&#39;43&#39; count&#x3D;&#39;14338&#39; backedge_count&#x3D;&#39;18554&#39; iicount&#x3D;&#39;14338&#39; stamp&#x3D;&#39;189.233&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4067&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;18813&#39; backedge_count&#x3D;&#39;18812&#39; iicount&#x3D;&#39;18813&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;189.484&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;18813&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4068&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;18813&#39; backedge_count&#x3D;&#39;18812&#39; iicount&#x3D;&#39;18813&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;189.484&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;18813&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4067&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb35108c4c0&#39; size&#x3D;&#39;8352&#39; address&#x3D;&#39;0x00007fb35108c210&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5328&#39; scopes_data_offset&#x3D;&#39;5768&#39; scopes_pcs_offset&#x3D;&#39;7552&#39; dependencies_offset&#x3D;&#39;8272&#39; nul_chk_table_offset&#x3D;&#39;8288&#39; oops_offset&#x3D;&#39;5640&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;19084&#39; backedge_count&#x3D;&#39;19084&#39; iicount&#x3D;&#39;19084&#39; stamp&#x3D;&#39;189.485&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4068&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb3514eac80&#39; size&#x3D;&#39;8352&#39; address&#x3D;&#39;0x00007fb3514ea9d0&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5328&#39; scopes_data_offset&#x3D;&#39;5768&#39; scopes_pcs_offset&#x3D;&#39;7552&#39; dependencies_offset&#x3D;&#39;8272&#39; nul_chk_table_offset&#x3D;&#39;8288&#39; oops_offset&#x3D;&#39;5640&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;19084&#39; backedge_count&#x3D;&#39;19084&#39; iicount&#x3D;&#39;19084&#39; stamp&#x3D;&#39;189.486&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4047&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C2&#39; level&#x3D;&#39;4&#39; entry&#x3D;&#39;0x00007fb3519527c0&#39; size&#x3D;&#39;124544&#39; address&#x3D;&#39;0x00007fb351951890&#39; relocation_offset&#x3D;&#39;296&#39; consts_offset&#x3D;&#39;3856&#39; insts_offset&#x3D;&#39;3888&#39; stub_offset&#x3D;&#39;57328&#39; scopes_data_offset&#x3D;&#39;58456&#39; scopes_pcs_offset&#x3D;&#39;113840&#39; dependencies_offset&#x3D;&#39;121376&#39; handler_table_offset&#x3D;&#39;121424&#39; nul_chk_table_offset&#x3D;&#39;122744&#39; oops_offset&#x3D;&#39;58000&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;bench&#x2F;server&#x2F;procedure&#x2F;calvin&#x2F;tpcc&#x2F;NewOrderProc executeSql (Ljava&#x2F;util&#x2F;Map;)V&#39; bytes&#x3D;&#39;1186&#39; count&#x3D;&#39;8134&#39; backedge_count&#x3D;&#39;89191&#39; iicount&#x3D;&#39;8134&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;189.895&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4069&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;bench&#x2F;server&#x2F;procedure&#x2F;calvin&#x2F;tpcc&#x2F;NewOrderProc executeSql (Ljava&#x2F;util&#x2F;Map;)V&#39; bytes&#x3D;&#39;1186&#39; count&#x3D;&#39;8151&#39; backedge_count&#x3D;&#39;89367&#39; iicount&#x3D;&#39;8151&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;189.912&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;8151&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4005&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C2&#39; level&#x3D;&#39;4&#39; entry&#x3D;&#39;0x00007fb351939480&#39; size&#x3D;&#39;39928&#39; address&#x3D;&#39;0x00007fb351938f90&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;1264&#39; stub_offset&#x3D;&#39;17968&#39; scopes_data_offset&#x3D;&#39;18416&#39; scopes_pcs_offset&#x3D;&#39;35904&#39; dependencies_offset&#x3D;&#39;38768&#39; handler_table_offset&#x3D;&#39;38808&#39; nul_chk_table_offset&#x3D;&#39;39312&#39; oops_offset&#x3D;&#39;18048&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;storage&#x2F;tx&#x2F;concurrency&#x2F;ConservativeOrderedCcMgr bookReadKeys (Ljava&#x2F;util&#x2F;Collection;)V&#39; bytes&#x3D;&#39;80&#39; count&#x3D;&#39;27968&#39; backedge_count&#x3D;&#39;200693&#39; iicount&#x3D;&#39;27968&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;190.118&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4035&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C2&#39; level&#x3D;&#39;4&#39; entry&#x3D;&#39;0x00007fb3513c45c0&#39; size&#x3D;&#39;114552&#39; address&#x3D;&#39;0x00007fb3513c3150&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;5232&#39; stub_offset&#x3D;&#39;67120&#39; scopes_data_offset&#x3D;&#39;68280&#39; scopes_pcs_offset&#x3D;&#39;105400&#39; dependencies_offset&#x3D;&#39;111416&#39; handler_table_offset&#x3D;&#39;111456&#39; nul_chk_table_offset&#x3D;&#39;113520&#39; oops_offset&#x3D;&#39;67656&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;bench&#x2F;server&#x2F;procedure&#x2F;calvin&#x2F;tpcc&#x2F;NewOrderProc prepareKeys (Lorg&#x2F;elasql&#x2F;schedule&#x2F;calvin&#x2F;ReadWriteSetAnalyzer;)V&#39; bytes&#x3D;&#39;682&#39; count&#x3D;&#39;14703&#39; backedge_count&#x3D;&#39;161383&#39; iicount&#x3D;&#39;14703&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;190.153&#39;&#x2F;&gt;</span><br></pre></td></tr></table></figure>
<p>后里蟹… 它到底優化了多少 method 啊…</p>
<p>從 <code>compile_id</code> 這項資訊可以看的出來少說有 4068 以上的 method 被進行了 JIT 優化。而且優化主要發生在兩個時間點。第一個是程式剛啟動的時候，這點很合理。另一個就是資料搬遷開始的時候。</p>
<p>從它優化的 method 名稱來看，可以推斷出原因應該是因為當資料搬遷開始之後，一堆不常被呼叫的 method 突然被大量呼叫。因此觸發了 JVM 的 JIT 優化機制。</p>
<p>不過至少是找到問題的源頭了。</p>
<h2 id="解決辦法"><a href="#解決辦法" class="headerlink" title="解決辦法"></a>解決辦法</h2><p>這樣就有幾個解決辦法：</p>
<ol>
<li>想辦法讓程式在開始資料搬遷之前就觸發 JIT 機制，避免在蒐集實驗數據時發生</li>
<li>關閉 JIT 功能</li>
<li>放置不管</li>
</ol>
<p>法一應該是最合理的作法，這樣就能保有 JIT 的好處，同時也可以避免實驗數據受到 JIT 影響。然而實際上要進行法一需要根據程式的設計來判斷最適當的做法。例如以我們的狀況來說可能就要進行兩次資料搬遷，讓第一次作為暖身，第二次再開始蒐集實驗數據。不過因為我們系統是一個分散式系統的架構，其內部運作又非常複雜，一旦搬出去的東西就很難搬回來。雖然不是辦不到，但要完成的複雜度太高。</p>
<p>不過如果這篇文章的讀者手上的程式相對沒那麼複雜的話，法一應該是最合理的作法。</p>
<p>因此接下來只能試試看法二。根據 <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/38721235/what-exactly-does-xx-tieredcompilation-do">這篇文章</a> 的分享，可以透過在 JVM 啟動時設定 <code>-XX:TieredStopAtLevel=n</code> 這個參數來決定要將 JIT 執行到甚麼程度。預設是執行到最高的 Level 4 的程度。</p>
<p>我首先測試將 JIT 設定為 Level 1 是否有效 (即設定 <code>-XX:TieredStopAtLevel=1</code>)：</p>
<p><img src="scaleout-ex-mgcrab-disable-c2.png" alt="Scale-out Experiment - MgCrab (C2 Disabled)"></p>
<p style='text-align: center'>圖五、預設設定與 Level 1 設定在 Throughput 總合的比較，為了方便比較，我把三個 server 的產出合併為一條線。這個圖沒有跑到資料搬遷結束</p>

<p>…嗯，確實是沒有下墜了，但效能整體也變低不少。</p>
<p>我好奇不同的設定下的效能差異會差到多少，所以嘗試了 Level 0 ~ 4：</p>
<p><img src="scaleout-ex-mgcrab-jit.png" alt="Scale-out Experiment - MgCrab (JIT Level Comparison)"></p>
<p style='text-align: center'>圖六、比較使用不同的 JIT Level 對 MgCrab 實驗的效能影響</p>

<p>真詭異，Level 1 竟然是第二高的辦法。雖然我不是很懂 JIT 的邏輯，但是顯然 Level 不是設定越高越好。而且 Level 4 雖然中間會跌下去一下，但這個代價顯然是值得的。</p>
<p>在知道了不同 Level 帶來的影響之後，最後就是要根據展示這個實驗的需求選擇最適合的設定。因為我們的實驗要展現的是極致的效能，因此我們最後應該是會選擇保留 JIT Level 4 的設定。並且需要的時候加註說明表示短暫的下跌是由於 JIT 造成的現象。</p>
<p>至於為什麼之前論文發表時沒有觀察到這個現象呢？比較一下之前的實驗結果發現：因為當時系統的效能還不算太好，很有可能是當時程式優化不足，讓機器的 CPU 使用率並沒有滿載。因此受到 JIT 影響的程度並不劇烈。雖然當時可能也發生了相同問題，但是在 CPU 沒有完全滿載的情況下問題就不太顯著。</p>
<p>所以我最後決定放置不管，將之視為合理的代價。</p>
<p>結案。</p>
</div><div id="disqus_thread"><script>var disqus_shortname = 'slmtsblog';
var disqus_identifier = '2021/06/07/java-note-drop-due-to-jit/';
var disqus_title = 'Java 筆記 (1) - 探究 JVM 對自製系統造成的效能問題';
var disqus_url = 'http://www.slmt.tw/blog/2021/06/07/java-note-drop-due-to-jit/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script></div></div><div id="footer"><p>&copy; Yu-shan Lin (SLMT) and SLMT's Blog, 2016-2021</p></div></div></body></html>