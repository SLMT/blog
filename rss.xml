<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SLMT&#39;s Blog</title>
  
  
  <link href="http://www.slmt.tw/blog/rss.xml" rel="self"/>
  
  <link href="http://www.slmt.tw/blog/"/>
  <updated>2022-04-25T08:49:17.096Z</updated>
  <id>http://www.slmt.tw/blog/</id>
  
  <author>
    <name>SLMT</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>千里馬計畫歷程分享 Part 4 - 撰寫研究計劃書</title>
    <link href="http://www.slmt.tw/blog/2021/07/18/uchicago-exchange-part-4/"/>
    <id>http://www.slmt.tw/blog/2021/07/18/uchicago-exchange-part-4/</id>
    <published>2021-07-18T07:53:35.000Z</published>
    <updated>2022-04-25T08:49:17.096Z</updated>
    
    <content type="html"><![CDATA[<p>研究計劃書是申請千里馬計畫的必備文件之一，而且我個人認為應該是是否能夠申請上計畫的關鍵。因此這次就來分享一些我個人撰寫的方式，以及我認為重要的要點吧！</p><a id="more"></a><h2 id="關於我到目前-2021-07-17-為止的千里馬計畫狀態"><a href="#關於我到目前-2021-07-17-為止的千里馬計畫狀態" class="headerlink" title="關於我到目前 (2021/07/17) 為止的千里馬計畫狀態"></a>關於我到目前 (2021/07/17) 為止的千里馬計畫狀態</h2><p>首先先更新一下我個人目前的千里馬計畫狀態。</p><p>距離上一篇已經過了一年了，雖然在這一年之間許多種類的 COVID-19 疫苗已經接連推出，但是由於美國疫情到現在都還沒有完全解決，當初申請上的芝加哥大學遲遲不願意開放交換生前往 (校方表示最快也要 2021 年 10 月才能前往)。</p><p>考慮了我已經延後了超過一年的時間，為了自己的人生規劃，我最後決定放棄這次交換，並已經在準備走畢業流程，待找工作的時候再以國外工作為優先考量。</p><p>雖然很可惜，但是申請過程中也獲得了不少經驗，因此相信撰寫這些分享文章應該也能多少幫助到其他申請者。</p><h2 id="研究計劃書的格式"><a href="#研究計劃書的格式" class="headerlink" title="研究計劃書的格式"></a>研究計劃書的格式</h2><p>研究計劃書的格式規定在「科技部補助博士生赴國外研究作業要點」之中，規定每年可能會隨時更新，所以並不一定格式都會與我相同。</p><p>在我申請的時候，研究計劃書的格式並沒有詳盡的規定，只簡要地說明須包含以下幾個項目：</p><ul><li>摘要</li><li>近五年研究與工作經驗和成果</li><li>研究計畫的背景、目的、研究方法與重要性</li><li>擬前往國外研究機構（得含指導教授）之學術成就與完成研究構想之相關性</li><li>預期完成工作與具體成果與未來工作之關係</li></ul><p>另外只有規定檔案須為 A4 紙二十頁以內之 PDF 檔，檔案大小不得超過 5MB。注意因為規定可能會修改，希望大家還是再自己確認一下申請當下的規定。這邊講一下我最後計畫書是含參考文獻共 17 頁。</p><h3 id="核心要點：強調連結與影響力"><a href="#核心要點：強調連結與影響力" class="headerlink" title="核心要點：強調連結與影響力"></a>核心要點：強調連結與影響力</h3><p>我認為科技部研擬的千里馬計畫的其中一個重要目標，就是要拓展台灣學界與國外學術圈的交流。而且這個交流最好是長久且可以持續的交流。因此我相信科技部的審核人員在閱讀計畫書的時候，應該會詳加考慮申請人是否可以透過這次交換達到持續且有益於台灣學界的交流。</p><p>另外，前往交流的機構與當地的指導教授等等也很重要。如果前往交換的機構或教授頗具名望，那就可以預期核准這個交換可以增加台灣學界與這些機構和教授的連結。</p><p>當然，以上這些都必須要自己寫在計畫書裡面。我們不能預期審核我們計畫書的人一定能夠理解我們所處領域的狀況，就算交換當地的指導教授是諾貝爾獎或圖靈獎得主，審核人也不見會馬上注意到這件事情。因此我認為在最後計劃書的最後兩章之中特別強調交換研究對台灣學界的幫助，以及未來如何延續這樣的連結都是很具有加分效果的。</p><h2 id="我的撰寫邏輯"><a href="#我的撰寫邏輯" class="headerlink" title="我的撰寫邏輯"></a>我的撰寫邏輯</h2><p>接下來我分享一下我自己的計畫書上針對每一個章節的撰寫方式。</p><h3 id="近五年的研究與工作表現"><a href="#近五年的研究與工作表現" class="headerlink" title="近五年的研究與工作表現"></a>近五年的研究與工作表現</h3><p>這個章節不難，就是誠實地列出相關表現，只是問題是要呈現哪些資訊。我當時參考了另一位曾經申請到千里馬計畫的博生生朋友，列出了以下幾個類型的表現：</p><ul><li>已發表論文清單<ul><li>雖然會另外附上學術論文清單，但我覺得多強調一下學術成就應該不是壞事</li></ul></li><li>參與過的研究計畫清單<ul><li>我曾經協助我在台灣的指導教授撰寫科技部計畫書，因此知道科技部在審核專案計畫時會考慮申請人之前是否曾經有被核准或者參與過其他專案計畫的經驗。所以我相信列出參與過的計畫應該也有加分效果。</li><li>另外列的時候可以不只列出科技部的，還可以盡可能列出其他部會或者產學合作的計畫。</li></ul></li><li>教學經驗列表<ul><li>這點是參考我的博士生朋友列的。因為我跟他在學校都有豐富的教學經驗，包括擔任講師與助教等等，因此有很多豐富的經驗可以寫。</li></ul></li></ul><h3 id="研究計畫內容"><a href="#研究計畫內容" class="headerlink" title="研究計畫內容"></a>研究計畫內容</h3><p>這個章節基本上就是靠大家發揮平日撰寫論文的能力，把預計要在國外進行的研究的前因後果與方法寫清楚。這邊我列出幾點我覺得重要的要點：</p><h4 id="先補充一下研究領域的背景知識"><a href="#先補充一下研究領域的背景知識" class="headerlink" title="先補充一下研究領域的背景知識"></a>先補充一下研究領域的背景知識</h4><p>就算提出申請的時候會填寫學門，但是審核人的專業背景並不一定完全跟申請人一樣，所以一開始可能要先補充一些理解研究問題的背景知識。例如我的研究是屬於資訊工程之中的分散式資料庫系統領域，但是審核人可能雖然是資訊工程專業，但不見得可以理解分散式的資料庫系統與一般資料庫系統的差異在哪。因此我一開始先用一些篇幅說明資料庫系統的發展脈絡，幫助審核人釐清分散式資料庫系統的難點在哪裡。</p><h4 id="最好有例子或圖表說明研究方法"><a href="#最好有例子或圖表說明研究方法" class="headerlink" title="最好有例子或圖表說明研究方法"></a>最好有例子或圖表說明研究方法</h4><p>這個應該算是撰寫論文的小技巧。有常常投遞論文的人應該瞭解利用例子跟概念性的圖表都有助於幫助讀者理解研究方法。</p><h4 id="可以先提供一些初步研究成果"><a href="#可以先提供一些初步研究成果" class="headerlink" title="可以先提供一些初步研究成果"></a>可以先提供一些初步研究成果</h4><p>這點跟一般寫論文不太一樣，因為一般論文都是成果都完成了才開始撰寫。然而計劃書卻是要提出預計要做的事情，因此通常不會包含研究成果。不過如果可以的話，最好先加上一些先期研究成果，這些成果可以是之前相關且自己做出來的研究成果，或者是關於預計要進行研究之中可能先開始做的成果。這些成果都可以幫助審核人瞭解研究的可行性。假若今天要從兩篇看起來相似的計劃書中挑選一個核准，那當然會選擇已經有初步成果，看起來比較有機會做出來的這邊囉！</p><h4 id="強調研究的影響力"><a href="#強調研究的影響力" class="headerlink" title="強調研究的影響力"></a>強調研究的影響力</h4><p>研究計畫的成果預期帶來的影響力也是很重要的。這點跟一般寫論文時類似，也就是想要解決的問題應該是大家關心，而且會在該領域造成影響的問題。因為千里馬計畫又強調是要增加學術圈的連結，計劃本身能夠帶來甚麼樣的影響，相信也是審查的一大要點。</p><h4 id="注意格式的簡潔"><a href="#注意格式的簡潔" class="headerlink" title="注意格式的簡潔"></a>注意格式的簡潔</h4><p>這是我個人撰寫比較正式的文件的習慣。簡單來說就是盡可能地用最少的格式變化，但同時保留區分標題與內文這些必要格式變化。平常常在撰寫論文的話，應該是就照平常寫論文的習慣即可。不過因為我自己寫計畫書時並非使用平常寫論文的編輯器，而是使用 Microsoft Word，所以會特別注意一下文字的格式。</p><p>我看過很多人的報告在撰寫的時候，都會在文字上使用大量不同的色彩，同時許多地方的用詞也都沒有統一。舉例來說，可能前面呈現一張圖的時候寫「Figure 1」，但是後面第二張圖則變成了「圖二」。如果被我審到這樣的文件，我馬上會判定這個人不夠細心。在文字的格式上，也常看到許多人前後使用的字體大小不一，以及字型也不同的情況。</p><p>這邊我列出幾點自己的格式習慣給大家參考：</p><ul><li>所有文字一律使用相同字型 (只要看起來正式的字型就好，我個人是用標楷體)</li><li>內文除了標題之外，文字大小一律大小設定為 12</li><li>標題必須能夠明確看出階層架構<ul><li>這邊有兩種做法，一種是越主要的標題字體越大，或者用前面的數字來標註。例如第三章前面寫「3」，而下面的第兩節用「3.2」，在其中的第一小節用「3.2.1」，然後後面再跟隨標題文字。</li><li>我自己兩種做法混用。除了使用數字的階層之外，第一層的標題字體會用粗體而且放大，第二層以下的標題只有用粗體但是大小與內文相同。</li></ul></li><li>除了圖表之外，一律用黑色字體</li><li>明確標出頁碼</li><li>重點只用粗體標記</li></ul><p>格式的使用習慣越一致，閱讀的人看起來就會越舒服。而且也比較能掌握格式變化的邏輯。例如重點只用粗體標記，而不同時使用不同顏色標註，這樣別人就不用特別去解讀不同顏色所代表的意義。</p><h3 id="國外研究機構之學術成就與計畫構想之相關性"><a href="#國外研究機構之學術成就與計畫構想之相關性" class="headerlink" title="國外研究機構之學術成就與計畫構想之相關性"></a>國外研究機構之學術成就與計畫構想之相關性</h3><p>關於這個部分，就跟上面說的類似，應該會是重點審查的一個部分。我在這個章節強調了兩個要點：</p><ol><li>當地指導教授在學術上的成就與人脈</li><li>我的研究計畫與該教授的主力研究的關係</li></ol><p>前者主要是強調藉由與他合作，便可加強台灣學術圈在國外的人脈。後者則主要是強調我的研究如何跟他的研究有關，這樣才能說明為什麼他會對我的研究有興趣，進而增進兩方的關係。</p><h3 id="預期完成工作與未來工作之關係"><a href="#預期完成工作與未來工作之關係" class="headerlink" title="預期完成工作與未來工作之關係"></a>預期完成工作與未來工作之關係</h3><p>這個部分可能是要看千里馬計畫到底對未來個人甚至對台灣會甚麼幫助，不過我猜想這章應該是對預期未來要在研究機構擔任教職或研究人員的人會比較有用，因為這樣學術圈的交流才比較容易延續。</p><p>我個人因為未來規畫是要進入業界服務，所以比較難寫說可以利用千里馬計畫回饋學界。不過若是未來計畫要進入業界，也可以強調對台灣的業界，甚至到世界有甚麼樣的影響。如果能夠看出研究的成果可以增進世界產業的發展，那我相信也會被認定為價值很高的研究。</p><h2 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h2><p>以上大概就是我撰寫計畫申請書的要點，最近應該很接近明年計畫申請的到期日，相信應該有不少人正在努力撰寫計畫書。因此希望這些分享對大家有幫助！祝各位申請計畫順利！</p><h2 id="我的全部時間軸"><a href="#我的全部時間軸" class="headerlink" title="我的全部時間軸"></a>我的全部時間軸</h2><p>以下紀錄從決定申請到現在為止發生的重要事件：</p><ul><li>2019/5 月中旬 - 決定申請千里馬計畫</li><li>2019/6/1 - 科技部系統開放申請</li><li>2019/6/9 - 跟指導老師討論要前往哪一位教授的 lab</li><li>2019/6/12 - 報名 TOEFL iBT 考試</li><li>2019/6/29 - TOEFL iBT 應考</li><li>2019/7/8 - 決定要前往的實驗室與連絡上國外的教授<ul><li>從研究要去哪間研究室到這步驟拖了點時間，因為當時正在忙著投一篇論文。 這也是為什麼要提早找教授，不然跟我一樣卡個論文 deadline 就可能會 delay。</li></ul></li><li>2019/7/9 - TOEFL iBT 開放線上查成績（總成績：93）</li><li>2019/7/18 - 與國外教授線上面談</li><li>2019/7/30 - 收到國外教授的接受函（超驚險）</li><li>2019/7/30 - 送出申請，並由校內統合送出</li><li>2019/11/29 - 科技部官網公布 <a href="https://www.most.gov.tw/folksonomy/detail?subSite=&l=ch&article_uid=342f7b32-5bc4-4885-9607-32d946c067cc&menu_id=d3c30297-bb63-44c5-ad30-38a65b203288">通過名冊</a></li><li>2019/12/4 - 通知國外指導教授並開始申請 DS-2019 (申請美國簽證必備文件)</li><li>2019/12/26 - 參加芝加哥大學英文能力測驗 (APEA)</li><li>2020/1/7 - 收到芝加哥大學通知通過 APEA 測驗，並完成 DS-2019 申請</li><li>2020/1/16 - 收到 DS-2019</li><li>2020/1/21 - 送出校內簽約資料，以申請補助款<ul><li>這個需要付 DS-2019 的副本，加上我到 1/18 都不在台灣。 所以拖到這個時候才提出申請。</li></ul></li><li>2020/1/29 - 填寫 DS-160 以申請簽證</li><li>2020/2/3 - 到郵局完成簽證費繳費，並預約 AIT 面試時間</li><li>2020/2/18 - 到台北內湖 AIT 進行面試，當場收取護照</li><li>2020/2/20 - 收到護照並附上 J-1 Visa</li><li>2020/3/13 - 收到芝加哥大學通知，因為 COVID-19 疫情的關係，延後所有交換計畫</li><li>2021/2/18 - 收到校方通知表示因為疫情尚未緩解，最快要到 2021 十月才能重啟交換</li><li>2021/2/20 - 與當地指導教授討論之後決定放棄交換，決定先以博士畢業為優先考量</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;研究計劃書是申請千里馬計畫的必備文件之一，而且我個人認為應該是是否能夠申請上計畫的關鍵。因此這次就來分享一些我個人撰寫的方式，以及我認為重要的要點吧！&lt;/p&gt;</summary>
    
    
    
    <category term="Exchange" scheme="http://www.slmt.tw/blog/categories/exchange/"/>
    
    
    <category term="usa" scheme="http://www.slmt.tw/blog/tags/usa/"/>
    
    <category term="exchange" scheme="http://www.slmt.tw/blog/tags/exchange/"/>
    
    <category term="uchicago" scheme="http://www.slmt.tw/blog/tags/uchicago/"/>
    
  </entry>
  
  <entry>
    <title>Java 筆記 (1) - 探究 JVM 對自製系統造成的效能問題</title>
    <link href="http://www.slmt.tw/blog/2021/06/07/java-note-drop-due-to-jit/"/>
    <id>http://www.slmt.tw/blog/2021/06/07/java-note-drop-due-to-jit/</id>
    <published>2021-06-07T08:46:40.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>最近在使用實驗室開發的 <a href="https://github.com/elasql/elasql">ElaSQL 分散式資料庫系統</a> 進行實驗時，發現系統效能在某個時間點會有突然下墜的情況。 因此這篇文章分享一下調查下墜原因的過程，以及可能的應對措施。</p><a id="more"></a><h2 id="發現問題"><a href="#發現問題" class="headerlink" title="發現問題"></a>發現問題</h2><p>最近正在整理之前 <a href="https://dl.acm.org/doi/10.14778/3303753.3303764">發表的論文</a> 的程式碼，以提供其他研究團隊進行後續的研究。</p><p>該論文主要是研究如何在分散式的先決式資料庫系統 (Deterministic Database System) 上一邊搬移資料的同時避免去影響到系統效能。</p><p>實驗的時候有很多情境要測試。其中一個測試是啟動一個包含三台 server 的分散式資料庫系統，讓第一台 server 的負載超過它能處理的能力，第二台 server 則處理適量的負載，第三台機器則作為預備 server，一開始不包含任何資料，也不處理任何使用者請求。此時系統在發現第一台 server 負載過高時，就會下達一個指示將第一台 server 的部分資料搬移到第三台 server，並且讓第三台 server 加入處理使用者請求。實驗過程我們會記錄效能的變化，以觀察效能是否有受到資料搬遷的影響。</p><p>因此最近我在我們最新版的系統上面重現了這組實驗：</p><p><img src="scaleout-ex-mgcrab.png" alt="Scale-out Experiment - MgCrab"></p><p style='text-align: center'>圖一、我們提出的方法 (MgCrab) 的實驗結果</p><p>圖的 X 軸代表時間軸，Y 軸代表每一台 server 每五秒處理的 transaction (Relational DBMS 處理請求的單位) 數量，資料搬遷發生在第 115 秒到 325 秒之間。</p><p>基本上結果看起來非常好，其中 Server 2 (第三台 server) 的效能飛起代表它具備足夠的資料開始處理使用者請求，而且效能也沒受到甚麼影響… </p><p>除了一個地方之外。</p><p>在第 115 ~ 125 秒之間，系統效能神秘地下墜了一下。這點是我們之前沒有觀察到的狀況，因此勾起了我的好奇。</p><h2 id="各種碰壁"><a href="#各種碰壁" class="headerlink" title="各種碰壁"></a>各種碰壁</h2><p>首先我考慮了一下系統在那個時間點是否出現了甚麼變化。第一個在我腦中顯現的就是系統在當時開始了資料搬遷的動作，然而這個下墜並沒有持續到資料搬遷結束，而只是在開始的前十秒下墜而已。顯然並不是資料搬遷本身造成的。</p><p>接著我思考了有甚麼東西會在資料搬遷的初始期才會存在。後來我想到可能是初始化資料搬遷的動作造成的影響。</p><p>為了要讓資料搬遷順利進行，在資料搬遷剛開始的瞬間，系統會進行一個準備作業。包括確定搬遷計畫的內容，要搬動的資料範圍等等。然而這些程式碼實際上並沒有太多工作要做，因此我對這項可能性感到懷疑。不過我暫時想不到其他可能性，所以還是先對該段程式碼進行計時 (這邊使用 <code>java.lang.System.nanoTime()</code> 進行)。</p><p>計時之後的結果令我感到訝異，該段準備工作竟然會耗費大概 5 ~ 30 ms 不等的時間。這段時間雖然看起來不多，但要知道對資料庫系統這種高效能系統來說其實是非常長的。我們系統其實處理一筆包含 10 個 SQL 的 transaction (假設資料都在同一台電腦上) ，從收到指令、解析、Query 優化、Index 搜尋、讀取資料表、序列化結果並回報使用者等等，也只要大概 5 ms 左右的時間而已。特別是該段程式碼又在系統一個重要的處理元件中，如果花太久時間鐵定會造成整體效能的下降。</p><p>為了找出確切是哪一段程式碼出拖慢效能，我進一步將該段程式碼分割成多份，並對每一段程式碼計時。然而結果卻令人失望。因為結果顯示每一段程式碼都分別花費差不多的時間。換句話說，沒有一個真正慢的地方，而是大家都很慢。</p><h2 id="難道是垃圾回收-GC-？"><a href="#難道是垃圾回收-GC-？" class="headerlink" title="難道是垃圾回收 (GC)？"></a>難道是垃圾回收 (GC)？</h2><p>中間我稍事休息一下，重新思考甚麼樣的動作可能會造成大家都變慢。後來得到一個結論，應該是 Java Virtual Machine (JVM) 搞得鬼。</p><p>JVM 是執行 Java 的必要程式，有時候它背後會做一些事情造成前景的程式變慢，這個時候就會造成大家都變慢的假象。我們的研究為了避免花太多時間在處理記憶體的問題，因此選擇了 Java 這種有 Garbage Collection (GC) 機制的語言作為開發語言。但是代價是效能會稍慢於 C/C++ 與 Rust 這種精確掌控記憶體的語言，而且背後有時候會因為 GC 而卡住。</p><p>為了確定是否是 GC 造成的問題，我在 JVM 啟動時加入了 <code>-verbose:gc -Xloggc:gc.log -XX:+PrintGCTimeStamps -XX:+PrintGCDetails</code> 的參數。這組參數可以讓 JVM 在每次 GC 的時候輸出一條 log 到 <code>gc.log</code> 檔案。因此如果有甚麼異狀就可以馬上知道。</p><p>我滿懷期待的心情，想說終於要抓到這個壞蛋了。打開了 <code>gc.log</code> 檔：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Java HotSpot(TM) 64-Bit Server VM (25.211-b12) for linux-amd64 JRE (1.8.0_211-b12), built on Apr  1 2019 20:39:34 by &quot;java_re&quot; with gcc 7.3.0</span><br><span class="line">Memory: 4k page, physical 32675496k(16773680k free), swap 4079612k(3923452k free)</span><br><span class="line">CommandLine flags: -XX:InitialHeapSize&#x3D;17179869184 -XX:MaxHeapSize&#x3D;17179869184 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC</span><br><span class="line">...</span><br><span class="line">(中略)</span><br><span class="line">...</span><br><span class="line">92.842: [GC (Allocation Failure) [PSYoungGen: 4040512K-&gt;1728K(4813824K)] 4535064K-&gt;496968K(15998976K), 0.0091350 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">94.758: [GC (Allocation Failure) [PSYoungGen: 4040384K-&gt;1728K(4843520K)] 4535624K-&gt;497728K(16028672K), 0.0092166 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">96.690: [GC (Allocation Failure) [PSYoungGen: 4080832K-&gt;1568K(4827648K)] 4576832K-&gt;498288K(16012800K), 0.0160904 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.02 secs]</span><br><span class="line">98.667: [GC (Allocation Failure) [PSYoungGen: 4080672K-&gt;2560K(4888064K)] 4577392K-&gt;499976K(16073216K), 0.0099236 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">100.644: [GC (Allocation Failure) [PSYoungGen: 4162560K-&gt;1920K(4864000K)] 4659976K-&gt;501032K(16049152K), 0.0099665 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">102.635: [GC (Allocation Failure) [PSYoungGen: 4161920K-&gt;1728K(4942848K)] 4661032K-&gt;501552K(16128000K), 0.0094264 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">104.654: [GC (Allocation Failure) [PSYoungGen: 4267200K-&gt;1728K(4914688K)] 4767024K-&gt;502240K(16099840K), 0.0093296 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">106.668: [GC (Allocation Failure) [PSYoungGen: 4267200K-&gt;2144K(5001728K)] 4767712K-&gt;503368K(16186880K), 0.0094392 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">108.814: [GC (Allocation Failure) [PSYoungGen: 4383840K-&gt;1696K(4972032K)] 4885064K-&gt;503648K(16157184K), 0.0144723 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">110.894: [GC (Allocation Failure) [PSYoungGen: 4383392K-&gt;1664K(5061632K)] 4885344K-&gt;504400K(16246784K), 0.0094931 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">113.020: [GC (Allocation Failure) [PSYoungGen: 4503168K-&gt;1824K(5031936K)] 5005904K-&gt;505376K(16217088K), 0.0096430 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">115.163: [GC (Allocation Failure) [PSYoungGen: 4503328K-&gt;2400K(5120000K)] 5006880K-&gt;506728K(16305152K), 0.0096150 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">117.324: [GC (Allocation Failure) [PSYoungGen: 4621664K-&gt;2240K(5091328K)] 5125992K-&gt;507384K(16276480K), 0.0097563 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">119.544: [GC (Allocation Failure) [PSYoungGen: 4621504K-&gt;1920K(5175808K)] 5126648K-&gt;507864K(16360960K), 0.0096707 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">121.757: [GC (Allocation Failure) [PSYoungGen: 4733824K-&gt;1728K(5148160K)] 5239768K-&gt;508472K(16333312K), 0.0166801 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.02 secs]</span><br><span class="line">124.013: [GC (Allocation Failure) [PSYoungGen: 4733632K-&gt;4160K(5227008K)] 5240376K-&gt;511728K(16412160K), 0.0110958 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">126.397: [GC (Allocation Failure) [PSYoungGen: 4841024K-&gt;1792K(5201920K)] 5348592K-&gt;512216K(16387072K), 0.0126207 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">128.720: [GC (Allocation Failure) [PSYoungGen: 4838656K-&gt;1664K(5273600K)] 5349080K-&gt;512952K(16458752K), 0.0099746 secs] [Times: user&#x3D;0.04 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">131.062: [GC (Allocation Failure) [PSYoungGen: 4934272K-&gt;2144K(5251072K)] 5445560K-&gt;514256K(16436224K), 0.0136200 secs] [Times: user&#x3D;0.05 sys&#x3D;0.00, real&#x3D;0.01 secs]</span><br><span class="line">...</span><br><span class="line">(下略)</span><br></pre></td></tr></table></figure><p>…嗯，好像沒啥異狀</p><p>一般 JVM 的 GC 分成兩種。一種是效能幾乎沒有影響的 Young GC，也就是上面 log 中每一行顯示的資訊。另一種是會花費大量時間，並且卡住所有 thread 的 Full GC。因此我們這邊主要要找的是 <code>Full GC</code> 的字樣。不過 log 中沒有任何這樣的字樣出現，代表並沒有 Full GC 發生。</p><h2 id="找到真正的問題來源"><a href="#找到真正的問題來源" class="headerlink" title="找到真正的問題來源"></a>找到真正的問題來源</h2><p>如果不是 GC 的話，就只能深入找找看到底程式的 Hot Spot 在哪裡。稍早用計時的方式就是一種尋找方式，但是只能針對某個特定的程式碼去找。如果問題並不在明顯的地方的話，就需要大範圍地去找。</p><p>這邊我使用 GitHub 上找到的一個很好用的程式：<a href="https://github.com/jvm-profiling-tools/async-profiler">async-profiler</a>。這個程式能夠利用著名的效能分析工具 <code>perf</code> 來對 Java 的程式進行 profile，並且將蒐集的 profile 資訊統整起來，依照想要的形式匯出。我最喜歡的功能就是把 profile 匯出成 SVG 的互動式圖片來檢視。這個工具曾經幫我找到了很多難解的問題。</p><p>這邊我使用 async-profiler 來分別針對剛開始進行資料搬遷的時段與進行了一陣子的時段進行 profile。理論上程式在後面的時段應該是正常的，所以可以作為一個參考點。</p><p>蒐集結果如下：</p><p><img src="profile-normal.png" alt="Profile - Normal"></p><p style='text-align: center'>圖二、效能正常時的 Profile</p><p><img src="profile-slow.png" alt="Profile - Slow"></p><p style='text-align: center'>圖三、效能異常時的 Profile</p><p>上面兩張圖顯示的是每一個 thread 呼叫每一個 method 的頻率，並且以 call stack 的方式顯示。非常地淺顯易懂。(有另一個模式是可以將各個 thread 的結果合併起來觀察，這邊就看各自的需求設定。)</p><p>可以看到效能異常的時候有一個區塊明顯地大很多，代表那些 method 的動作耗費了大量的時間。於是我們將這個區域放大 (這也是為什麼我喜歡用這個 profiler)：</p><p><img src="profile-slow-enlarge.png" alt="Profile - Slow (Enlarged)"></p><p style='text-align: center'>圖四、效能異常時的 Profile (放大黃色區塊)</p><p>可以看到裡面有些關鍵字：<code>CompileBroker</code>、<code>C2Compiler</code>、<code>Compiler::Optimize()</code>。</p><p>我起初看到這些字以為是 class loader 在讀取程式碼，但針對這些關鍵字搜尋了之後才發現不是。原來這代表的是 just-in-time (JIT) compilation。<a href="https://stackoverflow.com/questions/35601841/how-does-the-jvm-decided-to-jit-compile-a-method-categorize-a-method-as-hot">這篇 Stackoverflow</a> 的解答有稍微解釋 JVM 的 JIT 的運作機制。簡單來說，就是 JVM 觀察了程式碼的使用狀況之後，就會視情況對 Java 的程式進行優化，包括重構程式碼與編譯成機器碼等等。而我們在圖四所觀察到的現象，就是 JVM 在進行 JIT 優化。</p><p>但是為什麼是在資料搬遷的開始做呢？</p><p>我進一步根據 <a href="https://www.oracle.com/technical-resources/articles/java/architect-evans-pt1.html">這篇文章</a> 的指示在 JVM 上加上 <code>-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation</code>的參數，讓 JVM 在每次進行 JIT 優化的時候都會將動作輸出到一個 log 檔。</p><p>我擷取其中一段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;task_queued compile_id&#x3D;&#39;4063&#39; compile_kind&#x3D;&#39;osr&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;16765&#39; backedge_count&#x3D;&#39;16765&#39; iicount&#x3D;&#39;16765&#39; osr_bci&#x3D;&#39;13&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;188.930&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;16765&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4064&#39; compile_kind&#x3D;&#39;osr&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;16765&#39; backedge_count&#x3D;&#39;16765&#39; iicount&#x3D;&#39;16765&#39; osr_bci&#x3D;&#39;13&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;188.930&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;16765&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4063&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb350e34dc0&#39; size&#x3D;&#39;8520&#39; address&#x3D;&#39;0x00007fb350e34b10&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5456&#39; scopes_data_offset&#x3D;&#39;5896&#39; scopes_pcs_offset&#x3D;&#39;7696&#39; dependencies_offset&#x3D;&#39;8432&#39; nul_chk_table_offset&#x3D;&#39;8448&#39; oops_offset&#x3D;&#39;5768&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;17033&#39; backedge_count&#x3D;&#39;17033&#39; iicount&#x3D;&#39;17033&#39; stamp&#x3D;&#39;188.931&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4064&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb350edfb00&#39; size&#x3D;&#39;8520&#39; address&#x3D;&#39;0x00007fb350edf850&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5456&#39; scopes_data_offset&#x3D;&#39;5896&#39; scopes_pcs_offset&#x3D;&#39;7696&#39; dependencies_offset&#x3D;&#39;8432&#39; nul_chk_table_offset&#x3D;&#39;8448&#39; oops_offset&#x3D;&#39;5768&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;17033&#39; backedge_count&#x3D;&#39;17033&#39; iicount&#x3D;&#39;17033&#39; stamp&#x3D;&#39;188.932&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4065&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;cache&#x2F;calvin&#x2F;CalvinCacheMgr flush ()V&#39; bytes&#x3D;&#39;110&#39; count&#x3D;&#39;12584&#39; backedge_count&#x3D;&#39;173953&#39; iicount&#x3D;&#39;12584&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;189.122&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;12584&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4066&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;schedule&#x2F;calvin&#x2F;mgcrab&#x2F;CrabbingAnalyzer updateMigrationStatus ()V&#39; bytes&#x3D;&#39;43&#39; count&#x3D;&#39;14336&#39; backedge_count&#x3D;&#39;18551&#39; iicount&#x3D;&#39;14336&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;189.233&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;14336&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4066&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb350ee2820&#39; size&#x3D;&#39;2416&#39; address&#x3D;&#39;0x00007fb350ee2650&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;464&#39; stub_offset&#x3D;&#39;1712&#39; scopes_data_offset&#x3D;&#39;1976&#39; scopes_pcs_offset&#x3D;&#39;2152&#39; dependencies_offset&#x3D;&#39;2376&#39; nul_chk_table_offset&#x3D;&#39;2384&#39; oops_offset&#x3D;&#39;1928&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;schedule&#x2F;calvin&#x2F;mgcrab&#x2F;CrabbingAnalyzer updateMigrationStatus ()V&#39; bytes&#x3D;&#39;43&#39; count&#x3D;&#39;14338&#39; backedge_count&#x3D;&#39;18554&#39; iicount&#x3D;&#39;14338&#39; stamp&#x3D;&#39;189.233&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4067&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;18813&#39; backedge_count&#x3D;&#39;18812&#39; iicount&#x3D;&#39;18813&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;189.484&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;18813&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4068&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;18813&#39; backedge_count&#x3D;&#39;18812&#39; iicount&#x3D;&#39;18813&#39; level&#x3D;&#39;3&#39; stamp&#x3D;&#39;189.484&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;18813&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4067&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb35108c4c0&#39; size&#x3D;&#39;8352&#39; address&#x3D;&#39;0x00007fb35108c210&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5328&#39; scopes_data_offset&#x3D;&#39;5768&#39; scopes_pcs_offset&#x3D;&#39;7552&#39; dependencies_offset&#x3D;&#39;8272&#39; nul_chk_table_offset&#x3D;&#39;8288&#39; oops_offset&#x3D;&#39;5640&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkSourceNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;19084&#39; backedge_count&#x3D;&#39;19084&#39; iicount&#x3D;&#39;19084&#39; stamp&#x3D;&#39;189.485&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4068&#39; compiler&#x3D;&#39;C1&#39; level&#x3D;&#39;3&#39; entry&#x3D;&#39;0x00007fb3514eac80&#39; size&#x3D;&#39;8352&#39; address&#x3D;&#39;0x00007fb3514ea9d0&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;688&#39; stub_offset&#x3D;&#39;5328&#39; scopes_data_offset&#x3D;&#39;5768&#39; scopes_pcs_offset&#x3D;&#39;7552&#39; dependencies_offset&#x3D;&#39;8272&#39; nul_chk_table_offset&#x3D;&#39;8288&#39; oops_offset&#x3D;&#39;5640&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;migration&#x2F;mgcrab&#x2F;MgCrabMigrationMgr checkDestNode (Lorg&#x2F;elasql&#x2F;sql&#x2F;PrimaryKey;)I&#39; bytes&#x3D;&#39;71&#39; count&#x3D;&#39;19084&#39; backedge_count&#x3D;&#39;19084&#39; iicount&#x3D;&#39;19084&#39; stamp&#x3D;&#39;189.486&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4047&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C2&#39; level&#x3D;&#39;4&#39; entry&#x3D;&#39;0x00007fb3519527c0&#39; size&#x3D;&#39;124544&#39; address&#x3D;&#39;0x00007fb351951890&#39; relocation_offset&#x3D;&#39;296&#39; consts_offset&#x3D;&#39;3856&#39; insts_offset&#x3D;&#39;3888&#39; stub_offset&#x3D;&#39;57328&#39; scopes_data_offset&#x3D;&#39;58456&#39; scopes_pcs_offset&#x3D;&#39;113840&#39; dependencies_offset&#x3D;&#39;121376&#39; handler_table_offset&#x3D;&#39;121424&#39; nul_chk_table_offset&#x3D;&#39;122744&#39; oops_offset&#x3D;&#39;58000&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;bench&#x2F;server&#x2F;procedure&#x2F;calvin&#x2F;tpcc&#x2F;NewOrderProc executeSql (Ljava&#x2F;util&#x2F;Map;)V&#39; bytes&#x3D;&#39;1186&#39; count&#x3D;&#39;8134&#39; backedge_count&#x3D;&#39;89191&#39; iicount&#x3D;&#39;8134&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;189.895&#39;&#x2F;&gt;</span><br><span class="line">&lt;task_queued compile_id&#x3D;&#39;4069&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;bench&#x2F;server&#x2F;procedure&#x2F;calvin&#x2F;tpcc&#x2F;NewOrderProc executeSql (Ljava&#x2F;util&#x2F;Map;)V&#39; bytes&#x3D;&#39;1186&#39; count&#x3D;&#39;8151&#39; backedge_count&#x3D;&#39;89367&#39; iicount&#x3D;&#39;8151&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;189.912&#39; comment&#x3D;&#39;tiered&#39; hot_count&#x3D;&#39;8151&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4005&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C2&#39; level&#x3D;&#39;4&#39; entry&#x3D;&#39;0x00007fb351939480&#39; size&#x3D;&#39;39928&#39; address&#x3D;&#39;0x00007fb351938f90&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;1264&#39; stub_offset&#x3D;&#39;17968&#39; scopes_data_offset&#x3D;&#39;18416&#39; scopes_pcs_offset&#x3D;&#39;35904&#39; dependencies_offset&#x3D;&#39;38768&#39; handler_table_offset&#x3D;&#39;38808&#39; nul_chk_table_offset&#x3D;&#39;39312&#39; oops_offset&#x3D;&#39;18048&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;storage&#x2F;tx&#x2F;concurrency&#x2F;ConservativeOrderedCcMgr bookReadKeys (Ljava&#x2F;util&#x2F;Collection;)V&#39; bytes&#x3D;&#39;80&#39; count&#x3D;&#39;27968&#39; backedge_count&#x3D;&#39;200693&#39; iicount&#x3D;&#39;27968&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;190.118&#39;&#x2F;&gt;</span><br><span class="line">&lt;nmethod compile_id&#x3D;&#39;4035&#39; compile_kind&#x3D;&#39;osr&#39; compiler&#x3D;&#39;C2&#39; level&#x3D;&#39;4&#39; entry&#x3D;&#39;0x00007fb3513c45c0&#39; size&#x3D;&#39;114552&#39; address&#x3D;&#39;0x00007fb3513c3150&#39; relocation_offset&#x3D;&#39;296&#39; insts_offset&#x3D;&#39;5232&#39; stub_offset&#x3D;&#39;67120&#39; scopes_data_offset&#x3D;&#39;68280&#39; scopes_pcs_offset&#x3D;&#39;105400&#39; dependencies_offset&#x3D;&#39;111416&#39; handler_table_offset&#x3D;&#39;111456&#39; nul_chk_table_offset&#x3D;&#39;113520&#39; oops_offset&#x3D;&#39;67656&#39; method&#x3D;&#39;org&#x2F;elasql&#x2F;bench&#x2F;server&#x2F;procedure&#x2F;calvin&#x2F;tpcc&#x2F;NewOrderProc prepareKeys (Lorg&#x2F;elasql&#x2F;schedule&#x2F;calvin&#x2F;ReadWriteSetAnalyzer;)V&#39; bytes&#x3D;&#39;682&#39; count&#x3D;&#39;14703&#39; backedge_count&#x3D;&#39;161383&#39; iicount&#x3D;&#39;14703&#39; decompiles&#x3D;&#39;1&#39; stamp&#x3D;&#39;190.153&#39;&#x2F;&gt;</span><br></pre></td></tr></table></figure><p>后里蟹… 它到底優化了多少 method 啊…</p><p>從 <code>compile_id</code> 這項資訊可以看的出來少說有 4068 以上的 method 被進行了 JIT 優化。而且優化主要發生在兩個時間點。第一個是程式剛啟動的時候，這點很合理。另一個就是資料搬遷開始的時候。</p><p>從它優化的 method 名稱來看，可以推斷出原因應該是因為當資料搬遷開始之後，一堆不常被呼叫的 method 突然被大量呼叫。因此觸發了 JVM 的 JIT 優化機制。</p><p>不過至少是找到問題的源頭了。</p><h2 id="解決辦法"><a href="#解決辦法" class="headerlink" title="解決辦法"></a>解決辦法</h2><p>這樣就有幾個解決辦法：</p><ol><li>想辦法讓程式在開始資料搬遷之前就觸發 JIT 機制，避免在蒐集實驗數據時發生</li><li>關閉 JIT 功能</li><li>放置不管</li></ol><p>法一應該是最合理的作法，這樣就能保有 JIT 的好處，同時也可以避免實驗數據受到 JIT 影響。然而實際上要進行法一需要根據程式的設計來判斷最適當的做法。例如以我們的狀況來說可能就要進行兩次資料搬遷，讓第一次作為暖身，第二次再開始蒐集實驗數據。不過因為我們系統是一個分散式系統的架構，其內部運作又非常複雜，一旦搬出去的東西就很難搬回來。雖然不是辦不到，但要完成的複雜度太高。</p><p>不過如果這篇文章的讀者手上的程式相對沒那麼複雜的話，法一應該是最合理的作法。</p><p>因此接下來只能試試看法二。根據 <a href="https://stackoverflow.com/questions/38721235/what-exactly-does-xx-tieredcompilation-do">這篇文章</a> 的分享，可以透過在 JVM 啟動時設定 <code>-XX:TieredStopAtLevel=n</code> 這個參數來決定要將 JIT 執行到甚麼程度。預設是執行到最高的 Level 4 的程度。</p><p>我首先測試將 JIT 設定為 Level 1 是否有效 (即設定 <code>-XX:TieredStopAtLevel=1</code>)：</p><p><img src="scaleout-ex-mgcrab-disable-c2.png" alt="Scale-out Experiment - MgCrab (C2 Disabled)"></p><p style='text-align: center'>圖五、預設設定與 Level 1 設定在 Throughput 總合的比較，為了方便比較，我把三個 server 的產出合併為一條線。這個圖沒有跑到資料搬遷結束</p><p>…嗯，確實是沒有下墜了，但效能整體也變低不少。</p><p>我好奇不同的設定下的效能差異會差到多少，所以嘗試了 Level 0 ~ 4：</p><p><img src="scaleout-ex-mgcrab-jit.png" alt="Scale-out Experiment - MgCrab (JIT Level Comparison)"></p><p style='text-align: center'>圖六、比較使用不同的 JIT Level 對 MgCrab 實驗的效能影響</p><p>真詭異，Level 1 竟然是第二高的辦法。雖然我不是很懂 JIT 的邏輯，但是顯然 Level 不是設定越高越好。而且 Level 4 雖然中間會跌下去一下，但這個代價顯然是值得的。</p><p>在知道了不同 Level 帶來的影響之後，最後就是要根據展示這個實驗的需求選擇最適合的設定。因為我們的實驗要展現的是極致的效能，因此我們最後應該是會選擇保留 JIT Level 4 的設定。並且需要的時候加註說明表示短暫的下跌是由於 JIT 造成的現象。</p><p>至於為什麼之前論文發表時沒有觀察到這個現象呢？比較一下之前的實驗結果發現：因為當時系統的效能還不算太好，很有可能是當時程式優化不足，讓機器的 CPU 使用率並沒有滿載。因此受到 JIT 影響的程度並不劇烈。雖然當時可能也發生了相同問題，但是在 CPU 沒有完全滿載的情況下問題就不太顯著。</p><p>所以我最後決定放置不管，將之視為合理的代價。</p><p>結案。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在使用實驗室開發的 &lt;a href=&quot;https://github.com/elasql/elasql&quot;&gt;ElaSQL 分散式資料庫系統&lt;/a&gt; 進行實驗時，發現系統效能在某個時間點會有突然下墜的情況。 因此這篇文章分享一下調查下墜原因的過程，以及可能的應對措施。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://www.slmt.tw/blog/categories/programming/"/>
    
    <category term="Java" scheme="http://www.slmt.tw/blog/categories/programming/java/"/>
    
    
    <category term="java" scheme="http://www.slmt.tw/blog/tags/java/"/>
    
    <category term="performance" scheme="http://www.slmt.tw/blog/tags/performance/"/>
    
    <category term="jvm" scheme="http://www.slmt.tw/blog/tags/jvm/"/>
    
    <category term="jit" scheme="http://www.slmt.tw/blog/tags/jit/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning 筆記 (2) - Value Iteration &amp; Policy Iteration</title>
    <link href="http://www.slmt.tw/blog/2021/02/07/rl-note-2/"/>
    <id>http://www.slmt.tw/blog/2021/02/07/rl-note-2/</id>
    <published>2021-02-07T13:57:59.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇說明了 Reinforcement Learning (簡稱 RL) 的目標，以及 RL 通常會假設問題符合 Markov Decision Process (簡稱 MDP) 的特性，這篇則說明如何在 MDP 的假設下找出最佳的 policy。</p><a id="more"></a><h2 id="解法一：Value-Iteration"><a href="#解法一：Value-Iteration" class="headerlink" title="解法一：Value Iteration"></a>解法一：Value Iteration</h2><h3 id="主要概念"><a href="#主要概念" class="headerlink" title="主要概念"></a>主要概念</h3><p>首先想辦法計算出每個 state 出發能得到的最佳總報酬 (total reward)，將之記錄起來。接著再找出每個 state 上做哪個 action 得到的 total reward 最高。如此一來就能知道在每個 state 時該做甚麼 action，這就是最佳的 policy。</p><h3 id="概念說明與推導-假設最大走-H-步"><a href="#概念說明與推導-假設最大走-H-步" class="headerlink" title="概念說明與推導 (假設最大走 H 步)"></a>概念說明與推導 (假設最大走 H 步)</h3><p>首先我們先定義從一個 state $s$ 出發之後，依照一個 policy $\pi$ 走 $h$ 步能夠拿到的 total reward：</p><p>$$<br>V_\pi^{(h)}(s) = E_{s^{(1)},…,s^{(h)}}(\sum^h_{t=0}\gamma^t R(s^{(t)}, \pi(s^{(t)}), s^{(t+1)}) | s^{(0)} = s;\pi)<br>$$</p><p>這個式子跟第一份筆記最後的式子基本上是一樣的，只是我們多指定 initial state 為 $s$。而這個式子我們稱作 <strong>Value Function</strong>。Value 的意思就是預期的 total reward。</p><p>Value Iteration 的第一個目標是找出給從一個 state $s$ 出發，能夠得到的最佳 total reward：</p><p>$$<br>V^{*(h)}(s) = \max_\pi E_{s^{(1)},…,s^{(h)}}(\sum^h_{t=0}\gamma^t R(s^{(t)}, \pi(s^{(t)}), s^{(t+1)}) | s^{(0)} = s;\pi)<br>$$</p><p>此式子叫做 <strong>Optimal Value Function</strong>。</p><p>而所謂的最佳 policy (標記為 $\pi^*$) 其實就是在每一個 state $s$ 選擇一個會帶來最大 total reward 的 action $a$，也就是可以寫成下列式子：</p><p>$$<br>\pi^*(s) = \arg \max_a \sum_{s’} P(s’|s;a) [R(s,a,s’) + \gamma V^{*(H-1)}(s’)]<br>$$</p><p>注意上面這個式子假設我們已經知道了每一個 state 出發走 $H-1$ 步之後的 total reward。所以為了要能夠解出上述式子，我們必須要先知道 $V^{*(H-1)}(s’)$ 是多少。也就是要先算出下面式子：</p><p>$$<br>V^{*(H-1)}(s’) = \max_a \sum_{s’&#39;} P(s’&#39;|s’;a) [R(s’,a,s’&#39;) + \gamma V^{*(H-2)}(s’&#39;)]<br>$$</p><p>看到這邊應該有點感覺了，可以發現要解出每一個步的最佳 total reward 要先得到上一步的最佳 total reward，直到第 0 步為止。這其實符合 dynamic programming 的概念：「一個問題的 optimal solution 可以從他的子問題的 optimal solution 得到」。因此 optimal value function 可以使用 dynamic programming 來計算。</p><h3 id="Algorithm-假設最大走-H-步"><a href="#Algorithm-假設最大走-H-步" class="headerlink" title="Algorithm (假設最大走 H 步)"></a>Algorithm (假設最大走 H 步)</h3><p><img src="value-algo-finite.png" alt="Value Iteration (finite)"></p><p style='text-align: center'>圖一、Value Iteration 的 Pseudo Code</p><p>圖一展示了 Value Iteration 的實作方式，大致分成兩塊，第一塊建立一個 mapping，該 mapping 告訴我們一個 state 出發走 $H-1$ 步最佳的 total reward 是多少。建立的方式就是我先算第一步每一個 state 的 total reward 會是多少，然後再算第二步，再算第三步…直到算到第 $H-1$ 步為止，也就是 dynamic programming。第二塊則是建立在這個基礎上找出最佳的 policy，也就是每個 state 該做甚麼動作。</p><h3 id="推導-無限步數"><a href="#推導-無限步數" class="headerlink" title="推導 (無限步數)"></a>推導 (無限步數)</h3><p>接下來來考慮 $H \rightarrow \infty$ 的情況。</p><p>若我們不限制步數，也就是可以走無限步的話，optimal value function 就變成：</p><p>$$<br>V^{*}(s) = \max_a \sum_{s’} P(s’|s;a) [R(s,a,s’) + \gamma V^{*}(s’)]<br>$$</p><p>這個式子跟有限步數的式子基本相同，只差在計算時不需要考慮走幾步。因為每一個 state 出發的最佳 total reward (或稱為 optimal value) 在走了無限步之後都會收斂到一個值 (這個應該還算直覺，因為有 discount factor $\gamma$ 的存在)。這個遞迴的式子太有名，所以有個名字：<strong>Bellman Optimality Equation</strong>。</p><p>在無限步的情況下找 policy 的方法仍相同，就是對每個 state 找可以得到 optimal value 的 action。</p><p>不過此時得到的 policy 就有幾個特性：</p><ul><li>Stationary：每個 state 的最佳 action 不隨時間改變。</li><li>Memoryless：每個 state 的最佳 action 跟起始狀態 $s^{(0)}$ 無關。</li></ul><h3 id="Algorithm-無限步數"><a href="#Algorithm-無限步數" class="headerlink" title="Algorithm (無限步數)"></a>Algorithm (無限步數)</h3><p><img src="value-algo-infinite.png" alt="Value Iteration (infinite)"></p><p style='text-align: center'>圖二、Value Iteration (無限步數) 的 Pseudo Code</p><p>這個 algorithm 跟前一個最主要的不同就在於，他把 H 步的 for loop 用一個無限 loop 替代，直到 optimal value 沒有變化為止。</p><p>仔細想想可以發現好像很難說這個方法會收斂，不過事實上可以用數學證明會收斂，因此這邊就不探討。</p><h2 id="解法二：Policy-Iteration"><a href="#解法二：Policy-Iteration" class="headerlink" title="解法二：Policy Iteration"></a>解法二：Policy Iteration</h2><h3 id="主要概念-1"><a href="#主要概念-1" class="headerlink" title="主要概念"></a>主要概念</h3><p>先隨便亂用一個 policy (以 2D 迷宮來說就是設定全部往右走之類的) 試試看，然後根據得到的 reward 來改進 policy 以增加預期獲得的 total reward。再重複拿新的 policy 嘗試並改進 policy。直到 policy 沒有改變為止。</p><p>這種做法比較像是人類找最佳策略的做法。</p><h3 id="概念說明與推導"><a href="#概念說明與推導" class="headerlink" title="概念說明與推導"></a>概念說明與推導</h3><p>因為 policy iteration 的概念是要一直不斷嘗試直到 converge，因此就不考慮有限步數 $H$ 的情況。</p><p>首先我們知道給定一個 policy $\pi$，可以得到的預期總報酬 (expected total reward，或叫做 value) 可以用 value function 表示：</p><p>$$<br>V_\pi(s) = E_{s^{(1)},…}(\sum^\infty_{t=0}\gamma^t R(s^{(t)}, \pi(s^{(t)}), s^{(t+1)}) | s^{(0)} = s;\pi)<br>$$</p><p>那我們要怎麼找到最好的 policy 呢？</p><p>這要分成兩個步驟：</p><ol><li>先找出該 policy 可以得到的預期總報酬是多少</li><li>改進 policy 以提高預期總報酬</li></ol><p>首先 value function 的式子 $V_\pi(s)$ 也跟 Value Iteration 無限步數的情況相同，可以寫成遞迴形式：</p><p>$$<br>V_\pi(s) = \sum_{s’} P(s’|s;\pi(s)) [R(s,\pi(s),s’) + \gamma V_\pi(s’)]<br>$$</p><p>這個式子也非常有名，叫做 <strong>Bellman Expectation Equation</strong>。這個式子跟 Bellman Optimality Equation 有兩個差異：</p><ul><li>Policy $\pi$ 已經指定</li><li>沒有 $\max$</li></ul><p>知道這個遞迴式之後，有兩種方式可以解這個式子：</p><ol><li>解聯立方程式：因為這個式子只有 $V_\pi(s)$ 是未知的，而 $V_\pi(s)$ 的值有 $|\mathbb{S}|$ 種，然後式子剛好也有 $|\mathbb{S}|$ 個，所以可以解聯立方程式。時間複雜度 $|\mathbb{S}|^3$。</li><li>跟 Value Iteration 一樣，用 DP 跑到收斂為止。</li></ol><p>Policy Iteration 採用的就是第二種解法，因為實際上跑比較快。</p><p>那現在完成第一個步驟，也就是找出一個 policy 的預期總報酬之後，要如何改進 policy 呢？只要根據以下的式子更新 policy 就好：</p><p>$$<br>\hat\pi(s) = \arg\max_a\sum_{s’} P(s’|s;a) [R(s,a,s’) + \gamma V_\pi(s’)]<br>$$</p><p>講白話點就是，假設我們在 state $s$，因為我們知道每一個 action 之後到達的下一個 state $s’$ 持續用原本的 policy $\pi$ 的預期總報酬，所以我們就可以依此挑選一個帶來最大總報酬的 action $a$，並把這個新的策略記為 $\hat\pi(s)$。</p><p>這個式子可以經由數學證明每次計算都可以得到更好或是至少不會變爛的 policy，證明的部分就省略。</p><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="policy-algo.png" alt="Policy Iteration"></p><p style='text-align: center'>圖三、Policy Iteration 的 Pseudo Code</p><p>圖三展示了上述概念的實作方式。</p><h2 id="這兩種做法的不足之處"><a href="#這兩種做法的不足之處" class="headerlink" title="這兩種做法的不足之處"></a>這兩種做法的不足之處</h2><p>然而，現實世界並不如大家所想的容易。</p><p>實際上我們很難得知 $P(s’|s;a)$ 到底是多少，像是吃角子老虎機不會告訴你拉一次轉換到中獎的機率有多少。</p><p>因此下一份筆記將會解釋如何在不知道 $P(s’|s;a)$ 的情況下找最佳 policy，也就是所謂的 Model-free RL。</p><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p>以上筆記為我看清華大學資訊工程學系的吳尚鴻教授的 CS565600 深度學習課程第 16 課，再轉化成我的理解記錄下來，有興趣的人可以直接看課程：</p><p><a href="https://nthu-datalab.github.io/ml/">https://nthu-datalab.github.io/ml/</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;上一篇說明了 Reinforcement Learning (簡稱 RL) 的目標，以及 RL 通常會假設問題符合 Markov Decision Process (簡稱 MDP) 的特性，這篇則說明如何在 MDP 的假設下找出最佳的 policy。&lt;/p&gt;</summary>
    
    
    
    <category term="Reinforcement Learning" scheme="http://www.slmt.tw/blog/categories/reinforcement-learning/"/>
    
    
    <category term="note" scheme="http://www.slmt.tw/blog/tags/note/"/>
    
    <category term="reinforcement learning" scheme="http://www.slmt.tw/blog/tags/reinforcement-learning/"/>
    
    <category term="value iteration" scheme="http://www.slmt.tw/blog/tags/value-iteration/"/>
    
    <category term="policy iteration" scheme="http://www.slmt.tw/blog/tags/policy-iteration/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning 筆記 (1) - 基本概念與目標</title>
    <link href="http://www.slmt.tw/blog/2021/02/07/rl-note-1/"/>
    <id>http://www.slmt.tw/blog/2021/02/07/rl-note-1/</id>
    <published>2021-02-07T09:30:00.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>最近因為在探討新的研究方向，所以開始踏入了 Reinforcement Learning (以下簡稱 RL) 的領域。 這篇文章記錄了我學習 RL 的過程與理解，以供需要其他打算學習 RL 的人參考。</p><a id="more"></a><h2 id="RL-問題簡介"><a href="#RL-問題簡介" class="headerlink" title="RL 問題簡介"></a>RL 問題簡介</h2><p>RL 問題指的是設計一個策略 (policy)，讓他取得當下環境的狀態 (state)，來決定要做什麼樣動作 (action)，以讓我們最後使用該策略可以取得最大的總報酬 (total reward) 的問題。RL 可以拿來解決許多實務的問題，例如走迷宮、下圍棋、打遊戲、自動駕駛車等等。</p><p>更正式來說，一個 RL 問題包含以下幾個要素：</p><ul><li>State $s^{(t)}$：在一個環境中時間 $t$ (或是稱為第 $t$ 步) 的狀態，隨時間改變<ul><li>一般假設環境本身不會改變，例如迷宮的路是固定的，狀態則代表人在迷宮的位置等等資訊。</li></ul></li><li>Action $a^{(t)}$：在時間 $t$ 採取的行動</li><li>Reward $R^{(t)}$：在時間 $t$ 採取行動之後取得的報酬</li></ul><p>目標：找到一個策略 policy $\pi$，以取得最大的總和報酬 (total reward)： $\Sigma_t R^{(t)}$。</p><h2 id="Markov-Decision-Processes"><a href="#Markov-Decision-Processes" class="headerlink" title="Markov Decision Processes"></a>Markov Decision Processes</h2><p>Reinforcement Learning 為了方便計算，一般會假設問題是一個 Markov Decision Processes (以下簡稱 MDP)。</p><h3 id="MDP-假設"><a href="#MDP-假設" class="headerlink" title="MDP 假設"></a>MDP 假設</h3><p>首先我們先假設要解決的問題之中的 state 的序列是一個 Markov Process。意思就是一個 state $s^{(t)}$ 出現的機率只跟它的上一個 state  $s^{(t-1)}$ 有關，而跟更早之前的 state 無關。換句話說，考慮了之前所有狀態跟只考慮當下狀態的基礎上，下一個狀態的機率分布是相同的。寫成數學式如下：</p><p>$$<br>P(s^{(t+1)}|s^{(t)},s^{(t-1)},…)=P(s^{(t+1)}|s^{(t)})<br>$$</p><p>如果這個假設成真，解 RL 問題時就可以不需要考慮更早之前的狀態，只要關注當下的狀態就好。</p><p>而 Reinforcement Learning 則是在解 Markov <strong>Decision</strong> Process，也就是 state 的變換是在<strong>我們的控制中</strong>的 Markov Process。</p><h3 id="基本要素"><a href="#基本要素" class="headerlink" title="基本要素"></a>基本要素</h3><p>一個 Markov Decision Process 包含以下幾個基本要素與符號：</p><ul><li>State space $\mathbb{S}$: 定義所有可能出現的 state</li><li>Action space $\mathbb{A}$: 定義所有可能的 action</li><li>Initial state $s^{(0)}$: 初始狀態</li><li>Transition distribution $P(s’|s;a)$: 給定狀態 $s$ 與動作 $a$ 之後，某一個狀態 $s’$ 出現的機率<ul><li>這個要特別注意。一般會以為我在某個時間點做了一個動作就一定會轉換到想要的狀態，然而實際上可能會有些意外發生。例如我在橋上往前走，除了前進之外可能也會不小心掉到橋下 (雖然我選擇的動作是前進)。這個 distribution 其實考慮了現實生活中的隨機性。</li><li>這邊假設這個 distribution 在給定相同狀態與動作時都是固定的，不隨時間改變。</li></ul></li><li>Deterministic reward function $R(s, a, s’)$: 在狀態 $s$ 時做了動作 $a$ 轉換到狀態 $s’$ 獲得的報酬 (reward)</li><li>Discount factor $\gamma \in [0,1]$: 折扣係數<ul><li>用來降低越晚得到的 reward 帶來的效果 =&gt; 越早拿到 reward 越好</li></ul></li><li>Horizon $H \in \mathbb{N}$: 步數的上限</li></ul><p>因此總報酬 total reward 可以寫成以下式子：</p><p>$$<br>R(s^{(0)}, a^{(0)}, s^{(1)}) + \gamma R(s^{(1)}, a^{(1)}, s^{(2)}) + … + \gamma^{H-1} R(s^{(H-1)}, a^{(H-1)}, s^{(H)})<br>$$</p><h3 id="MDP-目標"><a href="#MDP-目標" class="headerlink" title="MDP 目標"></a>MDP 目標</h3><p>假設我們把策略 policy 用一個 function $\pi$ 表示，其中 $\pi$ 給定一個狀態可以告訴我們下一個動作該做甚麼。那它的預期總報酬 $V_\pi$ 可以寫成：</p><p>$$<br>V_\pi = E_{s^{(0)},…,s^{(H)}}(\sum^H_{t=0}\gamma^t R(s^{(t)}, a^{(t)}, s^{(t+1)});\pi)<br>$$</p><p>其中 $a^{(t)} = \pi(s^{(t)})$</p><p>這邊使用期望值表示是因為執行一個動作並不一定會轉換到想要的 state，而是由一個 transition distribution $P$ 決定。所以必須要用期望值來代表有考慮到其他可能性。</p><p>MDP 的目標就是要找到可以得到最大期望總報酬 (total reward) 的最佳的 policy $\pi^*$：</p><p>$$<br>\pi^* = \arg \max_\pi V_\pi<br>$$</p><h2 id="關於下一份筆記"><a href="#關於下一份筆記" class="headerlink" title="關於下一份筆記"></a>關於下一份筆記</h2><p>接下來會寫兩種找到最佳 policy 的基本作法：value iteration 與 policy iteration。</p><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p>以上筆記為我看清華大學資訊工程學系的吳尚鴻教授的 CS565600 深度學習課程第 16 課，再轉化成我的理解記錄下來，有興趣的人可以直接看課程：</p><p><a href="https://nthu-datalab.github.io/ml/">https://nthu-datalab.github.io/ml/</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近因為在探討新的研究方向，所以開始踏入了 Reinforcement Learning (以下簡稱 RL) 的領域。 這篇文章記錄了我學習 RL 的過程與理解，以供需要其他打算學習 RL 的人參考。&lt;/p&gt;</summary>
    
    
    
    <category term="Reinforcement Learning" scheme="http://www.slmt.tw/blog/categories/reinforcement-learning/"/>
    
    
    <category term="note" scheme="http://www.slmt.tw/blog/tags/note/"/>
    
    <category term="reinforcement learning" scheme="http://www.slmt.tw/blog/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>千里馬計畫歷程分享 Part 3 - 準備托福</title>
    <link href="http://www.slmt.tw/blog/2020/07/18/uchicago-exchange-part-3/"/>
    <id>http://www.slmt.tw/blog/2020/07/18/uchicago-exchange-part-3/</id>
    <published>2020-07-18T02:17:23.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>今天來講千里馬計畫申請中最令人頭痛的環節之一，外國語言能力檢定。 因為我申請前往的國家是美國，所以我考了常見的托福。 這篇文章簡單說明一下我如何準備托福。</p><a id="more"></a><h2 id="COVID-19-更新-（又稱武漢肺炎、新冠肺炎）"><a href="#COVID-19-更新-（又稱武漢肺炎、新冠肺炎）" class="headerlink" title="COVID-19 更新 （又稱武漢肺炎、新冠肺炎）"></a>COVID-19 更新 （又稱武漢肺炎、新冠肺炎）</h2><p>我在出發的前兩週 (2020/3/13) 收到了芝加哥大學的來信，信中表明因為 COVID-19 疫情的關係，所以學校延後所有交換計畫。</p><p>時至今日 (2020/7/18)，我還無法確定何時才能出發。 目前最有希望的時間是秋季抵達（大概九月底出發），不過現在還在觀察情勢。</p><p>希望今後申請的人不要跟我一樣遇到這樣的事件。</p><h2 id="托福簡介"><a href="#托福簡介" class="headerlink" title="托福簡介"></a>托福簡介</h2><p>首先，先給不熟悉托福的人說明一下。 托福的考試（現在一般是指托福網路測驗 TOEFL iBT） 一共依序分成四個部分（以下以 2019 年 8 月實施的新制為準）：</p><ol><li>讀：閱讀測驗，3~4 篇文章題組</li><li>聽：聽力測驗，2<del>3 個校園對話題組、3</del>4 個課堂演講題組</li><li>說：口說測驗，一則快速反應題、三則整合題目</li><li>寫：寫作測驗，一則整合題、一則申論題</li></ol><p>以上每個部分分數各佔 30 分，滿分 120 分。 整個考試時間長度大概會佔半天的時間，只有聽力跟口說中間會有休息時間，其他部分之間都沒有休息時間。</p><h2 id="托福準備參考資料"><a href="#托福準備參考資料" class="headerlink" title="托福準備參考資料"></a>托福準備參考資料</h2><p>接著我分享一下我在準備托福時參考過的各種資料：</p><ul><li>The Official Guide to the Toefl Test (ISBN: 9781260011210)<ul><li>這本是官方出的指引書，教沒有考過托福的人如何應試，內含大量的範例試題。 有許多人推薦這本書，因為可以有系統地了解托福考試的規則與應試技巧。 不過內容很多，我當初能準備的時間不多，所以沒有仔細看完。 我個人覺得最有幫助的其實是後半部的範例試題。</li></ul></li><li><a href="https://www.kmf.com/">托福考滿分</a><ul><li>這個網站提供了大量的托福練習試題，有許多官方認證的題目，而且也準備了類似正式考試時的介面，讓練習的人可以體會到接近實際應試的感覺。 實際上我大多數的時間都在寫這個網站的試題，我發現其實直接跳進試題裡練習是最有效的方法。</li></ul></li><li><a href="https://toeflstudy.pixnet.net/blog/post/15694954">部落格文章 - 托福讀書計畫攻略</a><ul><li>這個我覺得蠻有用的，但因爲我只剩下一個月時間準備，所以實際上沒派上用場，但如果有較長的時間準備，應該蠻有參考價值。</li></ul></li><li><a href="https://www.ptt.cc/bbs/TOEFL_iBT/M.1372577547.A.1EB.html">PTT 文章 - [心得] 托福綜合心得</a><ul><li>這個是實際上幫助我最多的文章，我非常推薦需要短期攻略托福的人閱讀！ 作者跟我的狀況很像，要在一個月內準備好托福，因此他整理出了一個月內有效準備的方式。 接下來的內容有許多是參考自他的做法。</li></ul></li><li><a href="https://www.ptt.cc/bbs/TOEFL_iBT/M.1283913406.A.6F6.html">PTT 文章 - [分享] 口說網路教學+自己的心得</a><ul><li>這篇重點放在托福口說的模板上面。 因為托福的口說題目形式固定，所以掌握模板的話就可以比較容易說出有組織的句子。 推薦要加強口說的人閱讀！</li></ul></li><li><a href="https://www.ptt.cc/bbs/TOEFL_iBT/M.1508937058.A.B41.html">PTT 文章 - [分享] 考托福前中後你需要知道的事（影片）</a><ul><li>這篇主要是考前應試的注意事項對我最有幫助，因此推薦考試前看一下這篇文章。</li></ul></li></ul><p>另外建議報名的時候先調查一下可以選擇的考場的狀況，網路上只要搜尋考場代號就能夠找到很多使用心得。</p><h2 id="我的準備方式"><a href="#我的準備方式" class="headerlink" title="我的準備方式"></a>我的準備方式</h2><p>準備的部分我分成聽、說、讀、寫四個部分討論。 因為我當時是五月底決定要申請計畫，計畫申請期限是七月底。 考慮到等待成績與一些突發狀況，我至少要預留一個月左右的時間等待考試結果。 因此我最後決定七月初考試，但是這也使得我只剩下一個月左右的時間可以準備。 因為我考量說跟寫難以短時間內進步，覺得重心最好放在容易取得滿分的項目上，所以我最後其實是將重心放在讀跟聽上。</p><h3 id="讀-Reading"><a href="#讀-Reading" class="headerlink" title="讀 (Reading)"></a>讀 (Reading)</h3><p>讀其實最好的作法就是大量練習範例試題。 我當時是安排我一週至少要寫兩組模擬試題（一組指的是一次考試的所有閱讀題，週間跟週末各一組），因此我考試前至少練習了八組以上。 如果有時間的話，最好是至少每兩天寫一份試題。 只是我當時剛好遇到要投稿論文的死線，所以白天都在趕論文，只能用晚上休息的時間練習。</p><p>要注意的是，並不是題目寫完、對完答案、看完分數之後就直接繼續寫了。 事後檢討非常重要，這裡其實才是進步的關鍵。 我每次寫完之後，我會仔細再閱讀一次文章，並且確保我百分之百搞懂文章每一句話在說什麼。 其中我覺得最重要的步驟是，記錄下看不懂的單字，並把這些單字背起來！ 因為托福的閱讀測驗主要是從教科書上的文本擷取下來，因此我發現許多較難的單字其實重複率很高！ 實際上我應試的時候也遇到很多我在模擬考時不會的單字，多虧我後來有背起來，應試時就比較沒遇到沒看過的單字。</p><p>至於背單字的部分，對許多人來說應該都很苦手。 對我其實也是。 因此我這邊很推薦一個背單字軟體：Anki。 使用方法可以參考這篇文章：<a href="https://blog.chunnorris.cc/2016/04/anki1.html">Chun Norris Facts - Anki 教學文</a>。 這個軟體可以裝在電腦跟手機上，而且可以透過同一個帳號同步，非常方便。 它的功能主要就是單字卡，然後可以根據使用情況決定單字卡出現的頻率。 而這個軟體的價值在於它出現的單字卡順序是隨機的。 有個笑話這樣說：「什麼單字是高中生最熟悉的？Abandon！」 因為這個字是高中生必備七千字的第一個字，很多人只背前幾個字就放棄了，所以最有印象的就是這個字XD 而 Anki 就是解決這個問題，讓單字出現的順序隨機，因此不會只記得少數幾個字。 我當時把所有托福不認識的字全部輸入，設定成每天最多顯示 100 個單字，然後在閒暇之餘拿手機背，其實大概三到五分鐘就可以全部看完。 所以負擔其實不會很大，而且效果很強，使得我到現在還在用它背單字。</p><p>重點：大量練習，背熟所有單字。</p><h3 id="聽-Listening"><a href="#聽-Listening" class="headerlink" title="聽 (Listening)"></a>聽 (Listening)</h3><p>聽的練習方式其實跟讀差不多，就是要依靠練習。 聽多了就會慢慢聽懂了。 我大概聽了十題之後，聽力就有明顯的進步。 當然最好是在模擬考方式下進行，可以練習在壓力下理解聽力的內容。</p><p>不過我最近發現了一個有趣的 Youtube 頻道，我覺得很適合練習聽力，而且也不會像考試那樣枯燥乏味： <a href="https://www.youtube.com/channel/UCKgpamMlm872zkGDcBJHYDg">Learn English with TV Series</a>。 這個頻道從許多知名的影集或者電影中擷取一些片段，然後解說其中的單字和片語。 因為有大量的字幕，所以可以一邊聽一邊確認聽到的內容。 另外我也推薦去找一些有興趣的國外 Youtuber，然後沒事的時候就看他們的影片。 像是我有跟隨一個知名的遊戲 Youtuber <a href="https://www.youtube.com/channel/UC7_YxT-KID8kRbqZo7MyscQ">Markiplier</a>，我常常喜歡看他玩一些恐怖遊戲，也可以ㄧ邊練習聽力。</p><p>重點：大量練習，閒暇時間可以看有興趣的國外 Youtube 影片。</p><h3 id="說-Speaking"><a href="#說-Speaking" class="headerlink" title="說 (Speaking)"></a>說 (Speaking)</h3><p>口說其實也是靠練習，而且需要的量遠大於讀跟聽。 不過托福的題目模式很固定，因此其實可以透過特定的模板作答。 如果掌握了模板的話，就會大幅增加得到高分的機率。 模板的部分我推薦大家閱讀<a href="https://www.ptt.cc/bbs/TOEFL_iBT/M.1283913406.A.6F6.html">這篇 PTT 的文章</a>的說的部分，他提供的影片解釋得非常好。</p><p>除此之外，也最好練習一下臨場反應。 托福有一兩題口說是考臨場反應。 他會簡短地問一句問題，像是「你最喜歡什麼類型的電影？」，然後只給你幾秒的時間準備，就要馬上給 60 秒的回答。 練習的方法上面文章有說，可以去網路上找「托福黃金口說 80 題」，裡面列了 80 個這種簡短的題目。 就拿個碼錶，看一下題目後，馬上開始計時，就可以練習了。</p><p>重點：口說模板可以大幅增加得分機率，然後要練一下臨場反應。</p><h3 id="寫-Writing"><a href="#寫-Writing" class="headerlink" title="寫 (Writing)"></a>寫 (Writing)</h3><p>寫是我最沒有準備的部分，主要是因為我當時正在準備投稿論文，因此白天其實就在大量練習寫學術文章了。 大家如果要參考準備方法的話，我很推薦讀<a href="https://www.ptt.cc/bbs/TOEFL_iBT/M.1372577547.A.1EB.html">這篇 PTT 的文章</a>。 裡面最多篇幅的部分就是在解釋托福寫作的技巧。 托福寫作我覺得最難的其實是一開始的整合寫作，題目會給一段文章，然後放一段課程，再要求你用寫作來統整重點。 我覺得這種題目最重要的就是寫筆記，需要練習一下怎麼樣在短時間內記錄最多的資訊。 我記得在某一篇 PTT 文章有看到，似乎寫作的內容可以講到越多細節的話分數就會愈高。 因此筆記真的很重要。</p><p>接下來最後一題寫作就是申論，這邊主要就是第一段要先重點提一下自己想要表達的想法，然後第二跟第三段則是要提出佐證來證明自己的論點。 其中每一段也是第一句話要先提出這整段的重點，然後接下來每句話都是圍繞在第一句話上講。 例如題目可能是「是否支持小孩看電視？」，如果想要申論支持的話，第二段第一句話可能是「我支持小孩看電視，因為電視提供了許多新知可供學習。」。 接著後面就要更細節的說，有什麼樣的新知可以學習，像是：「小孩可以透過新聞了解世界最新的趨勢。」這樣。 最後就下一段結論，說確實有好處等等。</p><p>重點：整合題的筆記很重要，申論則要靠舉例和佐證</p><h2 id="實際應試狀況"><a href="#實際應試狀況" class="headerlink" title="實際應試狀況"></a>實際應試狀況</h2><p>報名時記得就要先確認護照是否快過期，如果沒有六個月以上的效期的話，考場可能就會不讓你入場。 我有聽說有人因此就喪失考試權利。</p><p>考試前一天最好是住在考場附近，因為考試時間通常很早，而且最好再提早建議時間一個小時前到，所以住附近會比較快。 出發前也務必確認是否所有東西都帶齊。 最好列個清單在出發前可以確認一下。 到場後趕快熟悉一下考場位置，還有廁所在哪裡等等，最好再確認第二間廁所在哪，以免大家一起上廁所客滿沒廁所用。</p><p>我考試時大致狀況都符合網路上查到的狀況，沒有什麼太多意外。 唯一出乎我預料之外的是，口說時被旁邊的人影響的狀況比想像中嚴重。 大家都用很大聲的聲音說，所以我甚至可以很清楚地聽到人家在說什麼。 這使得我心理有因此受到一些影響，答題的時候腦袋有點轉不過來。 這可能得練習在吵雜的地方口說才有辦法改進。</p><h2 id="我的考試結果"><a href="#我的考試結果" class="headerlink" title="我的考試結果"></a>我的考試結果</h2><p>我最後的考試結果是：閱讀 28、聽力 28、口說 17、寫作 20。 總分 93 分。</p><p>因為我重心主要放在閱讀跟聽力，所以這兩項都拿了接近滿分。 不過口說跟寫作其實也比我預期的高了不少，畢竟我實際上根本沒什麼準備，近乎裸考。 口說只有考前三天惡補一下。</p><h2 id="芝加哥大學意料外的英語門檻"><a href="#芝加哥大學意料外的英語門檻" class="headerlink" title="芝加哥大學意料外的英語門檻"></a>芝加哥大學意料外的英語門檻</h2><p>我的托福分數以申請千里馬的門檻來說是足夠了，應該只要考到 80 分以上就沒什麼問題。 然而我後來發現芝加哥大學有額外的英語門檻。（事實上大多數美國學校都有，所以建議先查清楚。） 規定要當作理工學院的訪問學生的話，托福總分需達 90 分以上，同時口說需要 18 分以上。 而我口說沒有過這個門檻，讓我一度以為我需要重考一次。（我後來發現其實我可以申請複查口說，因為我也只差一分而已，有機會提高的話就該嘗試看看。 可惜我發現的時間點太晚，已經過複查的期限。 複查需要在考試後一個月內提出。）幸好芝加哥大學有專門的英語能力測驗 (APEA)，基本上就是大概半小時的時間用視訊跟他們的審查專員聊個天，他們會藉此評估英語能力。 細節之後我再另外說明。 總之我最後透過這個測驗達到了英語能力門檻。</p><h2 id="我的全部時間軸"><a href="#我的全部時間軸" class="headerlink" title="我的全部時間軸"></a>我的全部時間軸</h2><p>以下紀錄從決定申請到現在為止發生的重要事件：</p><ul><li>2019/5 月中旬 - 決定申請千里馬計畫</li><li>2019/6/1 - 科技部系統開放申請</li><li>2019/6/9 - 跟指導老師討論要前往哪一位教授的 lab</li><li>2019/6/12 - 報名 TOEFL iBT 考試</li><li>2019/6/29 - TOEFL iBT 應考</li><li>2019/7/8 - 決定要前往的實驗室與連絡上國外的教授<ul><li>從研究要去哪間研究室到這步驟拖了點時間，因為當時正在忙著投一篇論文。 這也是為什麼要提早找教授，不然跟我一樣卡個論文 deadline 就可能會 delay。</li></ul></li><li>2019/7/9 - TOEFL iBT 開放線上查成績（總成績：93）</li><li>2019/7/18 - 與國外教授線上面談</li><li>2019/7/30 - 收到國外教授的接受函（超驚險）</li><li>2019/7/30 - 送出申請，並由校內統合送出</li><li>2019/11/29 - 科技部官網公布 <a href="https://www.most.gov.tw/folksonomy/detail?subSite=&l=ch&article_uid=342f7b32-5bc4-4885-9607-32d946c067cc&menu_id=d3c30297-bb63-44c5-ad30-38a65b203288">通過名冊</a></li><li>2019/12/4 - 通知國外指導教授並開始申請 DS-2019 (申請美國簽證必備文件)</li><li>2019/12/26 - 參加芝加哥大學英文能力測驗 (APEA)</li><li>2020/1/7 - 收到芝加哥大學通知通過 APEA 測驗，並完成 DS-2019 申請</li><li>2020/1/16 - 收到 DS-2019</li><li>2020/1/21 - 送出校內簽約資料，以申請補助款<ul><li>這個需要付 DS-2019 的副本，加上我到 1/18 都不在台灣。 所以拖到這個時候才提出申請。</li></ul></li><li>2020/1/29 - 填寫 DS-160 以申請簽證</li><li>2020/2/3 - 到郵局完成簽證費繳費，並預約 AIT 面試時間</li><li>2020/2/18 - 到台北內湖 AIT 進行面試，當場收取護照</li><li>2020/2/20 - 收到護照並附上 J-1 Visa</li><li>2020/3/13 - 收到芝加哥大學通知，因為 COVID-19 疫情的關係，延後所有交換計畫</li><li>到現在 (2020/7/18) - 待機中</li></ul><h2 id="待續…"><a href="#待續…" class="headerlink" title="待續…"></a>待續…</h2><p>下次說明我如何撰寫研究計畫申請書～</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天來講千里馬計畫申請中最令人頭痛的環節之一，外國語言能力檢定。 因為我申請前往的國家是美國，所以我考了常見的托福。 這篇文章簡單說明一下我如何準備托福。&lt;/p&gt;</summary>
    
    
    
    <category term="Exchange" scheme="http://www.slmt.tw/blog/categories/exchange/"/>
    
    
    <category term="usa" scheme="http://www.slmt.tw/blog/tags/usa/"/>
    
    <category term="exchange" scheme="http://www.slmt.tw/blog/tags/exchange/"/>
    
    <category term="uchicago" scheme="http://www.slmt.tw/blog/tags/uchicago/"/>
    
  </entry>
  
  <entry>
    <title>Jepsen 針對 MongoDB 4.2.6 的調查報告</title>
    <link href="http://www.slmt.tw/blog/2020/06/06/jepsen-mongodb-4-2-6/"/>
    <id>http://www.slmt.tw/blog/2020/06/06/jepsen-mongodb-4-2-6/</id>
    <published>2020-06-06T08:19:56.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>Jepsen 最近發表了一篇針對 MongoDB 4.2.6 的測試報告，並提出了許多他們發現的問題。 我覺得報告的內容非常具有參考價值，因此寫一篇簡介介紹報告的主要發現。</p><h2 id="Jepsen-是誰？"><a href="#Jepsen-是誰？" class="headerlink" title="Jepsen 是誰？"></a>Jepsen 是誰？</h2><p>Jepsen 是一間專門測試各種分散式系統，以驗證他們是否有達到他們宣稱的 Consistency 或 ACID 目標的公司。 這間公司有為許多著名的分散式系統測試過，例如：Cassandra、CockroachDB、Elasticsearch、Redis… 等等。 他們進行測試的標準非常嚴格，並且會提出公開的測試報告說明他們發現的主要問題等等。</p><h2 id="報告目標"><a href="#報告目標" class="headerlink" title="報告目標"></a>報告目標</h2><p>Jepsen 每篇報告都會有一個要驗證的目標，而這次針對 MongoDB 4.2.6 的目標是他們最新提出的「Full ACID Transactional Support」。</p><p>Transaction 在 Relational DBMS 算是標配的東西，意指將一系列的 DB 指令當成單一的實體處理。 ACID 則是 Transaction 概念提供的保證：</p><ul><li>Atomicity: 保證 transaction 的動作要嘛全完成要嘛全部沒完成</li><li>Consistency: 保證資料不違反 DBMS 以及使用者訂下的 constraint</li><li>Isolation: 保證執行中的 transaction 不會互相影響（但已執行完的不管）</li><li>Durability: 保證 committed 的 transaction 執行的效果一定會保存下來</li></ul><p>不過對於像是 MongoDB 這樣的 NoSQL 分散式系統來說，一般就不會支援 transaction 了。 因為分散式系統維護 transaction 保證的代價不低，因此許多追求 scalability 的系統都決定放棄這樣的保證。 因此 MongoDB 提出會支援 transaction 算是很不得了的成就。</p><h2 id="Data-Loss-by-Default"><a href="#Data-Loss-by-Default" class="headerlink" title="Data Loss by Default"></a>Data Loss by Default</h2><p>事實上，這篇報告並非 Jepsen 第一篇針對 MongoDB 的測試報告。 到目前為止，不含這個報告在內，他們已經發表了五篇報告了。 他們之前就發現 MongoDB 存在一些問題。</p><p>這篇報告一開宗就先回顧一下之前發現最大的問題：「在 MongoDB 上 committed 的指令預設情況下可能會因為 node failure 遺失資料。」</p><p>一般來說，一個分散式資料庫系統會確保你的資料複製到其他機器上之後，才會回報使用者「Committed (已提交)」。 然而，Jepsen 發現 MongoDB 的預設設定是「Read Concern: Local、Write Concern: 1」。 意思是說，資料讀取時只檢查本地端的資料，只要本地端是 committed 就可以讀取，寫入時只要一台電腦回報 ok，就向使用者回報完成。 因此只要那台回報的電腦 GG，資料可能就跟著 loss 了。</p><p>這也是為什麼 DB 江湖上流傳著這句話：</p><p><img src="1_tweet.png" alt="Tweet"></p><p>不過這個問題可以藉由將 MongoDB 的設計改成「Read concern: linearizable, Write concern: majority」解決。 因此嚴格來說也不算 bug。 只是預設的設定顯然是為了效能而犧牲 consistency 與 durability 而已。</p><h2 id="真的是「Full-ACID」嗎？"><a href="#真的是「Full-ACID」嗎？" class="headerlink" title="真的是「Full ACID」嗎？"></a>真的是「Full ACID」嗎？</h2><p>接下來，Jepsen 提出了 MongoDB 廣告詞的問題。 MongoDB 宣稱他們系統具有「Full ACID Support」，這並不是真的。 </p><p>熟悉 Transaction 機制的人我想應該都了解，如果要宣稱具有 Full ACID 的話，那們系統一定要能夠保證最嚴格的 Serializable Isolation。 換句話說，必須要讓多個 transaction 執行完的效果像是讓 transaction 依照某種順序依序執行的效果才行。</p><p>然而，MongoDB 實際上只支援到 Snapshot Isolation，意指他只能保證讀到的資料是來自某個資料庫快照的結果而已。 Snapshot Isolation 實際上會有所謂的 <a href="https://en.wikipedia.org/wiki/Snapshot_isolation#Definition">write skew anomaly 問題</a>，進而形成沒有 Serializable 的結果。 因此 MongoDB 不應該宣稱他們有支援 Full ACID。</p><p>Jepsen 也做了許多試驗，發現 transaction 執行的結果之間具有大小不等的 dependency cycle。 例如下面這張圖：</p><p><img src="2_cycle1.png" alt="Cycle 1"></p><p>代表他們發現兩個 transaction 之間互有依賴關係，這是一種常見用來判斷系統是否為 Serializable 的做法。</p><p>另外他們也發現許多像是下圖這種更大的 cycle：</p><p><img src="3_cycle2.png" alt="Cycle 2"></p><p>這些都證明了 MongoDB 並不支援 Serializable Isolation，因此不能說有 Full ACID support。</p><h2 id="系統出錯了…-但還是先-commit-再說？"><a href="#系統出錯了…-但還是先-commit-再說？" class="headerlink" title="系統出錯了… 但還是先 commit 再說？"></a>系統出錯了… 但還是先 commit 再說？</h2><p>除了上述的問題外，Jepsen 常常發現他們會觸發一些系統錯誤。 而以一般的思考來說，系統若發生錯誤，執行中的 transaction 應該要 abort 才對。 然而，Jepsen 發現 MongoDB 並不一定會 abort 執行中的 transaction，甚至可能會 commit 這些未完成的 transaction。 雖然這個問題很嚴重，但更嚴重的點在於，MongoDB 並沒有在文件中仔細說明某些錯誤發生時的可能原因與對應措施，導致開發者可能對系統會有錯誤的期待。</p><h2 id="MongoDB-發明了時光機？"><a href="#MongoDB-發明了時光機？" class="headerlink" title="MongoDB 發明了時光機？"></a>MongoDB 發明了時光機？</h2><p>Jepsen 在某個測試中發現，在 read concern 為 snapshot 以及 write concern 為 majority 的情況時，其中一個執行的 transaction 竟然會看到未來才寫入的結果！</p><p>大致的情況是，該 transaction 會先讀取一個 array，然後在該 array 中放入 1 這個值。 結果竟然該 transaction 在讀取該 array 時發現裡面已經有 1 這個值了！ 因為只有該 transaction 會在該 array 寫入這個值，而且讀取時根本就還沒對系統下達寫入的指令。 因此這個結果宛如 MongoDB 利用時光機先到未來，偷看到未來要寫入的值了！ 連 Jepsen 都忍不住調侃了一下。</p><p>他們最後研究了一下猜測大概是該 transaction 的動作實際上被執行了兩次。 可能第一次執行時失敗，在執行第二次時沒有清除第一次的結果，所造成的現象。（但是這其實不該發生，因為沒完成的 transaction 應該 rollback 來確保沒有任何未完成的動作結果保留在系統。）</p><h2 id="其他問題"><a href="#其他問題" class="headerlink" title="其他問題"></a>其他問題</h2><p>這邊在簡單列出一些他們發現的問題</p><ul><li>重複效果<ul><li>在發生 network partition 時，可能會出現某些 transaction 的效果被執行兩遍的情況</li></ul></li><li>其他種類的 dependency cycles。 細節就不提了，有興趣的話可以讀報告的說明。</li></ul><h2 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h2><p>從報告的這些發現，可以了解 MongoDB 並不具有官方宣稱的 Full ACID support。 除此之外，也具有許多 bug，像是可能讀取到未來寫入的值等問題。 但這些問題主要是反應在使用 transaction 的情境。 如果並不打算用 MongoDB 進行 transaction 的操作的話，應該就不太需要在意這些問題。 但仍須謹記 MongoDB 的預設設定並無法確保資料在分散式環境下一定會安全地保存至其他備份站點。</p><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ul><li>JEPSEN - MongoDB 4.2.6<ul><li><a href="http://jepsen.io/analyses/mongodb-4.2.6">http://jepsen.io/analyses/mongodb-4.2.6</a></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Jepsen 最近發表了一篇針對 MongoDB 4.2.6 的測試報告，並提出了許多他們發現的問題。 我覺得報告的內容非常具有參考價值，因此寫一篇簡介介紹報告的主要發現。&lt;/p&gt;
&lt;h2 id=&quot;Jepsen-是誰？&quot;&gt;&lt;a href=&quot;#Jepsen-是誰？&quot; clas</summary>
      
    
    
    
    <category term="DBMS" scheme="http://www.slmt.tw/blog/categories/dbms/"/>
    
    
    <category term="dbms" scheme="http://www.slmt.tw/blog/tags/dbms/"/>
    
    <category term="concurrency-control" scheme="http://www.slmt.tw/blog/tags/concurrency-control/"/>
    
    <category term="mongodb" scheme="http://www.slmt.tw/blog/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>千里馬計畫歷程分享 Part 2 - 尋找國外機構/指導教授</title>
    <link href="http://www.slmt.tw/blog/2020/02/21/uchicago-exchange-part-2/"/>
    <id>http://www.slmt.tw/blog/2020/02/21/uchicago-exchange-part-2/</id>
    <published>2020-02-21T13:19:56.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>本文介紹了我為了千里馬計畫如何尋找國外的指導教授、準備面談的方法和實際遇到的狀況。</p><a id="more"></a><h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>之前提到了為了追求更高的研究境界 (?)，我決定申請千里馬計畫。 為了要申請千里馬，必須要先準備以下幾份資料：</p><ol><li>外國語文能力鑑定證明</li><li><strong>國外研究機構或國外指導教授接受前往研究之同意函</strong></li><li>所長或博士指導教授出具之資格證明</li><li>所長或博士指導教授出具之推薦函</li><li>大學、碩士及博士學程歷年成績單</li><li>國外研究計畫書</li></ol><p>（注意：這個清單是 <a href="https://www.most.gov.tw/sci/ch/detail?article_uid=b3d896f9-c70a-4bec-8fcb-e387b51b2a54&menu_id=6b4a4661-9126-4d0c-897a-4022c82114a9&content_type=P&view_mode=listView">2019 年申請千里馬的規定</a>。每年的規定還是以每年公佈為準。）</p><p>其中本篇會以如何尋找國外機構或教授並取得同意函為目標說明。</p><h2 id="國外機構-教授同意函的目的"><a href="#國外機構-教授同意函的目的" class="headerlink" title="國外機構/教授同意函的目的"></a>國外機構/教授同意函的目的</h2><p><img src="letter.png" alt="Acceptance Letter"></p><p style='text-align: center'>圖一、我的國外教授接受函</p><p>國外機構或教授同意函指的簡單來說就是國外研究機構或指導教授發給你，表示有意願收你的證明。 如果學校本來就有跟某些姊妹校合作，就可以透過學校來媒合教授。 不過以博士生的狀況來說，如果不是為了出去玩的話，通常都會想要找跟自己研究主題相關的機構或教授做研究。 這種情況就比較難讓學校幫你找。 因此大多要自己主動出擊。</p><h3 id="我取得同意函的時間軸"><a href="#我取得同意函的時間軸" class="headerlink" title="我取得同意函的時間軸"></a>我取得同意函的時間軸</h3><ul><li>2019/5 月中旬 - 決定申請千里馬計畫</li><li>2019/6/9 - 跟指導老師討論要前往哪一位教授的 lab</li><li>2019/7/8 - 決定要前往的實驗室與連絡上國外的教授</li><li>2019/7/18 - 與國外教授線上面談</li><li>2019/7/30 - 收到國外教授的接受函（超驚險）</li><li>2019/7/30 - 千里馬申請校內期限</li></ul><h2 id="我如何找國外教授？"><a href="#我如何找國外教授？" class="headerlink" title="我如何找國外教授？"></a>我如何找國外教授？</h2><p>我的研究領域是「雲端資料庫系統」，更細部地說，我的研究主要在探討如何建立一個具有高度彈性、能自動分配負載、根據需求自動重新分配資料的分散式資料庫系統。 這個研究就算是在現在很熱門的資訊工程學系裡面，也算是很冷門的領域。 因此並不是到任何學校都有可以合作的教授。 </p><p>首先我先列了一個名單，包含了在資料庫系統領域之中比較出名，也相對比較年輕的幾位教授。 列的時候最主要考慮的點就是<strong>是否容易透過老師搭上線</strong>。 如果老師本來就有認識的話更好，這樣可以省去中間透過他人介紹的時間。 我也聽說過有人是靠之前發表論文時，參加國際會議建立的人脈。 不過這種通常是參加會議時就會先講好。</p><p>無論如何，名單列出之後，我跟我的指導老師討論，並由我的指導老師寄第一封信給國外教授作為開頭。 雖然不一定要由指導教授起頭，但是這種出國研究通常是實驗室與實驗室間的合作，因此由實驗室的老闆開頭我覺得也會比較合理，另一方面信件也比較不會被國外教授忽略XD。</p><p>由指導教授開頭之後，國外教授很快就表示願意考慮，不過要先經過一個面談。 我一看到要面談就非常緊張 (一生中從來沒有經歷過英文面試的 27 歲博士生)，不過想一想也是合理的，誰會想隨便收一個完全不知道要做什麼的人來自己的實驗室~</p><h2 id="面談準備"><a href="#面談準備" class="headerlink" title="面談準備"></a>面談準備</h2><p>因為這其實也不算正式的面試，所以我一開始也不是很確定該怎麼準備。 不過從國外教授的來信可以得知他主要想了解我的研究方向與研究目標。 因此我主要的準備方向就以說明我過去的研究，以及博士論文的方向等等為主。</p><p>另外我也參考了一些網路上的文章。 雖然很難找到交換面談的分享，但是卻可以找到很多申請 PhD Program 的面試經驗。 準備的方向可能稍稍不同，不過我認為還是很有參考價值的。 以下是我參考的幾篇文章：</p><ul><li>[心得] PhD program - unofficial interview<ul><li><a href="https://www.ptt.cc/bbs/studyabroad/M.1545196283.A.1C3.html">https://www.ptt.cc/bbs/studyabroad/M.1545196283.A.1C3.html</a></li></ul></li><li>[分享] On-campus/on-site interview 的安排與準備<ul><li><a href="https://www.ptt.cc/bbs/studyabroad/M.1299207712.A.906.html">https://www.ptt.cc/bbs/studyabroad/M.1299207712.A.906.html</a></li></ul></li><li>[心得] 理工人Skype Interview 101<ul><li><a href="https://www.ptt.cc/bbs/studyabroad/M.1515752113.A.EB9.html">https://www.ptt.cc/bbs/studyabroad/M.1515752113.A.EB9.html</a></li></ul></li><li>Phone Interview Questions and Answers<ul><li><a href="https://ezinearticles.com/?Phone-Interview-Questions-and-Answers&amp;id=1909293">https://ezinearticles.com/?Phone-Interview-Questions-and-Answers&amp;id=1909293</a></li></ul></li></ul><p>除此之外，我也建議稍微看過該教授的最近一兩年的論文。 不用看得很細，只要大概知道要解決的問題就好。 一方面可以先看看有沒有甚麼有興趣的方向，另一方面也可以讓教授覺得你準備充分XD</p><h3 id="模擬問題"><a href="#模擬問題" class="headerlink" title="模擬問題"></a>模擬問題</h3><p>我以我的研究方向與以上文章為基礎，自己設想了一些教授可能會問的問題：</p><ol><li>Cloud you introduce yourself?</li><li>Cloud you tell me what your research is mainly about?</li><li>What kind of researches you are interested in?</li><li>Why do you apply my lab?</li><li>What will you do after you get your degree?</li><li>Do you have any question?</li></ol><p>然後我再以這些題目為基礎，自己打了一份回應的草稿。 我先針對每個問題寫下大致想講的方向。 例如自我介紹我列出：年級、主修、主要研究興趣、擁有的程式技能等等。 接著再以這些關鍵字為中心，一一寫出口語化的回答。</p><p>完成草稿之後，我先試著說一遍。 說的途中如果發現說起來怪怪的地方，就修正句子。 若發現內容不通暢或有缺失，就補上更多內容。 建議是在這個階段能多加多少就加多少內容，因為實際上可能會因為教授打斷或者緊張等理由而無法全部提到。</p><p>後來證明這個練習對我幫助很大，至少在問到類似的問題時腦中可以很快閃過練習時的句子。</p><h2 id="實際面談狀況"><a href="#實際面談狀況" class="headerlink" title="實際面談狀況"></a>實際面談狀況</h2><p>我後來也記錄了一下實際面談大概的狀況：</p><ol><li>互相問好</li><li>教授開頭，大致說明一下他這次面談想了解的問題<ul><li>對研究的看法</li><li>研究的目標</li><li>研究怎麼收尾</li><li>在這一年交換想做甚麼</li><li>打算如何達到畢業目標</li><li>畢業後打算做甚麼</li></ul></li><li>我開始說明這次交換的目標<ul><li>主要圍繞在想要透過這次交換建立人脈、了解不同研究室的做事方式等等</li></ul></li><li>說明我的研究近況<ul><li>這段我就用到了預先準備好的句子</li></ul></li><li>我反問了一些教授的研究近況<ul><li>這邊就利用到了之前預先做的功課，可以多打探一下教授對哪種題目比較有興趣。 另一方面，我也藉由這個機會稍微休息一下，讓教授講講話XD。</li></ul></li><li>教授說明他最近的研究有哪些，未來可能會有興趣的題目<ul><li>我們花了很多時間在這裡，這邊我問了教授很多關於他近期研究的問題。 一方面我可以多了解教授的研究方向，另一方面互動式的對話也比單方面的演說來的容易。 很適合我這種英文不好的人XD</li></ul></li><li>我說明了我可能會有興趣的題目方向，並與教授討論可以研究的部分<ul><li>不過我們最後並沒有討論出一個確切題目，所以實際要做甚麼還是未定。 不過是有幾個可以做的方向。</li></ul></li><li>聊一下畢業後打算做甚麼</li><li>聊一下我最近在研究新的程式語言 (Rust)</li><li>教授問一些關於交換的問題<ul><li>打算甚麼時候來？</li><li>大概要待多久？</li><li>有任何補助嗎？</li><li>我有找其他教授嗎？</li><li>芝加哥大學有一些基本的 <a href="https://internationalaffairs.uchicago.edu/page/english-language-requirements">英文要求</a>，可能要確定是否有符合</li></ul></li><li>教授反問是否有其他問題，我也提出了一些問題與請求<ul><li>有甚麼研究相關的事情我可以先做嗎？</li><li>除了英文門檻之外，芝加哥大學是否有對交換生的額外要求？</li><li>提出我需要教授的一封同意函來申請補助</li></ul></li></ol><h2 id="收到同意函"><a href="#收到同意函" class="headerlink" title="收到同意函"></a>收到同意函</h2><p>在面談的當下，教授就表明願意收我了。 原本應該很快就能拿到同意函。 可是在面談快結束時，我又查到了與教授提供的英文門檻相異的另一個門檻。</p><ul><li>原本教授 <a href="https://internationalaffairs.uchicago.edu/page/english-language-requirements">查到的門檻</a> 是：托福總分須達 90 分以上。</li><li>我後來查到一個 <a href="https://internationalaffairs.uchicago.edu/page/non-degree-visiting-students-1#english">針對交換生的門檻</a> 是：托福口說要 18 分以上。</li></ul><p>當時我的托福成績已經拿到，總分雖然有過 90 分，但是口說只有 17 分。 因此我其實沒有過第二個門檻。 我當下請教國外教授，他也表示會幫我跟學校的負責人確認。</p><p>結果當時不知道是出了甚麼問題，據教授所說，他去信去問他們的負責人，但是遲遲沒有收到回覆。 我們也因此拖了一個多禮拜的時間。 最後因為千里馬申請的時間期限快到了，他就幫我先寫一份同意函，但加上一條「須通過英文門檻」的但書。</p><blockquote><p>… assuming all internal requirements are satisfied for University of Chicago’s non-degree visting students (such as <a href="https://internationalaffairs.uchicago.edu/page/english-language-requirements">https://internationalaffairs.uchicago.edu/page/english-language-requirements</a>).</p></blockquote><p>幸好我後來打電話問科技部承辦人，他們表示只要有教授表明願意收我就可以接受。 最後我也如願地拿到了補助！</p><h2 id="給其他申請人的建議"><a href="#給其他申請人的建議" class="headerlink" title="給其他申請人的建議"></a>給其他申請人的建議</h2><ol><li>一定要提早開始找教授，最好是預留一到三個月的時間。 我因為運氣不錯，第一位教授就願意收我。 如果沒收的話，可能要花更多時間找教授。</li><li>找國外教授時，如果能利用自己指導教授的人脈，最好盡量利用。</li><li>如果國外教授要求面試，建議先擬定一些可能的問題，然後擬好一份逐字稿練習。 可以增加口說的流暢程度與信心。</li><li>面談時也可以多對教授提問，可以避免自己一直講話很尷尬，而且有互動的話也比較不會緊張。</li></ol><p>祝各位找教授順利！</p><h2 id="我的全部時間軸"><a href="#我的全部時間軸" class="headerlink" title="我的全部時間軸"></a>我的全部時間軸</h2><p>以下紀錄從決定申請到現在為止發生的重要事件：</p><ul><li>2019/5 月中旬 - 決定申請千里馬計畫</li><li>2019/6/1 - 科技部系統開放申請</li><li>2019/6/9 - 跟指導老師討論要前往哪一位教授的 lab</li><li>2019/6/12 - 報名 TOEFL iBT 考試</li><li>2019/6/29 - TOEFL iBT 應考</li><li>2019/7/8 - 決定要前往的實驗室與連絡上國外的教授<ul><li>從研究要去哪間研究室到這步驟拖了點時間，因為當時正在忙著投一篇論文。 這也是為什麼要提早找教授，不然跟我一樣卡個論文 deadline 就可能會 delay。</li></ul></li><li>2019/7/9 - TOEFL iBT 開放線上查成績（總成績：93）</li><li>2019/7/18 - 與國外教授線上面談</li><li>2019/7/30 - 收到國外教授的接受函（超驚險）</li><li>2019/7/30 - 送出申請，並由校內統合送出</li><li>2019/11/29 - 科技部官網公布 <a href="https://www.most.gov.tw/folksonomy/detail?subSite=&l=ch&article_uid=342f7b32-5bc4-4885-9607-32d946c067cc&menu_id=d3c30297-bb63-44c5-ad30-38a65b203288">通過名冊</a></li><li>2019/12/4 - 通知國外指導教授並開始申請 DS-2019 (申請美國簽證必備文件)</li><li>2019/12/26 - 參加芝加哥大學英文能力測驗 (APEA)</li><li>2020/1/7 - 收到芝加哥大學通知通過 APEA 測驗，並完成 DS-2019 申請</li><li>2020/1/16 - 收到 DS-2019</li><li>2020/1/21 - 送出校內簽約資料，以申請補助款<ul><li>這個需要付 DS-2019 的副本，加上我到 1/18 都不在台灣。 所以拖到這個時候才提出申請。</li></ul></li><li>2020/1/29 - 填寫 DS-160 以申請簽證</li><li>2020/2/3 - 到郵局完成簽證費繳費，並預約 AIT 面試時間</li><li>2020/2/18 - 到台北內湖 AIT 進行面試，當場收取護照</li><li>2020/2/20 - 收到護照並附上 J-1 Visa</li><li>預計 2020/3/30 前抵達芝加哥大學</li></ul><h2 id="待續…"><a href="#待續…" class="headerlink" title="待續…"></a>待續…</h2><p>之後預計說明如何準備托福~</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介紹了我為了千里馬計畫如何尋找國外的指導教授、準備面談的方法和實際遇到的狀況。&lt;/p&gt;</summary>
    
    
    
    <category term="Exchange" scheme="http://www.slmt.tw/blog/categories/exchange/"/>
    
    
    <category term="usa" scheme="http://www.slmt.tw/blog/tags/usa/"/>
    
    <category term="exchange" scheme="http://www.slmt.tw/blog/tags/exchange/"/>
    
    <category term="uchicago" scheme="http://www.slmt.tw/blog/tags/uchicago/"/>
    
  </entry>
  
  <entry>
    <title>千里馬計畫歷程分享 Part 1 - 準備申請</title>
    <link href="http://www.slmt.tw/blog/2020/01/27/uchicago-exchange-part-1/"/>
    <id>http://www.slmt.tw/blog/2020/01/27/uchicago-exchange-part-1/</id>
    <published>2020-01-27T16:42:54.000Z</published>
    <updated>2022-04-25T08:49:17.092Z</updated>
    
    <content type="html"><![CDATA[<p>我在 2019 年 5 月左右決定在博士生涯的最後一年利用科技部的千里馬計畫補助出國。 現在已經到了進到最後的準備步驟了。 我想最好將我中間過程的經歷與準備記錄下來，以幫助未來也想要申請補助出國去看看的博士生。</p><a id="more"></a><h2 id="計畫介紹"><a href="#計畫介紹" class="headerlink" title="計畫介紹"></a>計畫介紹</h2><p>千里馬計畫目前的正式名稱是「科技部補助博士生赴國外研究」。 因此如果要去科技部網站搜尋的話，用正式名稱比較容易找到資料。</p><p>這個計畫簡單來說就是政府以非常寬鬆的條件提供一年 90 萬新台幣（2019 年以前是 60 萬）的補助，讓在台灣的博士生能夠出國到國外的研究機構進行交流與研究。 補助會先用借款的方式在出國前提撥給受補助人，然後回國之後依照實際在當地執行計畫的天數依比例計算該補助多少。 如果實際上借用的金額高於應該補助的金額，則需要將多領的部分歸還給政府。 例如實際上只待 300 天，那麼補助金額就是 (300 / 365 * 90) 萬。 不過除此之外這筆補助使用上沒有任何限制，而且金額在大部分的國家很夠用。 只要省吃儉用一點，就有很大機會不需要動用到自己的錢。 因此對想要出國的博士生來說算是實惠的補助。</p><p>那這個補助有什麼應盡義務嗎？ 除了計畫結案時要繳交一份報告外，最重要的義務就是計畫結束後必須要回台灣完成學業。 相較於許多企業的補助會要求必須要去公司上班等等，這種條件基本上等於沒有條件。 所以我很推薦想要在博士生生涯出國看看的人申請。</p><p>2019 年計劃的 <a href="https://www.most.gov.tw/sci/ch/detail?article_uid=b3d896f9-c70a-4bec-8fcb-e387b51b2a54&menu_id=6b4a4661-9126-4d0c-897a-4022c82114a9&content_type=P&view_mode=listView">申請說明網頁</a></p><h2 id="我怎麼會想申請呢？"><a href="#我怎麼會想申請呢？" class="headerlink" title="我怎麼會想申請呢？"></a>我怎麼會想申請呢？</h2><p>我一開始得知這個計畫是來自於系上的一個博士生學長，他當時申請到京都的大學交換。 聽說之後，我就稍微研究一下，發現這個補助申請並沒有想像中困難，而且金額不小，對家裡不富裕的我來說算是很好的機會，於是就開始思考我是不是想出國看看呢？</p><p>做了很多考量之後，我最後認為最重要的因素就是想要脫離現在的舒適圈。 我在清華大學從大學一路念上來，包括碩士與博士已經待了將近十年的時間。 我從來都沒有跳脫這個環境，這樣我認為無論如何都對我未來很不利，而且思考的方式也許也缺乏變化。 我想要到其他環境親眼看看別人跟我們有何不同。 再來另一方面我覺得也需要出國去拓展一下人脈，大家常說多結交朋友絕對不是壞事。 無論以後打算往哪個方面繼續，人脈一定可以派得上用場的。</p><p>不過我最後決定要申請的時候已經有點晚了。 千里馬計畫是每年 6/1 開放申請到 7/31。 我決定要申請的時候已經五月中了。 因為準備申請資料也非常花費時間，包括要考英文檢定（如果以前沒考過的話）、聯絡國外機構取得同意函等等。 因此建議正在思考的人提早下決定，想要申請的人最好三月就開始準備。</p><h2 id="申請需要的準備"><a href="#申請需要的準備" class="headerlink" title="申請需要的準備"></a>申請需要的準備</h2><p>申請千里馬根據 2019 年的規定需要準備以下資料：</p><ol><li>外國語文能力鑑定證明<ul><li>關於能力鑑定證明有詳盡的 <a href="https://www.most.gov.tw/most/attachments/2ebfb38f-58ed-4a24-875b-77d3c5443e6c">規定</a>，每年可能會有些微的變化。 歷年來最大的不同在於取消最低門檻（例如托福需達總分 79 分）。</li><li>通常就是去講哪種語言的國家就要付哪種語言證明。 例如日本就日檢，美國就托福、雅思等等。</li></ul></li><li>國外研究機構或國外指導教授接受前往研究之同意函<ul><li>需有國外機構負責人或指導教授簽名</li></ul></li><li>所長或博士指導教授出具之資格證明<ul><li>千里馬說明網頁上有固定格式的文件，下載請老師簽名即可。</li></ul></li><li>所長或博士指導教授出具之推薦函<ul><li>就是推薦信，請指導老師寫好並簽名後，掃描並請老師從他的科技部帳號上傳。</li></ul></li><li>大學、碩士及博士學程歷年成績單<ul><li>學校提供的成績單。</li><li>這邊有個有趣的狀況是，因為我是碩士念到一半直攻博士，所以我同一份成績單內有碩士跟博士的修課成績。 這邊只要在成績單上註明哪些是碩士哪些是博士就沒有問題。</li></ul></li><li>國外研究計畫書<ul><li>20 頁以內的研究計畫書。 之後另外說明。</li></ul></li></ol><p>更詳細的說明可以參考官方的 <a href="https://www.most.gov.tw/most/attachments/65ca5c42-9ebb-4325-b7e6-df44fd10a9f6">作業要點</a> (注意這是 2019 年的作業要點)。</p><p>上面這些資料中，最需要提早準備的就是第 1 跟 2 項。 第 1 項是因為考試需要時間準備，還要等成績出來。 例如托福我花了一個月左右準備，然後兩週等成績出來。 第 2 項則是因為要看找不找得到收你的國外教授，可能需要跟好幾位教授面談，最後還需要請願意收的教授開同意函給你。 花費時間快的話可能一個禮拜搞定，久的話可能會弄到好幾個月。 我是運氣不錯不到一個月就搞定，不然可能就來不及申請。</p><p>另外要注意一點，雖然科技部寫說 7/31 截止，但實際上每個學校會有自己的繳交期限。 例如我們學校（清大）在 7/30 中午就截止了，建議問問學校的全球或國際事務處。</p><h2 id="我的時間軸"><a href="#我的時間軸" class="headerlink" title="我的時間軸"></a>我的時間軸</h2><p>以下紀錄從決定申請到現在為止發生的重要事件：</p><ul><li>2019/5 月中旬 - 決定申請千里馬計畫</li><li>2019/6/1 - 科技部系統開放申請</li><li>2019/6/9 - 跟指導老師討論要前往哪一位教授的 lab</li><li>2019/6/12 - 報名 TOEFL iBT 考試</li><li>2019/6/29 - TOEFL iBT 應考</li><li>2019/7/8 - 決定要前往的實驗室與連絡上國外的教授<ul><li>從研究要去哪間研究室到這步驟拖了點時間，因為當時正在忙著投一篇論文。 這也是為什麼要提早找教授，不然跟我一樣卡個論文 deadline 就可能會 delay。</li></ul></li><li>2019/7/9 - TOEFL iBT 開放線上查成績（總成績：93）</li><li>2019/7/18 - 與國外教授線上面談</li><li>2019/7/30 - 收到國外教授的接受函（超驚險）</li><li>2019/7/30 - 送出申請，並由校內統合送出</li><li>2019/11/29 - 科技部官網公布 <a href="https://www.most.gov.tw/folksonomy/detail?subSite=&l=ch&article_uid=342f7b32-5bc4-4885-9607-32d946c067cc&menu_id=d3c30297-bb63-44c5-ad30-38a65b203288">通過名冊</a></li><li>2019/12/4 - 通知國外指導教授並開始申請 DS-2019 (申請美國簽證必備文件)</li><li>2019/12/26 - 參加芝加哥大學英文能力測驗 (APEA)</li><li>2020/1/7 - 收到芝加哥大學通知通過 APEA 測驗，並完成 DS-2019 申請</li><li>2020/1/16 - 收到 DS-2019，開始申請 J-1 Visa (交換生簽證)</li><li>2020/1/21 - 送出校內簽約資料，以申請補助款<ul><li>這個需要付 DS-2019 的副本，加上我到 1/18 都不在台灣。 所以拖到這個時候才提出申請。</li></ul></li><li>現在 (2020/1/28) - 正在申請 J-1 Visa 中</li><li>預計 2020/3/30 前抵達芝加哥大學</li></ul><p>大家可以注意到我在 7/30 才拿到接受函，這顯示了提早開始接洽的重要性。 其實國外教授面談完不久就表明可以收我，可是我們後來發現芝加哥大學有額外的英文門檻，而且我的托福的口說成績不夠高。 這中間的時間都在跟該校的國際事務處確認我是否需要通過該門檻（因為該校的規定上寫的有點出入）。 結論是我還是要通過該門檻，可是也來不及考托福了，所以國外教授還是先給我接受函，但是在信上加上以下但書：</p><blockquote><p>… assuming all internal requirements are satisfied for University of Chicago’s non-degree visting students (such as <a href="https://internationalaffairs.uchicago.edu/page/english-language-requirements">https://internationalaffairs.uchicago.edu/page/english-language-requirements</a>).</p></blockquote><p>後來科技部也接受了，代表只要有教授表明願意收我就好。 至於後來怎麼通過該校的英文門檻… 後來也不是用托福通過，而是參加該校的另一個測驗 (APEA)，這點之後再做說明。</p><h2 id="待續…"><a href="#待續…" class="headerlink" title="待續…"></a>待續…</h2><p>之後預計說明：我怎麼撰寫研究計畫書、怎麼準備托福、怎麼跟教授面談…</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;我在 2019 年 5 月左右決定在博士生涯的最後一年利用科技部的千里馬計畫補助出國。 現在已經到了進到最後的準備步驟了。 我想最好將我中間過程的經歷與準備記錄下來，以幫助未來也想要申請補助出國去看看的博士生。&lt;/p&gt;</summary>
    
    
    
    <category term="Exchange" scheme="http://www.slmt.tw/blog/categories/exchange/"/>
    
    
    <category term="usa" scheme="http://www.slmt.tw/blog/tags/usa/"/>
    
    <category term="exchange" scheme="http://www.slmt.tw/blog/tags/exchange/"/>
    
    <category term="uchicago" scheme="http://www.slmt.tw/blog/tags/uchicago/"/>
    
  </entry>
  
  <entry>
    <title>論文筆記 - SLOG: Serializable, Low-Latency, Geo-replicated Transactions</title>
    <link href="http://www.slmt.tw/blog/2019/10/20/paper-slog/"/>
    <id>http://www.slmt.tw/blog/2019/10/20/paper-slog/</id>
    <published>2019-10-20T12:08:27.000Z</published>
    <updated>2022-04-25T08:49:17.088Z</updated>
    
    <content type="html"><![CDATA[<p>今天介紹的這篇論文發表於今年的 PVLDB 期刊。 這篇論文發表了一種新的分散式 SQL 資料庫系統架構，適用的規模可以橫跨世界各區的資料中心，主要針對 Online Transactional Processing (OLTP) 的環境。 他們想要<strong>同時達成</strong>近代分散式資料庫系統的三大目標：(1) Strict Serializability、(2) 低 latency 與 (3) 高 throughput。這是目前尚未有人能完美同時解決的目標。</p><a id="more"></a><h2 id="基本資料"><a href="#基本資料" class="headerlink" title="基本資料"></a>基本資料</h2><ul><li>論文作者群：Kun Ren, Dennis Li, Daniel J. Abadi</li><li>研究機構：The University of Maryland</li><li>發表會議/期刊：Very Large Database (VLDB) 2019 年期刊 <a href="#r1">[1]</a></li></ul><h2 id="需要具備的知識"><a href="#需要具備的知識" class="headerlink" title="需要具備的知識"></a>需要具備的知識</h2><ul><li>知道 Transaciton 是甚麼</li><li>知道 Deterministic Database System <a href="#r2">[2]</a> 的基本概念</li></ul><h2 id="Geo-replicated-DBMS"><a href="#Geo-replicated-DBMS" class="headerlink" title="Geo-replicated DBMS"></a>Geo-replicated DBMS</h2><p>在開始了解論文的問題前，要先理解論文假設的環境。 這個論文假設一個資料庫系統是跑在橫跨世界各地的資料中心的系統。 這類系統我們通常會稱之為 Geo-replicated Database Management System (DBMS)，因為它通常會將資料複製很多份儲存在各地的資料中心中。</p><p>下圖展示了一個分散在三個地區的資料庫系統。 通常一個資料中心會保有一份完整的資料，然後每一個資料中心內的資料會再切分成多個不相交的 partition。 因此下圖之中，一共有三份備份 (replica)，然後每個資料中心內有三個 partition。 資料中心之間會需要時常同步資料來保持資料的一致性 (consistency)。</p><p><img src="geo-dbms.png" alt="Geo-replicated DBMS"><br>圖一、Geo-replicated Database Management System</p><p>這種系統架構已經遍布於各大主要的分散式資料庫中。 這樣的設計不外乎兩個目的：</p><ol><li>High availability</li></ol><ul><li>因為資料有很多備份，如果一份無法服務就可以由其他備份不間斷地服務使用者。</li></ul><ol start="2"><li>Low Read Latency</li></ol><ul><li>可以優先從地理位置較近的資料中心更快速地讀取需要的資料。</li></ul><h2 id="近代分散式-OLTP-SQL-系統的三大目標"><a href="#近代分散式-OLTP-SQL-系統的三大目標" class="headerlink" title="近代分散式 OLTP SQL 系統的三大目標"></a>近代分散式 OLTP SQL 系統的三大目標</h2><p>這篇論文假設在前一節說明的 Geo-replicated DBMS 之中，想要再額外達成三個目標：</p><ol><li>Strict Serializability</li><li>(對使用者來說) Low Write latency</li><li>(對管理員來說) High throughput</li></ol><p>對於不熟悉 SQL 資料庫系統的人，可能不太能理解甚麼是 strict serializability。 Strict serialiability 是一種保證。 如果系統保證這點，就代表它保證所有執行的交易造成的結果與某個依序執行交易的結果相同。 有學過 transaction 的人，都知道 transaction 內可能包含多筆操作，因此需要額外的機制去確保許多 transaction 的操作同時發生不會導致結果異常。</p><p>這件事情放到分散式系統又更複雜一點。 在分散式系統上除了保障一台機器內的 serialiability 之外，還要確保：「從系統之中執行的 transaction 裡面任意挑出兩個 transaction X 跟 Y，無論我拿到哪個 replica，其執行順序都是相同的。」 也就是說，如果今天台灣 replica 執行的順序是 X-&gt;Y，那麼拿到美國或歐洲的 replica 也要是相同的順序。</p><p>乍聽之下似乎很合理，但是實際上要做到可能沒那麼容易。 假設 X 是送到台灣 replica，Y 是送到美國 replica，這樣很有可能在台灣執行就是先 X 再 Y，在美國則是先 Y 再 X。</p><p>為了要解決這個問題，近幾年有幾個熱門方向：</p><ul><li>Google Spanner <a href="#r3">[3]</a> - 在世界各地的資料中心放原子鐘，以取得一個全世界的絕對時間為 transaction 排序。 Transaction 完成時必須使用一種 consensus protocol (例如 Paxos <a href="#r13">[13]</a>) 讓全世界的資料中心知道它的存在。 CockroachDB <a href="#r4">[4]</a>、TiDB <a href="#r5">[5]</a> 等系統屬於它的變形。</li><li>Deterministic Databases <a href="#r2">[2]</a> - 在 transaction 執行之前，先使用 consensus protocol 讓全世界的資料中心知道它的存在，並確定執行順序。 然後用 deterministic execution 確保執行順序。 H-Store <a href="#r6">[6]</a>、VoltDB <a href="#r7">[7]</a>、Calvin <a href="#r8">[8]</a> 等系統屬於此類。</li><li>Weak Consistency - 放棄 strict serializability 這種嚴格的保證。 讓系統在資料剛寫入的時候可能會在資料中心間不太一致，但是在某些狀況下或者最後會一致 (如：Dynamo <a href="#r9">[9]</a>、Cassandra <a href="#r10">[10]</a>)。 甚至可能乾脆只保證較低的 isolation，例如 snapshot isolation (如：Walter <a href="#r11">[11]</a>、Jessy <a href="#r12">[12]</a>)。</li></ul><p>這些方向都有些問題，Google Spanner 與 Deterministic Database 的 latency 不低，因為全世界的資料中心要做一個 consensus。 但是第三種又只有保證較低的 consisntency。 因此沒有人同時完成這三大目標。 不過他們的共通點就是有很高的 throughput。</p><h2 id="主要發現"><a href="#主要發現" class="headerlink" title="主要發現"></a>主要發現</h2><p>這篇論文依賴了兩個主要發現來達成這些目標：</p><ol><li>使用者通常都會在同一個地區 (或資料中心) 存取自己的資料。</li><li>並非所有 transaction 之間都一定要有 global order，不衝突的 transaction 之間的順序可以任意排序。</li></ol><p>第一個發現很容易就可以理解，因為人很少會離開自己的居住區，因此最近的資料中心通常都不會改變。第二個發現可能就不是那麼直覺。簡單來說，如果今天有兩個 transaction T1 跟 T2。如果 T1 修改資料 A，T2 修改資料 B，那麼 T1、T2 無論誰先誰後其實都不影響結果。因此這兩個 transaction 無論如何排序，都不影響 serializability。</p><p>這篇論文基於這兩個概念，提出了 SLOG 系統架構。</p><h2 id="SLOG-主要概念：Home-Region"><a href="#SLOG-主要概念：Home-Region" class="headerlink" title="SLOG 主要概念：Home Region"></a>SLOG 主要概念：Home Region</h2><p>SLOG 架構之中主要的概念就是：每一組 records 可能會被跨資料中心複製很多份 replica，但是只有一份 replica 是主要的 (primary)。 存放這個主要的 replica 的區域就叫做 home region。 這個時候，一般馬上就會想到 master-slave 架構。 那 SLOG 跟那種架構又有什麼不同呢？ 主要差異是在常見的 master-slave 架構之中，replica 通常是以整個 database 作為單位，其中 primary replica 一定是整組 database 放在同一個區域中。但是 SLOG 提出的架構是以<strong>一組 records</strong> 作為單位。也就是說，可能有些 records 的 primary replica 在台灣，有些 records 在美國。 如下圖所示，每個方塊代表一組 records。 黑色代表 primary。 A 組的 home region 是 region 1，B 組則是在 region 2。</p><p><img src="home-region.png" alt="Home Region"><br>圖二、Home Region 示意圖，每個方塊代表一組資料的 replica。</p><h3 id="Single-home-Transactions"><a href="#Single-home-Transactions" class="headerlink" title="Single-home Transactions"></a>Single-home Transactions</h3><p>首先這種做法的好處跟 master-slave 架構相同。 如果今天我想要存取的資料的 home region 都在同一個資料中心 (這種 transaction 被稱之為 single-home transaction)。 此時我就只需要對資料中心內的機器進行 concurrency 的管控，其他資料中心的 replica 只要確保有複製到 primary 的結果就好。 因此 SLOG 在 home 完成 transaction 之後，就會把 log 複製到 slave。 一旦有 N 個資料中心回覆 (N 由使用者設定)，就可以答覆使用者 transaction 完成。 如此一來，就可以省下跨越資料中心做的 concurrency control 以及 two phase commit 這種花時間的 protocol。 這些 protocol 可能要所有資料中心參與，並且花費多個 round-trip time。</p><p>至於 slave 要怎麼樣複製 primary replica 的結果？ 論文這裡使用了 Calvin <a href="#r8">[8]</a> 的 deterministic database 架構，因此複製的時候只需要複製 master 上的 transaction 的指令，在 slave 上只要再跑一次同樣序列的指令就可以得到相同結果 (對這個有興趣的可以看 request log 這篇論文 <a href="#r14">[14]</a>)。</p><p>當然，因為有 home region 的關係，所有想要存取該組資料的 transaction 都必須要導向 home region。 例如，以圖二來說，使用者可能會在 region 2 存取 A 組的資料，雖然 region 2 本身有 A 組的備份，但仍會把請求轉給 region 1 處理。 所以才會假設使用者通常不會離自己存取的資料太遠。 不過在這種情況下，論文也有提出一種搬移 home region 的機制，以拉近 home region 與使用者的距離。 細節的部分可以參見論文。</p><h3 id="Multi-home-Transactions"><a href="#Multi-home-Transactions" class="headerlink" title="Multi-home Transactions"></a>Multi-home Transactions</h3><p>那麼 SLOG 這樣的設計相較於一般 primary-slave 架構又有什麼難點呢？ 因為不像一般的 primary-slave 架構，所有資料的主控權都同一個資料中心，導致仍有可能會發生某個 transaction 改的一部分資料的 home region 在台灣，另一部資料的 home region 在美國這種情況。 這種 transaction 就叫做 multi-home transaction。 對這種 transaction 還是會需要在這些資料中心之間做 concurrency control 來維持資料的正確性。 這個部分也是這篇論文的主要貢獻。</p><p>關於 multi-home transactions 的處理，我們可以分成兩個部分來看：「multi-home tx 跟 multi-home tx 之間」與「multi-home tx 跟 single-home tx 之間」。</p><p>針對「multi-home tx 跟 multi-home tx 之間」，這邊論文採用了 deterministic database <a href="#r2">[2]</a> 的概念。 在一開始先把所有 multi-home transactions 透過一個 total ordering protocol 進行排序，確定了這些 transaction 的 global order 後，再送到 deterministic execution engine 執行，以確保 consistent 的結果。 換句話說，對於這種 transaction，就使用之前其他論文 <a href="#r2">[2]</a> 的做法。 如圖三，Tx G.1 與 Tx G.2 無論送到哪個 region，都會被強制送進 total ordering layer 進行全域的排序之後，再送到下面的系統開始執行。</p><p><img src="multi-home-1.png" alt="Multiple Home - Total Oredering"><br>圖三、Multi-home Transactions 會進行全域排序</p><p>排序完成之後，在正式開始執行這些 transaction 之前，會先為每個 transaction 建立多個 lock transaction。 每個 lock transaction 負責鎖住某個 region 內的資料。 因此一個 multi-home transaction 存取的資料的 home region 有幾個，就會產生幾個 lock transaction。 如圖四，Tx G.1 想要存取 region 1 跟 2 的資料，所以產生了兩個 lock transaction G.1.1 跟 G.1.2，並送到所屬的 home region。 而當一個 region 的 lock 都拿到之後，這個 lock transaction 就會依循 replication 的規則被複製到其他 region。 而 multi-home transaction 的本體只會在一個 region 收到所有 lock transaction 的 log 時 (確保所有參與的 region 都把資料鎖住)，該 region 才會執行這個 transaction。</p><p><img src="multi-home-2.png" alt="Multiple Home - Lock Transactions"><br>圖四、Multi-home Transactions 會再產生 Lock Transaction</p><p>如果對分散式資料庫系統有點了解的人，應該可以發現第一步的 total ordering (全域排序) 其實就足以保證 consistency。 那為什麼還要多此一舉用什麼 lock transaction 呢？ 這主要是為了第二種狀況：「multi-home tx 跟 single-home tx 之間」的 consistency。 因為 single-home transaction 不會參與全域排序，因此若沒有額外處理的話，可能就會跟 multi-home transaction 發生錯序的情況。 這種情況下 lock transactions 的插入就可防止這種事情發生。 因為 lock transaction 會把資料鎖住，而且必須等所有 lock transaction 都完成才會執行，所以可以確保 multi-home transaction 跟 single-home transaction 的先後順序。</p><p>如圖五所示，一個 multi-home transaction tx G.1 跟三個 single-home transactions tx 1.1, tx 1.2, tx 2.1 同時出現。 那他們可能會出現如圖五的執行順序。 可以看到經由保證這樣的 global order，可以得到如圖五右方的紫色框框內的順序。 而這個順序可以經由複製 log 傳播到所有資料中心。 要注意的是，我們並沒有限制 tx 1.1 與 tx 2.1 的先後順序。 因為這兩個 tx 其實存取的資料沒有交集，因此執行的順序其實不重要！ 這也是利用了最一開始說的第二個發現。</p><p><img src="multi-home-3.png" alt="Multiple Home - 跟 Single-home 同時出現"><br>圖五、Multi-home Transactions 與 Single-home Transactions 同時出現</p><p>以上就是這篇論文的主要概念。 我只是說明了這篇論文最主要的概念與貢獻而已，想要知道更詳細的資訊，像是 protocol 或是其他的細節的話可以閱讀論文。</p><h2 id="實驗"><a href="#實驗" class="headerlink" title="實驗"></a>實驗</h2><p>論文上有許多實驗，這邊我們只看一個實驗就好。 圖六展示了他們的系統跑在 YCSB Benchmark 上 latency 的累積分佈函數圖。 線越左邊代表大多的 transaction latency 越低。 SLOG-B 代表 transaction 在一個 region 完成就直接回覆使用者，SLOG-HA 代表會等待 log 複製到 N 台機器後才回覆使用者。 0%, 1%, 10%, 100% mh 那個是代表有多少比例的 multi-home transactions。 詳情可以看論文。</p><p><img src="ex.png" alt="實驗"><br>圖六、YCSB Lateny CDF</p><p>這個實驗的結論就是，只要 multi-home transaction 不要多得太誇張，都可相較於 baseline Calvin <a href="#r8">[8]</a> 大幅降低 latency。 我認為這個實驗結果是很驚人的，因為這篇論文提出的架構無疑可以確保 strict serializability (請參照論文上的證明)。 而因為使用了 deterministic database 的架構，也確保了 high throughput (其他實驗也有證明這點)。 最後也有較低的 latency，因此這也許會成為下一代的資料庫系統架構。</p><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p><a name='r1'>[1]</a> <a href="http://www.vldb.org/pvldb/vol12.html">http://www.vldb.org/pvldb/vol12.html</a><br><a name='r2'>[2]</a> Thomson, Alexander, and Daniel J. Abadi. “The case for determinism in database systems.” Proceedings of the VLDB Endowment 3.1-2 (2010): 70-80.<br><a name='r3'>[3]</a> Corbett, James C., et al. “Spanner: Google’s globally distributed database.” ACM Transactions on Computer Systems (TOCS) 31.3 (2013): 8.<br><a name='r4'>[4]</a> <a href="https://github.com/cockroachdb/cockroach">https://github.com/cockroachdb/cockroach</a><br><a name='r5'>[5]</a> <a href="https://github.com/pingcap/tidb">https://github.com/pingcap/tidb</a><br><a name='r6'>[6]</a> <a href="https://hstore.cs.brown.edu/">https://hstore.cs.brown.edu/</a><br><a name='r7'>[7]</a> <a href="https://www.voltdb.com/">https://www.voltdb.com/</a><br><a name='r8'>[8]</a> Thomson, Alexander, et al. “Calvin: fast distributed transactions for partitioned database systems.” Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. ACM, 2012.<br><a name='r9'>[9]</a> <a href="https://aws.amazon.com/tw/dynamodb/">https://aws.amazon.com/tw/dynamodb/</a><br><a name='r10'>[10]</a> <a href="http://cassandra.apache.org/">http://cassandra.apache.org/</a><br><a name='r11'>[11]</a> Y. Sovran, R. Power, M. K. Aguilera, and J. Li. Transactional Storage for Geo-replicated Systems. In Proceedings of the Symposium on Operating Systems Principles, SOSP ’11, pages 385–400, 2011.<br><a name='r12'>[12]</a> M. S. Ardekani, P. Sutra, and M. Shapiro. Non-monotonic Snapshot Isolation: Scalable and Strong Consistency for Geo-replicated Transactional Systems. In Proceedings of the 2013 IEEE 32nd International Symposium on Reliable Distributed Systems, SRDS ’13, pages 163–172, 2013.<br><a name='r13'>[13]</a> Lamport, Leslie. “Paxos made simple.” ACM Sigact News 32.4 (2001): 18-25.<br><a name='r14'>[14]</a> N. Malviya, A. Weisberg, S. Madden, and M. Stonebraker, “Rethinking main memory OLTP recovery,” in Data Engineering (ICDE), 2014 IEEE 30th International Conference on, 2014, pp. 604-615.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天介紹的這篇論文發表於今年的 PVLDB 期刊。 這篇論文發表了一種新的分散式 SQL 資料庫系統架構，適用的規模可以橫跨世界各區的資料中心，主要針對 Online Transactional Processing (OLTP) 的環境。 他們想要&lt;strong&gt;同時達成&lt;/strong&gt;近代分散式資料庫系統的三大目標：(1) Strict Serializability、(2) 低 latency 與 (3) 高 throughput。這是目前尚未有人能完美同時解決的目標。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://www.slmt.tw/blog/categories/research/"/>
    
    <category term="Paper" scheme="http://www.slmt.tw/blog/categories/research/paper/"/>
    
    
    <category term="paper" scheme="http://www.slmt.tw/blog/tags/paper/"/>
    
    <category term="dbms" scheme="http://www.slmt.tw/blog/tags/dbms/"/>
    
    <category term="distributed-systems" scheme="http://www.slmt.tw/blog/tags/distributed-systems/"/>
    
    <category term="oltp" scheme="http://www.slmt.tw/blog/tags/oltp/"/>
    
  </entry>
  
  <entry>
    <title>使用 Travis CI 來自動發布 Hexo Blog</title>
    <link href="http://www.slmt.tw/blog/2019/04/26/hexo-auto-deploy/"/>
    <id>http://www.slmt.tw/blog/2019/04/26/hexo-auto-deploy/</id>
    <published>2019-04-26T05:27:04.000Z</published>
    <updated>2022-04-25T08:49:17.088Z</updated>
    
    <content type="html"><![CDATA[<p>最近將我的部落格改成使用 <a href="https://travis-ci.com/">Travis CI</a> 來自動發布，幫我省去在自己電腦上編譯再上傳到 Github Pages 的麻煩。 因此我將我的作法寫下來，幫助其他用 Hexo 建立 Blog 的人來設定自動發布。</p><a id="more"></a><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>這邊使用的方式是讓 Travis CI 來幫我們自動產生網頁，並將產生後的網頁自動上傳到 Github Pages 的做法。</p><p>Travis CI 是一種 continous integration (CI) 的服務，他可以連結到 Github 的 repository 上面，並自動幫你執行預先寫好的 script。 Travis CI 通常用於測試 repository 上面的程式碼是否正常，能否正常編譯，是否能透過 test cases 等等。 特別很多 open source project 會在接受其他人的 merge request 前會先確定通過 Travis CI 的測試。</p><p>因為 Travis CI 可以執行自訂的 script，並且會在 repository 上有新的 commit 上傳時被自動觸發，因此許多人會用 Travis CI 來自動發布程式碼。</p><h2 id="步驟"><a href="#步驟" class="headerlink" title="步驟"></a>步驟</h2><p>以下說明如何用 Travis CI 自動發布。 假設你在 Github 上已經擁有一個 repository，叫做 <code>blog</code>。</p><h3 id="第一步：申請-Travis-CI-帳號"><a href="#第一步：申請-Travis-CI-帳號" class="headerlink" title="第一步：申請 Travis CI 帳號"></a>第一步：申請 Travis CI 帳號</h3><p>請先到 <a href="https://travis-ci.com/">Travis CI</a> 網站申請一個帳號。</p><p>注意如果搜尋的話會發現 Travis CI 有兩個網站：一個是 <a href="https://travis-ci.com/">travis-ci.com</a>，另一個是 <a href="https://travis-ci.org/">travis-ci.org</a>。 .org 是比較早出來的服務，.com 則是後來為了商業目的而建立的網站。 <a href="https://blog.travis-ci.com/2018-05-02-open-source-projects-on-travis-ci-com-with-github-apps">官方聲明</a> 建議所有的 project，包括 open source project 都使用 .com 的服務。</p><h3 id="第二步：在-Travis-CI-上連結-Github-Project"><a href="#第二步：在-Travis-CI-上連結-Github-Project" class="headerlink" title="第二步：在 Travis CI 上連結 Github Project"></a>第二步：在 Travis CI 上連結 Github Project</h3><p>接下來要讓 Travis CI 知道你的 repository 的存在。</p><p>首先先到 Travis CI 上的設定畫面 (紅框處)，然後選擇 Manage Repositories on Github (橘框處)。</p><p><img src="travis-ci-1.png" alt="Travis CI 01"></p><p>選擇自己 blog 的 repository (橘框處)。 或者你也可以選擇上面的「All repositories」連結所有的 repo。放心，這不會讓 Travis CI 有辦法對你的 Github repo 有辦法作任何更動。 完成後選擇 Approve (下面的綠色按鈕)。</p><p><img src="link-repo.png" alt="Link Repository"></p><h3 id="第三步：申請-Github-Access-Token"><a href="#第三步：申請-Github-Access-Token" class="headerlink" title="第三步：申請 Github Access Token"></a>第三步：申請 Github Access Token</h3><p>這步驟要到 Github 上申請一個 token，讓 Travis CI 取得上傳網頁到自己的 Github repository 上的權力。</p><p>首先先到 Github 上的個人設定頁面 (點選紅框處)，並選擇 Developer Settings 進入開發者設定頁面 (橘框處)。</p><p><img src="github-token-1.PNG" alt="Github Token 1"></p><p>點選 Personal Access Token (紅框處)，然後選擇 Generate new token (橘框處)。</p><p><img src="github-token-2.png" alt="Github Token 2"></p><p>設定 token 名稱，隨便命名都可以，並點選 repo -&gt; public_repo ，以給他存取 public repo 的權限。 這是為了要讓它能夠上傳資料到 repo。</p><p><img src="github-token-3.png" alt="Github Token 3"></p><p>將 token 複製下來 (綠底處)，注意不要讓其他人取得這個 token，因為其他人取得就可以隨意修改你的 repo 資料。</p><p><img src="github-token-4.png" alt="Github Token 4"></p><p>回到 Travis CI 設定頁面，進入自己 repo 的設定畫面 (紅框處)。</p><p><img src="github-token-5.png" alt="Github Token 5"></p><p>找到最下面的 Environment Variables 區域，在 key 的位置輸入 <code>GITHUB_TOKEN</code> (紅色箭頭)，value 位置放上稍早複製的 token (橘色箭頭)，然後點選右邊的 Add (綠色箭頭)。</p><p><img src="github-token-6.png" alt="Github Token 6"></p><h3 id="第四步：在-Project-內加入-Travis-CI-設定檔"><a href="#第四步：在-Project-內加入-Travis-CI-設定檔" class="headerlink" title="第四步：在 Project 內加入 Travis CI 設定檔"></a>第四步：在 Project 內加入 Travis CI 設定檔</h3><p>以上這些設定都搞定後，再來就是要在 blog 的 project 內放入 Travis CI 的設定檔。 裡面會包含如何正確產生網頁，以及上傳資料到 Github 的指令。</p><p>這一步驟只需要在自己的 project 中，最上層資料夾內放入一個 <code>.travis.yml</code> 檔，並放入以下內容：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">language:</span> <span class="string">node_js</span></span><br><span class="line"></span><br><span class="line"><span class="attr">sudo:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">branches:</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line"></span><br><span class="line"><span class="attr">cache:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span></span><br><span class="line"></span><br><span class="line"><span class="attr">node_js:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;10&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">before_script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">cl</span></span><br><span class="line"></span><br><span class="line"><span class="attr">script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">generate</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">provider:</span> <span class="string">pages</span></span><br><span class="line">  <span class="attr">skip-cleanup:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">github-token:</span> <span class="string">$GITHUB_TOKEN</span></span><br><span class="line">  <span class="attr">local-dir:</span> <span class="string">public</span></span><br><span class="line">  <span class="attr">keep-history:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">on:</span></span><br><span class="line">    <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure><p>這樣就完成了！ 之後每次 commit、push 資料到 Github 上之後，Travis CI 就會自動產生 blog 頁面，並上傳到 Github Page。</p><h3 id="第五步：觀察有沒有問題"><a href="#第五步：觀察有沒有問題" class="headerlink" title="第五步：觀察有沒有問題"></a>第五步：觀察有沒有問題</h3><p>最後只要上傳一個新的 commit 到 master branch，就會觸發 Travis CI 開始執行發布動作。 你可以到 Travis CI 的主畫面觀察，同時上面也會顯示執行的 log。 如果一切正常的話，就會如下圖顯示綠色勾勾的結果。</p><p><img src="result.png" alt="Test Result"></p><h3 id="恭喜你成功完成自動發布！"><a href="#恭喜你成功完成自動發布！" class="headerlink" title="恭喜你成功完成自動發布！"></a>恭喜你成功完成自動發布！</h3><h2 id="附錄：解說-travis-yml-內容"><a href="#附錄：解說-travis-yml-內容" class="headerlink" title="附錄：解說 .travis.yml 內容"></a>附錄：解說 <code>.travis.yml</code> 內容</h2><p>這邊大致說明一下設定檔的內容，這樣如果想根據自己需求修改，也會比較方便一點。 詳細的說明可以參考 <a href="https://docs.travis-ci.com/">官方文件</a>。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">language:</span> <span class="string">node_js</span></span><br><span class="line"></span><br><span class="line"><span class="attr">node_js:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;10&quot;</span></span><br></pre></td></tr></table></figure><p>這兩條設定分別指定這個 repository 要用 Node.js 的環境執行，並且要用第 10 版的 Node.js。 版本的部分也可以設定其他版本，或是 <code>stable</code>。 我使用 10 的原因是在於我某些特定的 module 必須要使用 10 版才能夠跑，如果用最新版則會執行失敗。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">branches:</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">master</span></span><br></pre></td></tr></table></figure><p>這條設定只有在 master branch 有發生變化時（新的 commit），Travis CI 才會執行。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">cache:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span></span><br></pre></td></tr></table></figure><p>這條設定會讓 Travis CI 保存 npm 下載的 library。 因為 Travis CI 每次執行時都會使用一個全新的環境，如果保存之前下載過的 library 的話，可以節省重新下載 library 的時間。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">before_script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">cl</span></span><br></pre></td></tr></table></figure><p>這條設定定義了執行主要指令之前，應該先執行甚麼指令做準備。 第一條安裝 library，第二條則會清空之前曾經自動建立過的資料，以保持環境整潔。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">generate</span></span><br></pre></td></tr></table></figure><p>這條設定執行了產生 blog 網頁的指令。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">provider:</span> <span class="string">pages</span></span><br><span class="line">  <span class="attr">skip-cleanup:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">github-token:</span> <span class="string">$GITHUB_TOKEN</span></span><br><span class="line">  <span class="attr">local-dir:</span> <span class="string">public</span></span><br><span class="line">  <span class="attr">keep-history:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">on:</span></span><br><span class="line">    <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure><p>這條設定是由 Travis CI 特別提供用來發布程式用的，其中 <code>provider: pages</code> 設定要發布到 Github Pages，這邊會由 Travis CI 自己想辦法把指定內容上傳上去。 <code>github-token: $GITHUB_TOKEN</code> 這邊會引入稍早設定的 token，用來取得上傳的權限。 <code>local-dir: public</code> 指定上傳 <code>public</code> 資料夾 (<code>hexo generate</code> 預設輸出的位置) 內的內容。 <code>on: branch: master</code> 這條有點特別，我原先以為是上傳的目的地 branch，但其實指的是 source branch。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近將我的部落格改成使用 &lt;a href=&quot;https://travis-ci.com/&quot;&gt;Travis CI&lt;/a&gt; 來自動發布，幫我省去在自己電腦上編譯再上傳到 Github Pages 的麻煩。 因此我將我的作法寫下來，幫助其他用 Hexo 建立 Blog 的人來設定自動發布。&lt;/p&gt;</summary>
    
    
    
    <category term="Building Blog" scheme="http://www.slmt.tw/blog/categories/building-blog/"/>
    
    <category term="Hexo" scheme="http://www.slmt.tw/blog/categories/building-blog/hexo/"/>
    
    
    <category term="blog" scheme="http://www.slmt.tw/blog/tags/blog/"/>
    
    <category term="hexo" scheme="http://www.slmt.tw/blog/tags/hexo/"/>
    
    <category term="deploy" scheme="http://www.slmt.tw/blog/tags/deploy/"/>
    
    <category term="travis-ci" scheme="http://www.slmt.tw/blog/tags/travis-ci/"/>
    
  </entry>
  
  <entry>
    <title>論文筆記 - Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores</title>
    <link href="http://www.slmt.tw/blog/2019/04/23/paper-cc-on-1000-cores/"/>
    <id>http://www.slmt.tw/blog/2019/04/23/paper-cc-on-1000-cores/</id>
    <published>2019-04-23T10:14:59.000Z</published>
    <updated>2022-04-25T08:49:17.088Z</updated>
    
    <content type="html"><![CDATA[<p>近期開啟的新系列，以分享資料庫系統相關的論文並簡介內容為主，不會講得太深入，但是會需要些對資料庫系統內部運作原理的基本概念。</p><p>這篇論文 [1] 主要是把近期常被拿來討論幾個主要的 Concurrency Control 的分支，放在具備 1000 個 Core 的環境下進行測試。 目的是為了瞭解這些做法在 Core 數量極多的機器上的 Scalability 如何。 在研究過程中，他們也嘗試去優化這些方法，盡可能地避免實作上可能會造成的瓶頸。 所以這篇論文的研究也可以當作在 multi-thread 環境下，實作這些 CC 作法的參考。</p><a id="more"></a><h2 id="基本資料"><a href="#基本資料" class="headerlink" title="基本資料"></a>基本資料</h2><ul><li>論文作者群：Xiangyao Yu, George Bezerra, Andrew Pavlo, Srinivas Devadas, Michael Stonebraker</li><li>研究機構：MIT, CMU</li><li>發表會議/期刊：Very Large Database (VLDB) 2014 年期刊</li></ul><h2 id="需要具備的知識"><a href="#需要具備的知識" class="headerlink" title="需要具備的知識"></a>需要具備的知識</h2><ul><li>知道 Transaciton 是甚麼</li><li>了解 Concurrency Control 的目的</li><li>對 multi-threads programming 有基本認識</li></ul><h2 id="做為測試目標的-Concurrency-Control-作法"><a href="#做為測試目標的-Concurrency-Control-作法" class="headerlink" title="做為測試目標的 Concurrency Control 作法"></a>做為測試目標的 Concurrency Control 作法</h2><p>簡單介紹一下這篇論文所探討的主流 Concurrency Control 作法。</p><h3 id="Two-Phase-Locking-2PL"><a href="#Two-Phase-Locking-2PL" class="headerlink" title="Two Phase Locking (2PL)"></a>Two Phase Locking (2PL)</h3><p>最傳統且常見的 Concurrency Control 作法。 基本概念是在 Transaction (以下簡稱 Tx) 取得資料之前先把資料鎖住，防止其他 Tx 存取。 一般又會依照讀寫的狀況分成 shared lock (slock) 跟 exclusive lock (xlock)。 一旦 Tx 開始放棄 lock 就不能再 lock 資料，以確保資料能夠正確的 recovery。</p><p>其中這篇論文又依照處理 deadlock 的方式分成以下三種作法：</p><h4 id="DL-DETECT"><a href="#DL-DETECT" class="headerlink" title="DL_DETECT"></a>DL_DETECT</h4><p>不會預先防範 deadlock 的發生，但是發生的話可以藉由建立一個 wait-for graph 來找出發生的地方，並且會把其中一個卡住的 Tx abort 來解除 deadlock。</p><h4 id="NO-WAIT"><a href="#NO-WAIT" class="headerlink" title="NO_WAIT"></a>NO_WAIT</h4><p>只要 Tx 存取資料的時候，發現可能需要等待其他 Tx 釋放 lock，就會自動 abort。</p><h4 id="WIAT-DIE"><a href="#WIAT-DIE" class="headerlink" title="WIAT_DIE"></a>WIAT_DIE</h4><p>Tx A 存取資料時，如果發現資料被鎖住的話，依照下列情況做處理：</p><ul><li>如果 Tx A 比鎖住資料的 Tx B 年輕 =&gt; abort Tx A</li><li>如果 Tx A 比鎖住資料的 Tx B 老 =&gt; 等待 Tx B 釋放 lock</li></ul><p>這個方法確保不會有 deadlock 發生，因為一個 deadlock 互相等待的關係之中，一定有一個 Tx 比較年輕，因此只要讓其中一邊沒機會等待就可以避免 deadlock。</p><p>這個方法成本比 DL_DETECT 低很多，又不會亂 abort Tx，所以是最常見的作法。</p><h3 id="Timestamp-Ordering-T-O"><a href="#Timestamp-Ordering-T-O" class="headerlink" title="Timestamp Ordering (T/O)"></a>Timestamp Ordering (T/O)</h3><p>Timestamp ordering 的基本概念是 DBMS 會為每個 Tx 配發一個 timestamp (以下簡稱 ts)，這個 ts 會作為判斷 Tx 順序的標準。 除此之外，Tx 一般會將自己的 ts 寫在自己寫入過的資料上面，用來給後面存取的 Tx 辨識。</p><h4 id="Basic-T-O"><a href="#Basic-T-O" class="headerlink" title="Basic T/O"></a>Basic T/O</h4><p>Tx 會檢查資料上的 ts，若上面的 ts 比自己的 ts 還要年輕，就會 abort。 反之，照常寫入資料。</p><h4 id="Multi-version-Concurrency-Control-MVCC"><a href="#Multi-version-Concurrency-Control-MVCC" class="headerlink" title="Multi-version Concurrency Control (MVCC)"></a>Multi-version Concurrency Control (MVCC)</h4><p>每次 Tx 寫入資料的時候，直接創造一個新的版本另外儲存，原本的版本就保留不動。 好處是如果有其他人正在讀同樣的資料，就不會被寫入影響到 (reads do not block writes)。</p><h4 id="Optimistic-Concurrency-Control-OCC"><a href="#Optimistic-Concurrency-Control-OCC" class="headerlink" title="Optimistic Concurrency Control (OCC)"></a>Optimistic Concurrency Control (OCC)</h4><p>Tx 在執行期間不做任何檢查，讀取任何想讀的資料，寫的時候先寫在一個獨立的空間。 最後 Tx 要 commit 時檢查之前的讀寫是否會跟人家衝突 (conflict)。 沒問題的話就把先前寫入的東西寫到共用的空間。 有問題就 abort Tx。 一種先斬後奏的作法。</p><h4 id="H-STORE"><a href="#H-STORE" class="headerlink" title="H-STORE"></a>H-STORE</h4><p>H-Store [2] 這種系統專用的作法。 先將資料切割成多個分區 (partition)，然後每個分區交給一個 core 處理，並且每個分區一次只允許一個 thread 執行。 因此在一個分區內不需要處理 Concurrency Control。 若有 Tx 想要跨分區存取，就必須要先把這些分區全部鎖住。</p><h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><ul><li>需要實作各種 CC 方法</li><li>需要盡可能地避免實作上的瓶頸</li></ul><h2 id="有用的發現"><a href="#有用的發現" class="headerlink" title="有用的發現"></a>有用的發現</h2><h3 id="主要的瓶頸來源"><a href="#主要的瓶頸來源" class="headerlink" title="主要的瓶頸來源"></a>主要的瓶頸來源</h3><ul><li>Memory Allocation：很多時間會浪費在等 malloc 分配記憶體。解決方法是使用 previous work (TCMalloc [3], jemalloc [4]) 來為每個 thread 建立 memory pool，減少分配的 cost。</li><li>Lock Table: 避免使用 centrolized lock table，而是將 lock 儲存在各個 tuple 中，但是可能需要耗費額外記憶體。</li><li>Mutex: Mutex 是一個很昂貴的動作，造成 CPU 需要做多次 message passing。2PL 主要出現在 Deadlock detection，Timestamp-based 出現在 centrolized timestamp allocator。</li></ul><h3 id="實作-Scalable-2PL-的技巧"><a href="#實作-Scalable-2PL-的技巧" class="headerlink" title="實作 Scalable 2PL 的技巧"></a>實作 Scalable 2PL 的技巧</h3><ul><li>實作 lock-free deadlock detection 方法： 每個 Tx 只將等待的目標存在自己的 queue 中，detector 會看過所有 queue 來尋找 partial wait-for graph。</li><li>讓等太久的 Tx abort： 原本 Tx 等待 lock 時，會等到 lock 被釋放才回復執行。 根據實驗結果顯示，若能適度讓等太久的 Tx abort，可以減少 wait chaining 的狀況，因此反而可以增加 throughput。 實驗結果顯示等待上限設為 100us 差不多。</li></ul><h3 id="實作-Scalable-Timestamp-based-CC-的技巧"><a href="#實作-Scalable-Timestamp-based-CC-的技巧" class="headerlink" title="實作 Scalable Timestamp-based CC 的技巧"></a>實作 Scalable Timestamp-based CC 的技巧</h3><h4 id="分配-Timestamp"><a href="#分配-Timestamp" class="headerlink" title="分配 Timestamp"></a>分配 Timestamp</h4><p>分配 timestamp 必須是一個 centralized 的架構，以確保 timestamp 的順序性，但是也造成了效能瓶頸。這邊有四種解法：</p><ul><li>使用 Atomic Addition 指令。</li><li>使用 Atomic Addition 指令，一次取得大量 timestamps (batching)。</li><li>讓 timestamp 使用 core 的 local clock 加上 thread id 組成。這個方法需要 core 之間 synchronize clocks，用軟體實作會非常昂貴。目前只有 Intel 提供硬體支援。</li><li>用 hardware counter 來產生 timestamp，目前尚未有 CPU 提供支援。</li></ul><p>Clock 的作法在所有實驗上取得最佳效果，但是在 high-contention 的實驗中，單純使用無 batch 的 atomic addition 效果就跟 clock 一樣好。有鑑於簡單性與支援性，之後都採用 atomic addition 這個做法。</p><h4 id="分散式-Validation"><a href="#分散式-Validation" class="headerlink" title="分散式 Validation"></a>分散式 Validation</h4><p>類似 Microsoft Hakaton [5] ，在每個 tuple 上 validate tx，而不是用 centralized 的 critical section。</p><h3 id="實作-H-Store-的技巧"><a href="#實作-H-Store-的技巧" class="headerlink" title="實作 H-Store 的技巧"></a>實作 H-Store 的技巧</h3><p>讓 thread 直接 access 其他 thread 的 memory，而不是還要另外送 query 過去讓其他 core 處理。</p><h2 id="實驗"><a href="#實驗" class="headerlink" title="實驗"></a>實驗</h2><p>實驗的部分就不細談，基本上就是使用 YCSB Benchmark 去模擬各種 workloads，並且研究每種作法在不同環境的優缺點，以幫助使用者選擇自己適合用甚麼 Concurrency Control 方法。 實驗的數量很多，因此有興趣的人可以自己細看。</p><p>另外提一下，1000 Cores 的機器目前還不存在，所以論文中是使用將多台機器連接在一起，並使用模擬器的方式去模擬的。</p><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p>[1] Yu, Xiangyao, et al. “Staring into the abyss: An evaluation of concurrency control with one thousand cores.” Proceedings of the VLDB Endowment 8.3 (2014): 209-220.<br>[2] Kallman, Robert, et al. “H-store: a high-performance, distributed main memory transaction processing system.” Proceedings of the VLDB Endowment 1.2 (2008): 1496-1499.<br>[3] Ghemawat, Sanjay, and Paul Menage. “Tcmalloc: Thread-caching malloc.” (2009).<br>[4] J. Evans. jemalloc.<a href="http://canonware.com/jemalloc">http://canonware.com/jemalloc</a><br>[5] Neumann, Thomas, Tobias Mühlbauer, and Alfons Kemper. “Fast serializable multi-version concurrency control for main-memory database systems.” Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. ACM, 2015.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;近期開啟的新系列，以分享資料庫系統相關的論文並簡介內容為主，不會講得太深入，但是會需要些對資料庫系統內部運作原理的基本概念。&lt;/p&gt;
&lt;p&gt;這篇論文 [1] 主要是把近期常被拿來討論幾個主要的 Concurrency Control 的分支，放在具備 1000 個 Core 的環境下進行測試。 目的是為了瞭解這些做法在 Core 數量極多的機器上的 Scalability 如何。 在研究過程中，他們也嘗試去優化這些方法，盡可能地避免實作上可能會造成的瓶頸。 所以這篇論文的研究也可以當作在 multi-thread 環境下，實作這些 CC 作法的參考。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://www.slmt.tw/blog/categories/research/"/>
    
    <category term="Paper" scheme="http://www.slmt.tw/blog/categories/research/paper/"/>
    
    
    <category term="paper" scheme="http://www.slmt.tw/blog/tags/paper/"/>
    
    <category term="dbms" scheme="http://www.slmt.tw/blog/tags/dbms/"/>
    
    <category term="concurrency-control" scheme="http://www.slmt.tw/blog/tags/concurrency-control/"/>
    
    <category term="survey" scheme="http://www.slmt.tw/blog/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>漏洞筆記 - 別讓你的 .git 資料夾公開在網路上啊！</title>
    <link href="http://www.slmt.tw/blog/2016/08/21/dont-expose-your-git-dir/"/>
    <id>http://www.slmt.tw/blog/2016/08/21/dont-expose-your-git-dir/</id>
    <published>2016-08-21T16:00:45.000Z</published>
    <updated>2022-04-25T08:49:17.084Z</updated>
    
    <content type="html"><![CDATA[<p>這個周末玩了一個 CTF 線上賽。其中有一題是說有一個新手架了一個網站，然後分別使用了 Nginx、PHP、git 這些技術。點開題目提供的網址後，就看到一個 Hello World 的網頁。打開原始碼後，只看到幾行簡單的基礎程式碼，也沒有看到可疑的東西。正當我打算要放棄的時候，突然想到題目有特別提到他有使用 git。於是就嘗試了打開該網站的 <code>.git</code> 資料夾，不過馬上就被 403 Forbidden 打臉。</p><p>就在我快想不到到底怎麼辦的時候，突然又靈機一動。想到雖然我看不到 <code>.git</code> 的內容，但或許我仍可以下載裡面的檔案？於是我馬上隨便打開我手邊的一個 git repository。發現 <code>.git</code> 資料夾內一定有 <code>HEAD</code> 這個檔案。於是我馬上就嘗試下載 <code>.git/HEAD</code>。果不其然！可以抓到這個檔案！那麼接下來就有個方向了！</p><a id="more"></a><h2 id="git-資料夾"><a href="#git-資料夾" class="headerlink" title=".git 資料夾"></a><code>.git</code> 資料夾</h2><p>稍微研究了一下，一個 <code>.git</code> 的資料夾大概有 <code>hooks</code>、<code>info</code>、<code>logs</code>、<code>objects</code>、<code>refs</code>，檔案則大概有 <code>COMMIT_EDITMSG</code>、<code>config</code>、<code>description</code>、<code>HEAD</code>。</p><p>其中 <code>hooks</code>、<code>info</code> 這兩個資料夾在大多數的 <code>.git</code> 之中都沒有甚麼有用的資訊，<code>logs</code> 則是其中可以馬上看出最多資訊的資料夾。<code>objects</code> 則存著所有版本的 binary 檔，裡面的東西乍看之下沒有甚麼規則，於是我先跳過。<code>refs</code> 則存放每個 branch 目前指向的 commit 為何。</p><p>除了 <code>objects</code> 以外，所有檔案的檔名大多可以猜到，因此我就將這些檔案抓了下來。可惜裡面最多只能從 log 中看出曾經有 commit 過含有 flag 的檔案。但是檔案的實際內容就無從得知了。</p><h2 id="Git-Objects"><a href="#Git-Objects" class="headerlink" title="Git Objects"></a>Git Objects</h2><p>我發現我似乎最後仍得要還原出每個版本，才有辦法解出這題。因此我開始研究了 <code>objects</code> 內的內容。後來稍微思考了一下，覺得 git 官方應該會有相關的文件。Google 一下很快就有發現了！果然有關於內部運作邏輯的文件，甚至連 objects 的存放方式跟意義都有明確說明。甚至還有繁體中文版！文件有興趣的可以參考看看：</p><p><a href="https://git-scm.com/book/zh-tw/v1/Git-%E5%85%A7%E9%83%A8%E5%8E%9F%E7%90%86">https://git-scm.com/book/zh-tw/v1/Git-%E5%85%A7%E9%83%A8%E5%8E%9F%E7%90%86</a></p><p>大略看過之後，才知道原來所有的 commit 的文件都會獨立存成一個檔案。每個檔案會先計算 SHA1 值為多少，然後取前兩碼做為 <code>objects</code> 內的資料夾名稱，後 38 碼則做為 <code>objects</code> 內部的檔名存放。在 <code>objects</code> 中，除了存放 commit 的檔案外，還會存放 commit 時的目錄結構 (稱為 tree)，以及 commit 的紀錄。這些也同樣會用上述的方式存起來。目錄會紀錄裡面包含的其他目錄以及檔案的 SHA1 值為何。Commit 紀錄則會有該次 commit 對應的目錄 SHA1 值，以及上一次 commit 的 SHA1 值。</p><p>這些檔案都被以 binary 的方式存起來。我稍微查了一下有沒有簡便的方法可以直接看到內容。果不其然，可以透過 <code>git cat-file</code> 指令解碼 objects 的內容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git cat-file -p [SHA1]</span><br></pre></td></tr></table></figure><p><code>[SHA1]</code> 處要填上你想要解碼的 object 檔的 SHA1 值，有興趣的人可以自己試試看。記住 SHA1 前兩碼是資料夾名稱，後 38 碼是檔案名稱。</p><h2 id="檢查指令"><a href="#檢查指令" class="headerlink" title="檢查指令"></a>檢查指令</h2><p>在得知這些資訊後，我馬上去查看 log 檔，找到 commit 的 SHA1 值，然後嘗試去下載對應的 object 檔。一試之後，馬上就成功下載對應的檔案。我接著立刻用查到的指令解碼，就看到了類似下列的內容：(這個內容是我拿我的部落格 git 資料夾 demo)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tree 9aa33d38927cdde7b969586a2a7e942d816ea947</span><br><span class="line">parent bfd06e73e40a78720418795cacc3072bad168d85</span><br><span class="line">author slmt &lt;sam123456777@gmail.com&gt; 1471021607 +0800</span><br><span class="line">committer slmt &lt;sam123456777@gmail.com&gt; 1471021607 +0800</span><br><span class="line"></span><br><span class="line">Add a new post</span><br></pre></td></tr></table></figure><p><code>tree</code> 指的就是該次 commit 對應的目錄檔，<code>parent</code> 指的是上一次 commit 的 SHA1 值。其他則是容易辨別的 commit 資料。</p><p>我馬上就知道我又獲得了兩個 SHA1，所以就繼續使用這些 SHA1 下載對應的 object 檔。只是多試幾次之後，很快就感到厭煩了。因為你要先解碼，還要看哪一個是沒有抓過的。全部抓下來的話很花時間。</p><p>幸好我後來又發現另一個指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fsck</span><br></pre></td></tr></table></figure><p>這個指令會檢查你的 objects 檔之間的 link 是否完整，並且會找出應該存在但是找不到的 object 檔。這個指令大大地幫助我減少檢查檔案的時間。於是我很快就把遺失的 object 檔補齊。找到所有 object 檔後，很輕易地就使用常用的 git 指令找出了之前的版本，然後發現題目要求的 flag。順利解決。</p><h2 id="下載-Script"><a href="#下載-Script" class="headerlink" title="下載 Script"></a>下載 Script</h2><p>寫完這題之後，我覺得雖然有 <code>git fsck</code> 幫助，但是一一下載檔案仍然非常麻煩。因此我就寫了一個 python script 來幫助我進行自動下載。該 script 可以在這裡找到：</p><p><a href="https://github.com/SLMT/ctf-tools/tree/master/git-repository-downloader">https://github.com/SLMT/ctf-tools/tree/master/git-repository-downloader</a></p><p>基本上 script 就是做我前列提到的那些事情，只是變成只要輸入一個指令就可以完成所有動作。</p><h2 id="呼籲"><a href="#呼籲" class="headerlink" title="呼籲"></a>呼籲</h2><p>最後呼籲一下。別忘記這題會被解開是因為 <code>.git</code> 的下載權限被設為公開。若之後大家在開發網站，別忘記把 <code>.git</code> 的下載權限關掉。只有關掉閱讀目錄的權限還遠遠不夠，只要使用我的 script 就可以完整地復原整個 git repository XD 因此真的要很小心~~!!!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;這個周末玩了一個 CTF 線上賽。其中有一題是說有一個新手架了一個網站，然後分別使用了 Nginx、PHP、git 這些技術。點開題目提供的網址後，就看到一個 Hello World 的網頁。打開原始碼後，只看到幾行簡單的基礎程式碼，也沒有看到可疑的東西。正當我打算要放棄的時候，突然想到題目有特別提到他有使用 git。於是就嘗試了打開該網站的 &lt;code&gt;.git&lt;/code&gt; 資料夾，不過馬上就被 403 Forbidden 打臉。&lt;/p&gt;
&lt;p&gt;就在我快想不到到底怎麼辦的時候，突然又靈機一動。想到雖然我看不到 &lt;code&gt;.git&lt;/code&gt; 的內容，但或許我仍可以下載裡面的檔案？於是我馬上隨便打開我手邊的一個 git repository。發現 &lt;code&gt;.git&lt;/code&gt; 資料夾內一定有 &lt;code&gt;HEAD&lt;/code&gt; 這個檔案。於是我馬上就嘗試下載 &lt;code&gt;.git/HEAD&lt;/code&gt;。果不其然！可以抓到這個檔案！那麼接下來就有個方向了！&lt;/p&gt;</summary>
    
    
    
    <category term="Hacking" scheme="http://www.slmt.tw/blog/categories/hacking/"/>
    
    <category term="Exploit" scheme="http://www.slmt.tw/blog/categories/hacking/exploit/"/>
    
    
    <category term="hacking" scheme="http://www.slmt.tw/blog/tags/hacking/"/>
    
    <category term="web" scheme="http://www.slmt.tw/blog/tags/web/"/>
    
    <category term="exploit" scheme="http://www.slmt.tw/blog/tags/exploit/"/>
    
    <category term="git" scheme="http://www.slmt.tw/blog/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Rust-PTT 開發筆記 1</title>
    <link href="http://www.slmt.tw/blog/2016/08/12/rust-ptt-notes-1/"/>
    <id>http://www.slmt.tw/blog/2016/08/12/rust-ptt-notes-1/</id>
    <published>2016-08-12T16:34:51.000Z</published>
    <updated>2022-04-25T08:49:17.084Z</updated>
    
    <content type="html"><![CDATA[<p>很早以前我就想深入研究 PTT 的程式碼，雖然 PTT 很早就將程式碼開源出來，但是當時我並沒有能力看懂。最近又將程式碼翻出來看，看了一些之後有些心得。剛好在 PTT 上有人在<a href="https://github.com/ptt/pttbbs/issues/5">討論重寫 PTT</a> 的問題，因此就讓我起了重寫 PTT 的意思。</p><p>這裡我選擇使用 Rust 做為重寫的語言。主要是因為我最近在研究這個程式語言，但是一直沒有甚麼機會寫出比較大的專案。因此我認為用 Rust 寫 PTT 剛好是個不錯的機會，於是這個專案就這麼開始了！</p><p>從這裡可以到 Rust-PTT 的 Github 頁面：<a href="https://github.com/SLMT/rust-ptt/">https://github.com/SLMT/rust-ptt/</a></p><a id="more"></a><h2 id="為什麼選擇-Rust"><a href="#為什麼選擇-Rust" class="headerlink" title="為什麼選擇 Rust"></a>為什麼選擇 Rust</h2><p><a href="https://www.rust-lang.org/en-US/">Rust</a> 是很新的程式語言，去年 (2015) 5 月 16 號才釋出 1.0 正式版。最近也才剛進到 1.10.0 而已。很多東西都還在討論之中，但是大多數的東西應該都差不多定型了。</p><p>Rust 語言具有不會有 Segmentation Falut、不需自己管理記憶體 (但是也不用 Garbage Collection 等方式降低執行效能)、近似於 C 效能等特性。同時該語言融合了許多近期新興語言的特色，像是 Pattern Matching、Closures、Generics 等等，並且在於 Concurrency 的方面具有許多 Native Support。我認為 Rust 很適合用來開發大量用戶同時連線的 PTT，而且相較於 C 更容易維護。</p><p>Rust 語言目前由 Mozilla 公司開發維護，並且正以 Rust 與開發 Firefox 的經驗，重新撰寫<a href="https://github.com/servo/servo">新的瀏覽器核心</a>。現在也有其它專案正在重新以 Rust 替換掉原本以 C 撰寫的程式。</p><h2 id="近期進度"><a href="#近期進度" class="headerlink" title="近期進度"></a>近期進度</h2><p>撰寫這篇文章的同時，我已經 commit 了 8 個版本。目前最新的版本為 <a href="https://github.com/SLMT/rust-ptt/commit/a63e83012f479ceea13b01fcdd037ae56ce857f5">a63e830</a>。</p><p>一開始只有 Hello World，八個版本後已經有一個基本的 TCP Server，並且會對 Telnet Protocol 做一些初始化的動作。若一個 telnet client 嘗試連上目前的 server，在進行 telnet 初始化之後，server 會知道 client 需要多大的 terminal size。</p><p>目前 telnet 的實作主要是根據 PTT 內的實作方式進行，詳情可以參考我撰寫的另一篇文章：<a href="http://www.slmt.tw/2016/08/07/tracing-ptt-note-2/">PTT Source Code 研究筆記 2</a>。</p><h2 id="嘗試看看"><a href="#嘗試看看" class="headerlink" title="嘗試看看"></a>嘗試看看</h2><p>假設你的電腦已經安裝好 Rust 與 Git，你可透過在 shell 輸入下列指令啟動 rust-ptt 的 server：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; git clone https:&#x2F;&#x2F;github.com&#x2F;SLMT&#x2F;rust-ptt</span><br><span class="line">&gt; cd rust-ptt</span><br><span class="line">&gt; cargo run</span><br></pre></td></tr></table></figure><p>之後啟動都只要執行最後一個指令即可。</p><p>然後隨便找一個拿來連 PTT 的 client 或者 telnet client 來連上 server (網址：<code>localhost:54321</code>)，此時 server 這邊應該會顯示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Start a connection to 127.0.0.1:4229</span><br><span class="line">Width: 80, Height: 24</span><br></pre></td></tr></table></figure><p>第一行是 client 的資訊，第二行是 client 要求的 terminal 大小。目前只能顯示這些東西而已，client 則還不會看到任何結果。</p><h2 id="近期目標"><a href="#近期目標" class="headerlink" title="近期目標"></a>近期目標</h2><p>接下來應該會朝向完成基本的 terminal 功能，以及登入功能為主。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;很早以前我就想深入研究 PTT 的程式碼，雖然 PTT 很早就將程式碼開源出來，但是當時我並沒有能力看懂。最近又將程式碼翻出來看，看了一些之後有些心得。剛好在 PTT 上有人在&lt;a href=&quot;https://github.com/ptt/pttbbs/issues/5&quot;&gt;討論重寫 PTT&lt;/a&gt; 的問題，因此就讓我起了重寫 PTT 的意思。&lt;/p&gt;
&lt;p&gt;這裡我選擇使用 Rust 做為重寫的語言。主要是因為我最近在研究這個程式語言，但是一直沒有甚麼機會寫出比較大的專案。因此我認為用 Rust 寫 PTT 剛好是個不錯的機會，於是這個專案就這麼開始了！&lt;/p&gt;
&lt;p&gt;從這裡可以到 Rust-PTT 的 Github 頁面：&lt;a href=&quot;https://github.com/SLMT/rust-ptt/&quot;&gt;https://github.com/SLMT/rust-ptt/&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Project" scheme="http://www.slmt.tw/blog/categories/project/"/>
    
    <category term="Rust-PTT" scheme="http://www.slmt.tw/blog/categories/project/rust-ptt/"/>
    
    
    <category term="rust" scheme="http://www.slmt.tw/blog/tags/rust/"/>
    
    <category term="code" scheme="http://www.slmt.tw/blog/tags/code/"/>
    
    <category term="ptt" scheme="http://www.slmt.tw/blog/tags/ptt/"/>
    
    <category term="bbs" scheme="http://www.slmt.tw/blog/tags/bbs/"/>
    
    <category term="project" scheme="http://www.slmt.tw/blog/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>PTT Source Code 研究筆記 2</title>
    <link href="http://www.slmt.tw/blog/2016/08/07/tracing-ptt-note-2/"/>
    <id>http://www.slmt.tw/blog/2016/08/07/tracing-ptt-note-2/</id>
    <published>2016-08-07T07:15:00.000Z</published>
    <updated>2022-04-25T08:49:17.084Z</updated>
    
    <content type="html"><![CDATA[<p>基本上，PTT 的使用者連上 PTT 時，都是透過一個叫做 telnet 的 protocol 進行。看了 PTT 的程式碼，會發現 PTT 並沒有使用其它的 telnet 函式庫，而是自行實作 telnet protocol。剛剛將這個部分看的差不多了，因此稍微紀錄一下實作方式。</p><a id="more"></a><h2 id="簡介-Telnet-Protocol"><a href="#簡介-Telnet-Protocol" class="headerlink" title="簡介 Telnet Protocol"></a>簡介 Telnet Protocol</h2><p>Telnet Protocol 的基本概念定義在 RFC 854 中，需要的話可以透過底下的 reference 看到全文。內容我花一點時間大致看過了，其實概念不難理解。</p><p>Telnet 是一種建立在 TCP 上的通訊協定。TCP 基本上處理好了傳送訊息過程中的各種錯誤，因此 telnet 很少需要處理甚麼錯誤的情況。Telnet 的基本概念是在模擬過去電腦的工作模式。很早期以前的電腦是有一台大型的主機 (mainframe) 在進行計算，然後使用者必須要透過一台小型的終端機 (terminal) 來連上主機進行工作 (就像下圖一樣)。跟現在這種一台電腦一個螢幕，然後螢幕的顯示直接由主機負責很不一樣。以前的模式裡，終端機很像是一個 client，主機則是 server。終端機會負責接收使用者訊息，透過線路送出指令，並顯示結果。Telnet 大概也類似這樣。Server 上儲存各種資料，每個使用者自己電腦的 telnet client 就是一個終端機。連上 server 後，server 會把你畫面上該顯示的東西傳過來給你，client 則會印出收到的文字。</p><img src="https://upload.wikimedia.org/wikipedia/commons/7/7d/IBM_704_mainframe.gif" /><p>了解基本概念之後，就會知道 telnet 其實該作的事情不多。基本上 server 就是會把一個個你畫面上該顯示的文字傳遞給 client，client 則會下達指令給 server。唯一要特別處理的，就是兩者間必須要能夠透過一些預先定義好的指令，來設定兩者傳遞資料的一些規則。</p><h2 id="PTT’s-Telnet-Implementation"><a href="#PTT’s-Telnet-Implementation" class="headerlink" title="PTT’s Telnet Implementation"></a>PTT’s Telnet Implementation</h2><p>PTT 自行實作了 telnet protocol，主要是由當時在台大資工系的 piaip 實作。程式碼可以在 PTT Source Code 的 <code>common/sys/telnet.c</code> 中找到。內容非常簡單，大概一個下午就可以看完。不過也因為實作非常簡單，所以對於很多設定的選項並不會給予回覆。在該檔之中有一段註解寫著：</p><blockquote><p>We are the boss. We don’t respect to client. It’s client’s responsibility to follow us.</p></blockquote><p>我看到這段霸氣註解之後笑了一下XD</p><p>不過也多虧這個決定，這邊就有很多實作的細節都可以跳過。</p><p>基本上實作的程式碼大概可以分成三塊：</p><ul><li>剛開始連線時，會送出一些初始設定資訊</li><li>讓 server 其他部分調整一些基本設定</li><li>處理 client 送來的設定</li></ul><p>這邊可以發現主要都是在實作關於設定的通訊。其他像是處理 server 送出的畫面內容、如何處理 client 對於 PTT 的指令這些，就不是 telnet protocol 本身的工作。因此並沒有寫在這裡。</p><h3 id="起始設定"><a href="#起始設定" class="headerlink" title="起始設定"></a>起始設定</h3><p>一開始 server 會將一連串的設定訊息送給 client，client 收到後則會對每個訊息做出回應。PTT 送出的設定可以在 <code>telnet.c</code> 的 <code>telnet_init_cmds</code> 這個變數內找到：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">char</span> telnet_init_cmds[] = &#123;</span><br><span class="line"> <span class="comment">// retrieve terminal type and throw away.</span></span><br><span class="line">  <span class="comment">// why? because without this, clients enter line mode.</span></span><br><span class="line"> IAC, DO, TELOPT_TTYPE,</span><br><span class="line"> IAC, SB, TELOPT_TTYPE, TELQUAL_SEND, IAC, SE,</span><br><span class="line"></span><br><span class="line"> <span class="comment">// i&#x27;m a smart term with resize ability.</span></span><br><span class="line"> IAC, DO, TELOPT_NAWS,</span><br><span class="line"></span><br><span class="line"> <span class="comment">// i will echo.</span></span><br><span class="line"> IAC, WILL, TELOPT_ECHO,</span><br><span class="line"> <span class="comment">// supress ga.</span></span><br><span class="line"> IAC, WILL, TELOPT_SGA,</span><br><span class="line"> <span class="comment">// 8 bit binary.</span></span><br><span class="line"> IAC, WILL, TELOPT_BINARY,</span><br><span class="line"> IAC, DO,   TELOPT_BINARY,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中使用到的常數都定義在 <code>arpa/telnet.h</code> 中。這個檔案並不是 PTT 的一部分，而是大多數系統都會包含的標頭檔。上網搜尋一下就可以找到檔案。這些初始訊息翻譯成人話的話，意思大概如下 (以下每一行分別對應到上面一行)：</p><ul><li>現在來設定終端機種類吧 (TELOPT_TTYPE)</li><li>請給我終端機種類設定資訊</li><li>現在來設定終端機大小吧 (TELOPT_NAWS)</li><li>希望你能回應每個我傳送的訊息 (TELOPT_ECHO)</li><li>希望你能夠直接傳送下個訊息，而不要等我回覆 (TELOPT_SGA)</li><li>希望你能使用 8bit 傳輸模式 (TELOPT_BINARY)</li></ul><p>特別注意註解中有提到，若不送出前兩項設定訊息，client 可能就無法正確地顯示出 PTT 畫面。</p><h3 id="處理-client-設定訊息"><a href="#處理-client-設定訊息" class="headerlink" title="處理 client 設定訊息"></a>處理 client 設定訊息</h3><p>至於 client 這邊送回來的訊息，處理的方式基本上就是一個 finite state machine (FSM)。FSM 的概念就是程式會有一組狀態。每次收到訊號之後，檢查現在的狀態是甚麼，然後做出對應的動作，最後更新目前的狀態。詳細的部分各位有興趣可以自己去看，那段程式碼才大概 224 行，很快就可以看完。</p><p>大概需要注意的是，若收到 client 傳出的 <code>IAC SB</code> 訊息，那就會進入一個<strong>暫存</strong>狀態。接下來所有收到的訊息都會被放近一個 buffer 之中，直到收到 <code>SE</code> 指令為止。這個動作意義在於，<code>IAC SB</code> 是代表接下來收到的是關於某個選項的詳細資訊，例如選項若是 <code>TELOPT_NAWS</code>，那接下來就會收到終端機的長跟高的資訊。有趣的是，PTT 似乎只會對 <code>TELOPT_NAWS</code> 這個選項做出反應，其他的選項則大多都被忽略掉了。</p><h3 id="實際例子"><a href="#實際例子" class="headerlink" title="實際例子"></a>實際例子</h3><p>目前我用 Rust 撰寫的 <a href="https://github.com/SLMT/rust-ptt/tree/5246412a8ca514823c01e2cc40c4ee06d281e9cf">PTT prototype</a> 已經可以送出前兩章看到的基本設定，以及接收 client 的訊息。</p><p>我使用 PCMan 來測試，發現 PCMan 在收到我的訊息後，會回傳下列訊息 (in bytes)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">255, 251, 24, 255, 250, 24, 0, 86, 84, 49, 48, 48, 255, 240, 255, 251, 31, 255, 250, 31, 0, 80, 0, 24, 255, 240, 255, 253, 1, 255, 253, 3, 255, 254, 0, 255, 252, 0</span><br></pre></td></tr></table></figure><p>若轉換為各自代表的意義，則大概是這樣：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">IAC, WILL, TELOPT_TTYPE</span><br><span class="line">IAC, SB, &#123;TELOPT_TTYPE, TELQUAL_IS, 86, 84, 49, 48, 48, 255&#125;, SE</span><br><span class="line">IAC, WILL, TELOPT_NAWS</span><br><span class="line">IAC, SB, &#123;TELOPT_NAWS, width&#123;0, 80&#125;, height&#123;0, 24&#125;, 255&#125;, SE</span><br><span class="line">IAC, DO, TELOPT_ECHO,</span><br><span class="line">IAC, DO, TELOPT_SGA,</span><br><span class="line">IAC, DONT, TELOPT_BINARY,</span><br><span class="line">IAC, WONT, TELOPT_BINARY</span><br></pre></td></tr></table></figure><p>這邊可以看到像是對於 <code>TELOPT_NAWS</code> 這個選項，PCMan 送出了寬 80、高 24 的訊息。而 PTT 這邊就會依照他的請求來調整大小。其中有一個有趣的點是，PCMan 送出了他不會使用 8bit 模式的訊息。而 PTT 這邊則是看完之後就丟掉了。這感覺就像是以下發生了以下情境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PTT: 請使用 8-bit 模式</span><br><span class="line">PCMan: 我不能使用 8-bit 模式</span><br><span class="line">PTT: 哦，是哦。</span><br></pre></td></tr></table></figure><p>大概就是這樣吧XD</p><p>這邊了解之後，會先花點時間實作在 Rust-PTT 上，之後應該會進入 PTT 上關於 terminal 的實作。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>PTT Source Code - <a href="https://github.com/ptt/pttbbs">https://github.com/ptt/pttbbs</a></li><li>我的 PTT Source Code 閱讀紀錄 - <a href="https://github.com/SLMT/pttbbs/tree/tracing">https://github.com/SLMT/pttbbs/tree/tracing</a></li><li>Rust PTT Project - <a href="https://github.com/SLMT/rust-ptt">https://github.com/SLMT/rust-ptt</a></li><li>PTT Source Code 中的 telnet.c - <a href="https://github.com/ptt/pttbbs/blob/master/common/sys/telnet.c">https://github.com/ptt/pttbbs/blob/master/common/sys/telnet.c</a></li><li>RFC 854 - Telnet Protocol Specification - <a href="https://tools.ietf.org/html/rfc854">https://tools.ietf.org/html/rfc854</a></li><li>PCMan - <a href="http://pcman.ptt.cc/">http://pcman.ptt.cc/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;基本上，PTT 的使用者連上 PTT 時，都是透過一個叫做 telnet 的 protocol 進行。看了 PTT 的程式碼，會發現 PTT 並沒有使用其它的 telnet 函式庫，而是自行實作 telnet protocol。剛剛將這個部分看的差不多了，因此稍微紀錄一下實作方式。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://www.slmt.tw/blog/categories/research/"/>
    
    <category term="PTT" scheme="http://www.slmt.tw/blog/categories/research/ptt/"/>
    
    <category term="Source Code" scheme="http://www.slmt.tw/blog/categories/research/ptt/source-code/"/>
    
    
    <category term="code" scheme="http://www.slmt.tw/blog/tags/code/"/>
    
    <category term="tracing" scheme="http://www.slmt.tw/blog/tags/tracing/"/>
    
    <category term="ptt" scheme="http://www.slmt.tw/blog/tags/ptt/"/>
    
    <category term="bbs" scheme="http://www.slmt.tw/blog/tags/bbs/"/>
    
  </entry>
  
  <entry>
    <title>PTT Source Code 研究筆記 1</title>
    <link href="http://www.slmt.tw/blog/2016/07/31/tracing-ptt-note-1/"/>
    <id>http://www.slmt.tw/blog/2016/07/31/tracing-ptt-note-1/</id>
    <published>2016-07-31T13:15:04.000Z</published>
    <updated>2022-04-25T08:49:17.084Z</updated>
    
    <content type="html"><![CDATA[<p>之前一直有打算要研究 PTT 的程式碼。剛好近期也在學習 Rust 語言，因此起了想要使用 Rust 重寫 PTT 的想法。Rust 具有的許多特性我認為都很適合用來寫 PTT。因此開始進行了「用 Rust 重寫 PTT 計畫」。詳細的程式碼會一一更新在 Github 上的這個 <a href="https://github.com/SLMT/rust-ptt">repository</a>。</p><p>另外，撰寫之前也需要先了解 PTT 的程式碼在做些甚麼，所以我必須要先讀懂原本的程式碼是如何運作的。我會將閱讀程式碼的筆記紀錄在我所 fork 的 PTT repository 之中的 <a href="https://github.com/SLMT/pttbbs/tree/tracing">tracing branch</a> 內。</p><a id="more"></a><p>到現在為止，我已經閱讀了 <a href="https://github.com/ptt/pttbbs">PTT Source Code</a> 之中，最主要的 <code>mbbsd.c</code> 這個檔案大多數的內容。<code>mbbsd.c</code> 這個檔案具有 <code>main</code> 函式，是程式的進入點，因此從這裡看起。</p><p>光是看到我目前為止的內容，就覺得當時寫這個 BBS 的人真的非常厲害。因為以當時的時代背景來說，幾乎沒有甚麼 library 可以使用。需要甚麼輔助功能就要自己寫。我看到了他們自己撰寫了顯示的功能，自己實作了 telnet protocol 等等。然後對系統，特別是 linux，內各個 API 都要瞭若指掌，才能掌握 BBS 站需要的功能。從這些就可以看出要搞出 BBS 站是多麼的不容易。</p><p>之後這些文章會紀錄我在閱讀程式碼時，注意到的一些我覺得值得紀錄的事情。</p><h2 id="Shared-Memory-amp-Multi-processes"><a href="#Shared-Memory-amp-Multi-processes" class="headerlink" title="Shared Memory &amp; Multi-processes"></a>Shared Memory &amp; Multi-processes</h2><p>第一個引起我注意的是，PTT 使用了 multi-processes 的方式來撰寫，而不是 multi-threading。因為我只有在修 Operating System 的時候使用過 <code>fork()</code>(產生 child process 的函式)，在這之後都是寫 multi-threading 的程式。因此我對 PTT 選擇了 fork 的做法很感興趣。</p><p>使用 fork 其實有不少好處，像是產生出來的 process 與原本的 process 是兩個獨立的個體。以資訊安全上的觀點來說，避免使用 shared memory 可以減少不同用戶之間的資料被竊取的可能性。不過，PTT 內其實大量使用了 shared memory (至少我目前看起來是這樣)，因此我覺得應該不是因為資訊安全的原因而做。看起來比較可能是因為 fork-based 的寫法比較容易撰寫與維護。另外，早期 thread 的 API 似乎還沒有一個穩定的標準，所以開啟一個 thread 也許也沒有現在這麼容易。</p><p>直覺上若使用了 multi-processes 的寫法，應該會使用 message passing 的方式來互相傳遞資料。不過 PTT 採用了跨 process 之間的 shared memory 來共享資訊。這也讓我挺訝異的，因為這也跟我的直覺不太符合。這邊我比較感興趣的是，不知道他們是怎麼處理不同 process 之間同時使用相同資料的問題，之後看到這部分會再另外撰寫筆記。</p><h2 id="偵測-Loading"><a href="#偵測-Loading" class="headerlink" title="偵測 Loading"></a>偵測 Loading</h2><p>每當有一個使用者連上 PTT 伺服器，PTT 的程式碼就會做一個系統負載檢查。若偵測到負載過高，就會送出「系統過載」的訊息。這邊我學到了如何檢查系統的負載量。</p><p>PTT 檢查的方式主要是透過 <code>getLoadavg()</code> 以及查看 <code>/proc/loadavg</code> 檔案這兩種方式來進行。這邊在檢查之前會先看是哪種系統，如果是 FreeBSD 的話，就會使用前者。若是 Linux 的話，就會使用後者。有趣的是，若兩者都不是，就會跟你說「不知道」XD</p><p>根據這份<a href="http://linux.die.net/man/3/getloadavg">官方文件</a>，只要將一個陣列塞給 <code>getLoadavg()</code>，他就會將過去 1, 5, 15 分鐘的系統平均 loading 放到陣列之中。</p><p><code>/proc/loadavg</code> 則是一份 Linux 系統中的文件，每過一段時間會被更新一次。文件中的內容大概長這樣：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.20 0.18 0.12 1&#x2F;80 11206</span><br></pre></td></tr></table></figure><p>前三個數字代表最近 1, 5, 10 分鐘的平均 loading，第四個數字代表正在執行與所有 processes 的數目，第五個代表目前最大的 process id。</p><p>目前 PTT 的程式碼只看最近 1 分鐘內的 loading，並且根據 <code>config.h</code> 之中 <code>MAX_CPULOAD</code> 的設定，來看目前系統是否過載。程式碼之中預設是超過 70% 就算是過載，不過實際上的設定也有可能會被改為其他數值。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;之前一直有打算要研究 PTT 的程式碼。剛好近期也在學習 Rust 語言，因此起了想要使用 Rust 重寫 PTT 的想法。Rust 具有的許多特性我認為都很適合用來寫 PTT。因此開始進行了「用 Rust 重寫 PTT 計畫」。詳細的程式碼會一一更新在 Github 上的這個 &lt;a href=&quot;https://github.com/SLMT/rust-ptt&quot;&gt;repository&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;另外，撰寫之前也需要先了解 PTT 的程式碼在做些甚麼，所以我必須要先讀懂原本的程式碼是如何運作的。我會將閱讀程式碼的筆記紀錄在我所 fork 的 PTT repository 之中的 &lt;a href=&quot;https://github.com/SLMT/pttbbs/tree/tracing&quot;&gt;tracing branch&lt;/a&gt; 內。&lt;/p&gt;</summary>
    
    
    
    <category term="Research" scheme="http://www.slmt.tw/blog/categories/research/"/>
    
    <category term="PTT" scheme="http://www.slmt.tw/blog/categories/research/ptt/"/>
    
    <category term="Source Code" scheme="http://www.slmt.tw/blog/categories/research/ptt/source-code/"/>
    
    
    <category term="code" scheme="http://www.slmt.tw/blog/tags/code/"/>
    
    <category term="tracing" scheme="http://www.slmt.tw/blog/tags/tracing/"/>
    
    <category term="ptt" scheme="http://www.slmt.tw/blog/tags/ptt/"/>
    
    <category term="bbs" scheme="http://www.slmt.tw/blog/tags/bbs/"/>
    
  </entry>
  
  <entry>
    <title>「Hacking - The Art of Exploitation」閱讀筆記 - 第一章</title>
    <link href="http://www.slmt.tw/blog/2016/07/23/hacking-the-art-of-exploitation-1/"/>
    <id>http://www.slmt.tw/blog/2016/07/23/hacking-the-art-of-exploitation-1/</id>
    <published>2016-07-23T17:37:17.000Z</published>
    <updated>2022-04-25T08:49:17.084Z</updated>
    
    <content type="html"><![CDATA[<p>最近打算開始好好來鑽研一下駭客的技術。雖然我一直對這塊抱持著很高的興趣，但是一直沒有好好研究這方面的知識。之前有稍微打打看一些簡單的 CTF，不過一直遭遇各種挫折XD 後來因為開始忙著要弄研究方面的東西，所以這件事就被我擱置了。最近去了美國一趟，在當地的書店發現了「Hacking - The Art of Exploitation」這本書。稍微翻一下之後覺得不錯，所以這次回來之後就要來好好看看。</p><a id="more"></a><p>為了要鞭策我閱讀這本書，我打算要每閱讀完一章後，寫一份閱讀筆記。這次就先從簡單的第一章開始。</p><h2 id="第一章-簡介"><a href="#第一章-簡介" class="headerlink" title="第一章 - 簡介"></a>第一章 - 簡介</h2><p>想當然爾，第一章不外乎就是在介紹書中的內容或者提醒讀者一些基本知識。這本書則是花費這一章來好好介紹一下「駭客」到底是甚麼。</p><p>以下來簡單總結一下這章的內容。</p><h3 id="駭客思維"><a href="#駭客思維" class="headerlink" title="駭客思維"></a>駭客思維</h3><p>有趣的是，這本書一開始提出了一個簡單的數學問題，來讓大家對駭客的思維有些感覺。題目如下 (以原文的方式呈現)：</p><blockquote><p>Use each of the numbers 1, 3, 4, and 6 exactly once with any of the four basic math operations (addition, subtraction, multiplication, and division) to total 24. Each number must be used once and only once, and you may define the order of operations; for example, 3 * (4 + 6) + 1 = 31 is valid, however incorrect, since it doesn’t total 24.</p></blockquote><p>簡單來說，題目給你 1, 3, 4, 6 四個數字，他希望你用這四個數字加上基本的加減乘除來組合出 24 的結果。</p><p>這題我花了點時間思考一下，不過我沒有想到答案 (〒︿〒)</p><p>最後正確答案是 <code>6 / (1 - 3 / 4)</code>。</p><p>這個答案符合題目的規則，但是一般人通常不會往分數的方向去思考，因此很難想到要用 <code>3 / 4</code>。</p><p>這本書用這個題目引出了駭客的思維：駭客通常就是一群會遵守著系統規則去尋找答案的人，但是他們會跳脫原本的框架，使用非直覺的方式來解答。</p><p>我個人很喜歡這種解釋方式，讓我覺得駭客很像是在程式上玩藝術的一群人。</p><h3 id="Hacker-與-Cracker"><a href="#Hacker-與-Cracker" class="headerlink" title="Hacker 與 Cracker"></a>Hacker 與 Cracker</h3><p>另外，第一章也強調了駭客 (Hacker) 與破壞者 (Cracker) 的不同。書中認為駭客是一群追求知識以及推廣自由知識的人們，破壞者則是拿駭客的工具去搞破壞、偷竊他人資訊的一群人。不過許多報章雜誌常會將這兩種人都統稱為駭客。這對遵守規則的人駭客們是很不公平的。</p><p>我個人也認同這點。大眾對駭客 (Hacker) 這個名詞一直有錯誤的概念。覺得駭客就是要去入侵系統，然後竊取人家的個資這樣。因此書中特別提出這點，想要先矯正讀者的觀念。</p><h3 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h3><p>這章其他的部分則是大概介紹一下這本書中的程式碼使用方法，以及駭客的一些歷史等等。</p><p>雖然這章只是一個開頭而已，不過一開始的題目倒是讓我有些收穫。如果要成為駭客的話，那就不能依照常理的思路來思考。</p><p>不知道一直習慣這樣想的我，是否也有辦法成為駭客呢XD</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近打算開始好好來鑽研一下駭客的技術。雖然我一直對這塊抱持著很高的興趣，但是一直沒有好好研究這方面的知識。之前有稍微打打看一些簡單的 CTF，不過一直遭遇各種挫折XD 後來因為開始忙著要弄研究方面的東西，所以這件事就被我擱置了。最近去了美國一趟，在當地的書店發現了「Hacking - The Art of Exploitation」這本書。稍微翻一下之後覺得不錯，所以這次回來之後就要來好好看看。&lt;/p&gt;</summary>
    
    
    
    <category term="Hacking" scheme="http://www.slmt.tw/blog/categories/hacking/"/>
    
    <category term="Books" scheme="http://www.slmt.tw/blog/categories/hacking/books/"/>
    
    <category term="The Art of Exploitation" scheme="http://www.slmt.tw/blog/categories/hacking/books/the-art-of-exploitation/"/>
    
    
    <category term="hacker" scheme="http://www.slmt.tw/blog/tags/hacker/"/>
    
    <category term="hacking" scheme="http://www.slmt.tw/blog/tags/hacking/"/>
    
    <category term="note" scheme="http://www.slmt.tw/blog/tags/note/"/>
    
  </entry>
  
  <entry>
    <title>2016 美國行 見聞筆記</title>
    <link href="http://www.slmt.tw/blog/2016/07/05/sigmod-2016-travel-notes/"/>
    <id>http://www.slmt.tw/blog/2016/07/05/sigmod-2016-travel-notes/</id>
    <published>2016-07-05T08:36:39.000Z</published>
    <updated>2022-04-25T08:49:17.056Z</updated>
    
    <content type="html"><![CDATA[<p>6/19 ~ 7/5 這段期間我前往美國進行了為期兩個多禮拜的旅行，主要目的是參加 SIGMOD 2016 學術會議，次要目的則是到美國去玩。(但是實際上花的時間是玩比較多XD)</p><p>因為這次是我第一次去美國，觀察到很多有趣的事情。因此特別將觀察到的事物紀錄在這篇文章之中，讓沒有機會去美國，或者將要去美國的人可以參考看看。</p><p>關於 SIGMOD 2016 會議的心得與見聞之後會寫在另一篇文章中。</p><a id="more"></a><h2 id="旅遊路徑"><a href="#旅遊路徑" class="headerlink" title="旅遊路徑"></a>旅遊路徑</h2><p>首先先用一張圖來展示一下我們的旅遊路線 (請從左上角的藍點出發)：</p><p><a href="route.png" target="_blank"><img src="route.png" /></a></p><p>以下詳細列出我們經過的地點：</p><ul><li>第一天：桃園國際機場 -&gt; 坐 11 小時飛機 -&gt; 舊金山國際機場 (SFO) -&gt; 住 SFO 附近的旅館</li><li>第二天：舊金山 (San Francisco) -&gt; 山景城 (Mountain View) Google 總部 -&gt; 庫帕提諾 (Cupertino) Apple 總部 -&gt; 史丹佛大學 (Stanford University) -&gt; 在 奧克荷斯特 (Oakhurst) 的旅館住宿</li><li>第三天：奧克荷斯特 (Oakhurst) -&gt; 優勝美地國家公園 (Yosemite National Park) -&gt; 莫諾湖 (Mono Lake, 我們又叫它單聲道湖) -&gt; 在 馬麥斯湖 (Mammoth Lakes) 的旅館住宿</li><li>第四天：馬麥斯湖 (Mammoth Lakes) -&gt; 進入內華達州 (State of Nevada) -&gt; 六小時左右車程 -&gt; 拉斯維加斯 (Las Vegas) -&gt; 看秀 -&gt; 在當地住宿</li><li>第五天：拉斯維加斯 (Las Vegas) -&gt; 進入亞利桑納州 (State of Arizona) -&gt; 西大峽谷 (Grand Canyon West) -&gt; 胡佛水壩 (Hoover Dam) -&gt; 拉斯維加斯 (Las Vegas)</li><li>第六天：拉斯維加斯 (Las Vegas) -&gt; 槍店打靶 -&gt; 進入加州 (State of California) -&gt; 洛杉磯 (Los Angeles) -&gt; 在好萊塢附近住宿</li><li>第七天：好萊塢附近 -&gt; 環球影城 (University Studio) -&gt; 回到旅館</li><li>第八天：旅館 -&gt; 長灘 (Long Beach) -&gt; 愛荷華級戰艦博物館 (Iowa Battleship Museum) -&gt; 聖莫尼卡 (Santa Monica) -&gt; 洛杉磯聯合車站 (Los Angeles Union station) -&gt; 搭八小時夜間班車回舊金山</li><li>第九天：下車 -&gt; 搭公車前往市區 -&gt; 將行李寄放在旅館 -&gt; 聯合廣場 (Union Square) -&gt; 回到旅館</li><li>第十天～第十二天：SIGMOD 2016 會議</li><li>第十三天：旅館 -&gt; 惡魔島 (Alcatraz Island) -&gt; 逛 39 號碼頭 (Pier 39) -&gt; 在舊金山市區內亂晃 -&gt; 回到旅館</li><li>第十四天：旅館 -&gt; 前往舊金山購物城 (San Francisco Premium Outlets) -&gt; 回到旅館</li><li>第十五天：旅館 -&gt; 舊金山市政中心 (Civic Center) -&gt; 延市場街 (Market Street) 一路逛到碼頭 -&gt; 渡輪大厦 (Ferry Building) -&gt; 反向逛回旅館 -&gt; 到 SFO 準備搭飛機回台灣</li></ul><h2 id="觀察"><a href="#觀察" class="headerlink" title="觀察"></a>觀察</h2><p>以下採用條列式的方式列出了我所觀察到的一些特點。若未來我有想到其他的，可能會再補充上去。</p><h3 id="整體"><a href="#整體" class="headerlink" title="整體"></a>整體</h3><ul><li>美金 100 元很難用，因為太大張很少店願意收</li><li>超商或餐廳大多數的飲料都是碳酸飲料或能量飲料，茶通常只有檸檬紅茶或奇怪的調味茶，不容易買到日式綠茶</li><li>美國平常能吃到的最低價餐點為速食，價格通常不會低於 5 USD，一般在 10 USD 左右</li><li>薯條為最常出現的主食</li><li>美國大眾交通運輸沒有很方便，若要進行離開城市的旅行，最好租車來開</li><li>人行紅綠燈與台灣很不同。不能行進的時候，雖然跟台灣一樣會顯示紅色的號誌。但是可以行進的時候，會先變成白色號誌，再轉變成紅色手掌搭配倒數計時。一般台灣人看到紅色手掌會以為是不能前進的意思，但是搭配倒數計時則其實是可以通行的。</li><li>Wifi 普及率算高，但是大多數網速都很慢</li><li>基本上在美國，有人服務到你包括桌邊點餐、搬行李、整理房間等等行為都要給小費 (Tips)。金額隨行為不同而變。整理房間通常 1~3 USD，吃飯則有人說給 10%，有人說給 18%，後者似乎比較多人講。</li><li>美國刷卡有種先刷卡再填入金額交易的行為。通常台灣都是先看好多少錢，再刷卡簽名。但是美國是先刷卡，然後在請款單上寫上小費與總金額之後再簽名。</li></ul><h3 id="優勝美地國家公園"><a href="#優勝美地國家公園" class="headerlink" title="優勝美地國家公園"></a>優勝美地國家公園</h3><p><a href="yosemite.jpg" target="_blank"><img src="yosemite.jpg" /></a></p><ul><li>Glacier point 可以開車上去，但是要盡量在早上 10 點以前上去，不然人多就會開始管制車輛進出。</li><li>Yosemite Valley 內雖然有很多停車場，但是很容易停滿。若想停那邊就同樣也要很早去。我們當時是去完 Glacier Pointer 再下來，結果我們巡完 Valley 內所有停車場完全找不到任何位置。</li></ul><h3 id="Las-Vegas"><a href="#Las-Vegas" class="headerlink" title="Las Vegas"></a>Las Vegas</h3><p><a href="vegas.jpg" target="_blank"><img src="vegas.jpg" /></a></p><ul><li>白天很熱</li><li>晚上也很熱，跟白天的差異只差在少了直曬的陽光，很有可能跟集中的水泥建築、沙漠地帶與持續排放熱氣的空調外機有關。熱的程度基本上就是熱到汗流出來馬上就會蒸發。</li><li>街道上有很多人在賣冰水，大多價格為 1 USD</li><li>高速公路的交流道非常複雜，而且幾乎快到閘道才會有告示牌通知前有閘道，如果沒有 Google 地圖或其他導航系統就很容易走錯</li><li>賭場要 21 歲以上才能進去，安全人員有權在任意時候要求查看 ID (身分證明, 外國人就看護照)。有些賭場會提供一個服務台，讓你在那邊查完 ID 之後取得一個手環。該手環可以證明你符合資格，安全人員就不會一直來煩你。</li></ul><h3 id="Los-Angeles"><a href="#Los-Angeles" class="headerlink" title="Los Angeles"></a>Los Angeles</h3><ul><li>儘管在夏天，天氣仍稍微偏涼，晚上可能最好穿件薄外套</li><li>高速公路上限速大概 65 miles/hr，但是大家都開到差不多 80 miles/hr</li><li>路上有人會發送光碟片，然後附上他的簽名，並表示他是知名藝人。當你接手光碟片後，就會要求你付錢購買，遇到這種情況要盡量避免接觸。</li><li>有很多很大的海灘</li></ul><h4 id="環球影城"><a href="#環球影城" class="headerlink" title="環球影城"></a>環球影城</h4><p><a href="universal.jpg" target="_blank"><img src="universal.jpg" /></a></p><ul><li>遊樂設施（排除表演）之中，最好玩的應該是哈利波特的 4D 冒險</li><li>表演都很值得看，甚至應該先看表演再看是否有剩餘時間玩遊樂設施</li><li>就算中午才去，也可以把所有表演跟設施在閉園前玩完，因此其實不太需要一大早就去排隊</li></ul><h4 id="愛荷華級戰艦博物館"><a href="#愛荷華級戰艦博物館" class="headerlink" title="愛荷華級戰艦博物館"></a>愛荷華級戰艦博物館</h4><p><a href="iowa.jpg" target="_blank"><img src="iowa.jpg" /></a></p><ul><li>上網買門票可以便宜 2 USD (19.95 USD =&gt; 17.95 USD)</li><li>戰艦很大，可以逛的區域很多，走完需要一點時間。走馬看花大概要半到一小時，仔細逛可以逛一整天</li></ul><h3 id="San-Francisco"><a href="#San-Francisco" class="headerlink" title="San Francisco"></a>San Francisco</h3><p><a href="sf.jpg" target="_blank"><img src="sf.jpg" /></a></p><p><a href="sf_china.jpg" target="_blank"><img src="sf_china.jpg" /></a></p><ul><li>雖然有很多華人，但大多數的華人都講廣東話，幾乎不會說普通話</li><li>公車非常多樣，有些是使用高架電纜，有些是輕軌，另外還有地下鐵與一般公車</li><li>街道上常會聞到有尿騷味</li><li>Union Square 以南有很多流浪漢和奇怪的人聚集</li><li>海邊很舒適，風景不錯</li><li>受到加利福尼亞洋流影響，夏天也非常冷，白天可能需要穿件長袖，晚上則冷到需要穿上外套</li><li>公車大概價格是 2.25 USD/人，通常買一張票後在該時間區段內都可以重複使用</li></ul><h4 id="SFO"><a href="#SFO" class="headerlink" title="SFO"></a>SFO</h4><ul><li>安檢比台灣嚴格多，例如鞋子也必須脫下來進行掃描，並且每個人都要進到一個小房間進行全身掃描。</li><li>候機處到處都有插頭可以使用，很方便</li></ul><h2 id="Fails"><a href="#Fails" class="headerlink" title="Fails"></a>Fails</h2><p>這邊列一些這次旅行沒有事先考慮清楚，而造成旅行不方便的一些點。</p><ul><li>沒有帶延長線，因為美國旅館的插頭都超級少，但是四個人一堆電器都要用電</li><li>沒有帶拖鞋，洗完澡後要出房門不太方便</li><li>帶太多 100 塊，因為很少店家會收，其他錢用完之後就很不方便</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;6/19 ~ 7/5 這段期間我前往美國進行了為期兩個多禮拜的旅行，主要目的是參加 SIGMOD 2016 學術會議，次要目的則是到美國去玩。(但是實際上花的時間是玩比較多XD)&lt;/p&gt;
&lt;p&gt;因為這次是我第一次去美國，觀察到很多有趣的事情。因此特別將觀察到的事物紀錄在這篇文章之中，讓沒有機會去美國，或者將要去美國的人可以參考看看。&lt;/p&gt;
&lt;p&gt;關於 SIGMOD 2016 會議的心得與見聞之後會寫在另一篇文章中。&lt;/p&gt;</summary>
    
    
    
    <category term="Traveling" scheme="http://www.slmt.tw/blog/categories/traveling/"/>
    
    <category term="USA" scheme="http://www.slmt.tw/blog/categories/traveling/usa/"/>
    
    
    <category term="traveling" scheme="http://www.slmt.tw/blog/tags/traveling/"/>
    
    <category term="san francisco" scheme="http://www.slmt.tw/blog/tags/san-francisco/"/>
    
    <category term="sigmod" scheme="http://www.slmt.tw/blog/tags/sigmod/"/>
    
    <category term="usa" scheme="http://www.slmt.tw/blog/tags/usa/"/>
    
  </entry>
  
  <entry>
    <title>Rust 任天堂64 模擬器</title>
    <link href="http://www.slmt.tw/blog/2016/06/17/rust-nintendo64-emulator/"/>
    <id>http://www.slmt.tw/blog/2016/06/17/rust-nintendo64-emulator/</id>
    <published>2016-06-17T13:19:28.000Z</published>
    <updated>2022-04-25T08:49:17.056Z</updated>
    
    <content type="html"><![CDATA[<p>先說不是我寫的XD</p><p>最近訂閱了 <a href="https://this-week-in-rust.org/">This Week in Rust</a> 這個部落格上的文章。這個部落格會將每周關於 Rust 值得注意的事項整理成一篇文章，分享給大家。因為近期對 Rust 很有興趣，就訂閱了這個平台。</p><p>其中我看到了一個很有趣的 project。就是一位叫做 ferris 的網友，在 Twitch 上實況用 Rust 撰寫一個任天堂64 的模擬器。</p><a id="more"></a><p>一直以來我都沒有真正看過模擬器裡面的程式碼，而且我也沒有看過一個大型 Rust Project 的撰寫過程，因此對這個 project 就備感興趣。</p><p>目前最新才到 11 集，雖然我看了一集多還沒看到它載入第一個 instruction，不過目前為止讓我複習不少 Rust 語法，而且也學到了關於模擬器的一些基本知識。也許未來我也可以實況寫一個 Game Boy XD (寫任天堂64看起來很累)</p><p>有興趣的人可以追蹤它的 Twitter，或者到 Youtube 上看它的實況記錄，程式碼則可以在 Github 上找到：</p><p>Twitter - 追蹤 ferris：<a href="https://twitter.com/ferristweetsnow">https://twitter.com/ferristweetsnow</a><br>Youtube - 實況記錄：<a href="https://www.youtube.com/playlist?list=PL-sXmdrqqYYcznDg4xwAJWQgNL2gRray2">https://www.youtube.com/playlist?list=PL-sXmdrqqYYcznDg4xwAJWQgNL2gRray2</a><br>Github - 程式碼：<a href="https://github.com/yupferris/rustendo64">https://github.com/yupferris/rustendo64</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;先說不是我寫的XD&lt;/p&gt;
&lt;p&gt;最近訂閱了 &lt;a href=&quot;https://this-week-in-rust.org/&quot;&gt;This Week in Rust&lt;/a&gt; 這個部落格上的文章。這個部落格會將每周關於 Rust 值得注意的事項整理成一篇文章，分享給大家。因為近期對 Rust 很有興趣，就訂閱了這個平台。&lt;/p&gt;
&lt;p&gt;其中我看到了一個很有趣的 project。就是一位叫做 ferris 的網友，在 Twitch 上實況用 Rust 撰寫一個任天堂64 的模擬器。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://www.slmt.tw/blog/categories/programming/"/>
    
    <category term="Rust" scheme="http://www.slmt.tw/blog/categories/programming/rust/"/>
    
    
    <category term="rust" scheme="http://www.slmt.tw/blog/tags/rust/"/>
    
    <category term="programming" scheme="http://www.slmt.tw/blog/tags/programming/"/>
    
    <category term="emulator" scheme="http://www.slmt.tw/blog/tags/emulator/"/>
    
  </entry>
  
  <entry>
    <title>hexo-blog</title>
    <link href="http://www.slmt.tw/blog/2016/06/15/hexo-blog/"/>
    <id>http://www.slmt.tw/blog/2016/06/15/hexo-blog/</id>
    <published>2016-06-15T14:31:18.000Z</published>
    <updated>2022-04-25T08:49:17.056Z</updated>
    
    <content type="html"><![CDATA[<p>我又換新部落格啦！這次 Static Pages Generator 改用 <a href="https://hexo.io/zh-tw/">Hexo</a>，原因主要為：</p><ul><li>Hexo 以 Node.js 撰寫</li><li>Hexo 中文資源比較多可以參考 (使用者大多為華人)</li><li>Hexo 是台灣人 <a href="https://zespia.tw/">Tommy Chen</a> 開發的</li></ul><h2 id="主題"><a href="#主題" class="headerlink" title="主題"></a>主題</h2><p>因為我一直都沒有自己很喜歡的主題，所以這次決定來自己寫一個。</p><p>這次主要的概念是簡單明瞭，又要 responsive。因此就製作出了現在看到的這個部落格風格。</p><p>如果想要參考我自己撰寫的程式碼，可以到我的 Github Repository 參考：</p><p><a href="https://github.com/SLMT/slmt-blog">https://github.com/SLMT/slmt-blog</a></p><p>雖然這個風格很容易寫就是了XD</p><p>這個風格主要使用了以下這些 library：</p><ul><li><a href="http://purecss.io/">Pure CSS</a> - 一個極輕量的 responsive library。主要是為了上面的 navigation bar。</li><li><a href="http://fontawesome.io/?utm_source=hackernewsletter">Font Awesome</a> - 一個整合各種實用 icon 的字型。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我又換新部落格啦！這次 Static Pages Generator 改用 &lt;a href=&quot;https://hexo.io/zh-tw/&quot;&gt;Hexo&lt;/a&gt;，原因主要為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hexo 以 Node.js 撰寫&lt;/li&gt;
&lt;li&gt;Hexo 中文資源比</summary>
      
    
    
    
    <category term="Building Blog" scheme="http://www.slmt.tw/blog/categories/building-blog/"/>
    
    <category term="Hexo" scheme="http://www.slmt.tw/blog/categories/building-blog/hexo/"/>
    
    
    <category term="blog" scheme="http://www.slmt.tw/blog/tags/blog/"/>
    
    <category term="hexo" scheme="http://www.slmt.tw/blog/tags/hexo/"/>
    
    <category term="welcome" scheme="http://www.slmt.tw/blog/tags/welcome/"/>
    
    <category term="chinese" scheme="http://www.slmt.tw/blog/tags/chinese/"/>
    
  </entry>
  
  <entry>
    <title>BambooFox 第三堂社課心得</title>
    <link href="http://www.slmt.tw/blog/2015/10/29/bamboofox-club-03/"/>
    <id>http://www.slmt.tw/blog/2015/10/29/bamboofox-club-03/</id>
    <published>2015-10-29T16:00:00.000Z</published>
    <updated>2022-04-25T08:49:17.056Z</updated>
    
    <content type="html"><![CDATA[<p>這次的課程接續上次組合語言的內容，主要在談 x86 架構下的組合語言，以及常見的 Buffer Overflow 漏洞。</p><a id="more"></a><h2 id="課程內容分享"><a href="#課程內容分享" class="headerlink" title="課程內容分享"></a>課程內容分享</h2><h3 id="組合語言"><a href="#組合語言" class="headerlink" title="組合語言"></a>組合語言</h3><p>一開始先回顧一下 x86 下的架構，包含 registers 與一些 conditional flags 等等。 接著複習了一些 x86 架構下常見的組合語言指令。 這邊有提到 Intel 與 AT&amp;T 兩種 style 不同的寫法，並介紹一些之間的差異等等。</p><p>最重要的資訊，我想應該就是了解如何做 system call 吧！</p><p>System call 是一種讓你程式跟作業系統 (Opearating System, OS) 溝通的管道。 舉凡要進行任何需要 OS 幫忙的工作，都要透過 system call。 而在組合語言之中，想要進行 system call，就要使用 interrept 的指令來暫時中斷程式，並轉交權限給 OS。 大概進行的 pattern 就如同下面所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">moveax, xxx; 想要 OS 執行的 function 代碼</span><br><span class="line">movebx, xxx; function 的第一個參數</span><br><span class="line">movecx, xxx; function 的第二個參數</span><br><span class="line">movedx, xxx; function 的第三個參數</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">int0x80; 進行 system call</span><br></pre></td></tr></table></figure><p>一開始要先將一些參數存入 registers，<code>eax</code> 要放你想要 OS 進行的 system call function 代碼。 例如你想要系統讀檔，就要放 3 (sys_read)。 然後，其他 registers，像是 <code>ebx</code>, <code>ecx</code>, <code>edx</code>, <code>esx</code>, <code>edi</code> 則是要放呼叫該動作的參數。 例如剛剛說的讀檔，就必須要分別在 <code>ebx</code>、<code>ecx</code> 與 <code>edx</code> 放入 file descriptor、buffer pointer 與想要讀取的大小。 最後再執行 <code>int 0x80</code> 指令來進行 system call。</p><p>詳細每個 register 在進行 system call 所需要放的參數可以在 <a href="http://docs.cs.up.ac.za/programming/asm/derick_tut/syscalls.html">這個表</a> 找到。</p><p>我想學這個的目的，除了是為了要能夠對程式做逆向工程之外，也是為了要在之後 inject (注入) shellcode 而使用。 甚至是做更進一步的攻擊。 算是還挺實用的。</p><h3 id="Buffer-Overflow"><a href="#Buffer-Overflow" class="headerlink" title="Buffer Overflow"></a>Buffer Overflow</h3><p>Buffer overflow 是 C/C++ 常見的漏洞。 只要你的程式之中使用到了陣列或指標，並配合呼叫了不安全的 function，就有可能有潛在的問題。</p><p>例如下面這段 code：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> input[<span class="number">50</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, input);</span><br></pre></td></tr></table></figure><p>這段看起來極其平淡，且在一開始程設課就學過的 code，潛藏著極大的危機存在。</p><p><code>scanf</code> 不會檢查使用者輸入的長度，也不會知道 <code>input</code> 這個陣列有多大，除非遇到特定的字元，不然他就會持續性地一直讀取輸入值。 而當使用者輸入的長度超過了 <code>input</code> 的空間，也就是在上例中超過 49 個字元 (最後一個字是 <code>\0</code>)，就會發生 overflow 的情況。 一般來說 overflow 只會讓程式出現 <code>segmentation fault</code> 而已，可是有心人士可以利用這個來控制程式的運作方向。</p><p>區域變數通常是放在 stack 中，stack 除了變數之外，還會放著各式各樣其他的資訊。 像是 function arguments，stack frame pointer，還有最重要的 saved eip。 EIP 是 x86 系統下一個特殊的 register，這個 register 不能直接寫入，只能透過特殊指令來進行修改。 EIP 其重要之處，就是在他負責告訴 CPU，下一個要執行的指令在哪裡。</p><p>因此掌控了 EIP，就掌控了整個程式走向。</p><p>想想前面提到的 buffer overflow，到底多出的部分跑哪去了？基本上就是跑到外面的地方，覆蓋掉 stack 上的其他資訊。</p><p>剛剛提到了 stack 有放 saved eip。 當程式呼叫 function 的時候，為了要能夠在 function 結束之後，跳回到原本的位置，會將回去預計繼續執行的程式碼位址暫存在 stack 中，這就是 saved eip。</p><p>利用 buffer overflow，你就會有機會覆寫掉 saved eip 的數值。 只要控制得好，就能將你想要讓程式執行的程式碼位址覆蓋掉 saved eip。 當程式 return 的時候，就會拿出你預先設計的數值，並跳轉到你希望的位置繼續執行程式。 這個時候就可以做很多有趣的事情，例如讓程式執行你預先塞好的程式碼，然後呼叫 shell 等等。</p><p>這也是到現今為止還是常常能看見的大洞。 不過編譯器其實也有在進步，為了這防止駭客攻擊這個部分，使用了各式各樣的技巧來保護。 當然駭客也不是笨蛋，也想出了很多方法繞過這些機制。 到現在還沒有一定的勝負。</p><h2 id="練習題的收穫"><a href="#練習題的收穫" class="headerlink" title="練習題的收穫"></a>練習題的收穫</h2><p>今天主要的練習是 <a href="http://train.cs.nctu.edu.tw/problems/1">這題</a> ，重點在於 buffer overflow 的觀念。 讓正確的 buffer overflow，找到如何覆蓋 saved eip，找到程式應該要執行到哪，以及要怎麼避免程式搗亂的行為。</p><p>這題今天學到最有用的知識有兩點：</p><h3 id="1-scanf-終止條件"><a href="#1-scanf-終止條件" class="headerlink" title="1. scanf 終止條件"></a>1. <code>scanf</code> 終止條件</h3><p>這題有個部分會檢查你輸入 buffer 的長度，檢查的方式是利用 <code>strlen</code>，並且會對你的 buffer 做攪亂的動作。 這邊我們可以讓程式只攪亂部分的 buffer，或甚至完全繞過。 重點在於讓程式以為 buffer 很短，但是其實比他知道的大很多。</p><p>但是要怎麼做呢？ <code>strlen</code> 的檢查中止條件是看到 <code>\0</code> 就停下來。 換句話說，<code>\0</code> 之前的內容都會被當作字串的一部分，之後的東西就不管了。 這邊我一開始有想到在 buffer 內插入 <code>\0</code> 來防止程式攪亂我的 payload。 但是我馬上想到了，<code>scanf</code> 應該會把 <code>\0</code> 也當作終止條件，所以我想這招應該沒用。</p><p>可是在卡了許久之後，經過前輩提示，看了看提示的投影片，才知道原來 <code>scanf</code> 的中止條件更狹隘。 他們只會在遇到空白或是換行字元才停，<code>\0</code> 也會被當成字串的一部分吃進來。 這還真是大洞啊！ 我完全意想不到這種我以為該有的條件竟然沒有！ 看來 C\C++ 比我想像的更危機四伏。</p><h3 id="2-cat"><a href="#2-cat" class="headerlink" title="2. cat -"></a>2. <code>cat -</code></h3><p>這個也很有趣。 他們的程式是放在他們專有的機器上執行，而我們必須要透過網路連線才有辦法跟程式溝通。 通常會使用 <code>nc</code> (netcat) 進行。 當攻擊者取得 shell 之後，就可以拿到機器上的 flag。 不過雖然我將 payload 送過去之後，也成功呼叫出 shell 了。 可是遇到了一個很大的問題，就是我無法跟 shell 進行互動！ 因為我使用了 <code>cat payload | nc [IP] [Port]</code> 的方式來將預先寫好的 input 傳過去，但是也封閉了我使用 <code>nc</code> 進行溝通的道路。</p><p>正當我在想是否要自己寫 python code 來互動的時候，發現了一個更簡單的方式！</p><p>就是使用 <code>cat -</code>！ <code>cat</code> 指令會印出檔案的內容，後面接著檔案名稱。 那 <code>-</code> 又是啥檔案？</p><p><code>-</code> 代表的就是 standard input！ 也就是標準輸入 (通常是鍵盤)！</p><p>如果你有自己的 unix 環境可以試試看，使用 <code>cat -</code> ，並輸入一些字元會發生甚麼事情。 你會發現它會將你輸入的東西直接 output 出來。</p><p>這就是我需要的啊！</p><p>我只要把上面的指令改成 <code>cat payload - | nc [IP] [Port]</code>。 這樣 <code>cat</code> 就會先將 payload 傳過去，然後再轉接 standrad input 給它。 這樣我就可以在取得 shell 之後，輸入指令給 <code>nc</code> 傳送了！</p><p>這個算是我今天覺得最有用的技巧XD</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;這次的課程接續上次組合語言的內容，主要在談 x86 架構下的組合語言，以及常見的 Buffer Overflow 漏洞。&lt;/p&gt;</summary>
    
    
    
    <category term="CTF" scheme="http://www.slmt.tw/blog/categories/ctf/"/>
    
    <category term="BambooFox" scheme="http://www.slmt.tw/blog/categories/ctf/bamboofox/"/>
    
    
    <category term="bamboofox" scheme="http://www.slmt.tw/blog/tags/bamboofox/"/>
    
    <category term="ctf" scheme="http://www.slmt.tw/blog/tags/ctf/"/>
    
    <category term="club" scheme="http://www.slmt.tw/blog/tags/club/"/>
    
  </entry>
  
</feed>
